# ì„œìš¸ì£¼íƒë„ì‹œê³µì‚¬ ì£¼íƒì§€ì› ë´‡

ì„œìš¸ì‹œ ì£¼íƒ ê´€ë ¨ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í•˜ëŠ” í¬ë¡¤ë§ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸ“‹ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- **Python**: 3.12+ (ê¶Œì¥: 3.12)
- **OS**: macOS, Linux, Windows
- **ë°ì´í„°ë² ì´ìŠ¤**: PostgreSQL (ì„ íƒì‚¬í•­)

## ğŸš€ ì„¤ì¹˜ ë° ì„¤ì •

### 1. ì €ì¥ì†Œ í´ë¡ 

```bash
git clone <repository-url>
cd SeoulHousingAssistBot
```

### 2. Python ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”

#### uv ì‚¬ìš© (ê¶Œì¥)

```bash
# Python 3.12ë¡œ ê°€ìƒí™˜ê²½ ìƒì„±
uv venv --python 3.12

# ê°€ìƒí™˜ê²½ í™œì„±í™”
# macOS/Linux:
source .venv/bin/activate
# Windows:
# .venv\Scripts\activate
```

#### pip ì‚¬ìš©

```bash
# Python 3.12 ì‚¬ìš© (ê¶Œì¥)
python3.12 -m venv .venv

# ê°€ìƒí™˜ê²½ í™œì„±í™”
# macOS/Linux:
source venv/bin/activate
# Windows:
# venv\Scripts\activate
```

### 3. íŒ¨í‚¤ì§€ ì„¤ì¹˜

#### uv ì‚¬ìš© (ê¶Œì¥)

```bash
# uv ì„¤ì¹˜ (ì•„ì§ ì„¤ì¹˜í•˜ì§€ ì•Šì€ ê²½ìš°)
curl -LsSf https://astral.sh/uv/install.sh | sh

# ê°œë°œ ëª¨ë“œë¡œ ì„¤ì¹˜ (ê¶Œì¥)
uv pip install -e .

# ë˜ëŠ” requirements.txtë¡œ ì„¤ì¹˜
uv pip install -r backend/requirements.txt

# ê°€ìƒí™˜ê²½ê³¼ í•¨ê»˜ ì„¤ì¹˜
uv venv
uv pip install -e .
```

#### pip ì‚¬ìš©

```bash
# ê°œë°œ ëª¨ë“œë¡œ ì„¤ì¹˜ (ê¶Œì¥)
pip install -e .

# ë˜ëŠ” requirements.txtë¡œ ì„¤ì¹˜
pip install -r backend/requirements.txt

playwright install
```

### 4. í™˜ê²½ë³€ìˆ˜ ì„¤ì •

```bash
# .env íŒŒì¼ ìƒì„±
cp backend/env.example .env

# .env íŒŒì¼ í¸ì§‘í•˜ì—¬ API í‚¤ ì„¤ì •
# SEOUL_API_KEY=your_seoul_api_key_here
# LOCALDATA_API_KEY=your_localdata_api_key_here
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### âš¡ uvë¡œ ë¹ ë¥¸ ì„¤ì • (ê¶Œì¥)

```bash
# 1. ì €ì¥ì†Œ í´ë¡ 
git clone <repository-url>
cd SeoulHousingAssistBot

# 2. uvë¡œ ê°€ìƒí™˜ê²½ ìƒì„± ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜
uv venv --python 3.12
source .venv/bin/activate  # macOS/Linux
uv pip install -e .

# 3. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
cp backend/env.example .env
# .env íŒŒì¼ í¸ì§‘í•˜ì—¬ API í‚¤ ì„¤ì •

# 4. API ë°ì´í„° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
data_collection api load --csv
```

## ğŸ“‹ ìƒì„¸ ì„¤ì¹˜ ê°€ì´ë“œ

```bash
# ì„œìš¸ ì—´ë¦°ë°ì´í„° ìˆ˜ì§‘ (ëª¨ë“  ì„œë¹„ìŠ¤ - 7ê°œ)
data_collection api load --csv
# ìˆ˜ì§‘ ë°ì´í„°: ì§€í•˜ì² ì—­, ì•½êµ­, ì–´ë¦°ì´ì§‘, ì´ˆë“±í•™êµ, í•™êµ, ëŒ€í•™êµ, ê³µì›

# íŠ¹ì • ì„œë¹„ìŠ¤ë§Œ ìˆ˜ì§‘
data_collection api public --csv    # ì§€í•˜ì² ì—­ ì •ë³´ë§Œ (SearchSTNBySubwayLineInfo)
data_collection api housing --csv   # ê³µì› ì •ë³´ë§Œ (SearchParkInfoService)

# CSV ì €ì¥ ì—†ì´ ìˆ˜ì§‘ë§Œ (ë°ì´í„°ëŠ” ë©”ëª¨ë¦¬ì—ë§Œ ë¡œë“œ)
data_collection api load
data_collection api public
data_collection api housing

# ë¡œì»¬ë°ì´í„° í¬í„¸ ìˆ˜ì§‘ (API ê¶Œí•œ í•„ìš”)
data_collection api load --source localdata --csv
```

#### ğŸ“Š ìˆ˜ì§‘ë˜ëŠ” ë°ì´í„° ìƒì„¸

**`data_collection api load --csv` ì‹¤í–‰ ì‹œ:**

1. **SearchSTNBySubwayLineInfo** - ì§€í•˜ì² ì—­ ì •ë³´ (799ê±´)
2. **TbPharmacyOperateInfo** - ì•½êµ­ ìš´ì˜ ì •ë³´ (1000ê±´)
3. **ChildCareInfo** - ì–´ë¦°ì´ì§‘ ì •ë³´ (1000ê±´)
4. **childSchoolInfo** - ì´ˆë“±í•™êµ ì •ë³´ (944ê±´)
5. **neisSchoolInfo** - í•™êµ ì •ë³´ (1000ê±´)
6. **SebcCollegeInfoKor** - ëŒ€í•™êµ ì •ë³´ (64ê±´)
7. **SearchParkInfoService** - ê³µì› ì •ë³´ (131ê±´)

**ì €ì¥ ìœ„ì¹˜:** `backend/data/public-api/openseoul/`

### í¬ë¡¤ë§ ë°ì´í„° ìˆ˜ì§‘

```bash
# ì‚¬íšŒì£¼íƒ í¬ë¡¤ë§
data_collection crawl sohouse --fresh

# ê³µë™ì²´ì£¼íƒ í¬ë¡¤ë§
data_collection crawl cohouse --fresh

# ì²­ë…„ì£¼íƒ í¬ë¡¤ë§
data_collection crawl youth --fresh

# ëª¨ë“  í”Œë«í¼ í¬ë¡¤ë§
data_collection crawl all --fresh
```

### ë°ì´í„° ë¶„ì„ ë° ë³€í™˜

```bash
# í¬ë¡¤ë§ëœ ë°ì´í„° ì •ê·œí™” (ë¶„ì„)
data_collection normalized process

# íŠ¹ì • í”Œë«í¼ë§Œ ì •ê·œí™”
data_collection normalized process --platform sohouse

# íŠ¹ì • ë‚ ì§œë§Œ ì •ê·œí™”
data_collection normalized process --date 2025-09-18

# ì •ê·œí™” í›„ DBì— ì €ì¥
data_collection normalized process --db

# ì „ì²´ í”„ë¡œì„¸ìŠ¤ (í¬ë¡¤ë§ â†’ ì •ê·œí™”)
data_collection crawl all --fresh && data_collection normalized process
```

### ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬

```bash
# ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„±
sha-db create

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸
sha-db test

# ëª¨ë“  í…Œì´ë¸” ëª©ë¡ í™•ì¸
sha-db list

# íŠ¹ì • í…Œì´ë¸” êµ¬ì¡° í™•ì¸
sha-db structure bus_stops

# PostgreSQLë¡œ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
sha-db migrate-pg

# MySQLì— ë°ì´í„° ë¡œë“œ
sha-db load-mysql

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (ì£¼ì˜!)
sha-db reset
```

## ğŸ“ ë°ì´í„° ì €ì¥ ìœ„ì¹˜

### API ë°ì´í„°

- **ì„œìš¸ ì—´ë¦°ë°ì´í„°**: `backend/data/public-api/openseoul/`
- **ë¡œì»¬ë°ì´í„° í¬í„¸**: `backend/data/public-api/localdata/`

### í¬ë¡¤ë§ ë°ì´í„°

- **ì‚¬íšŒì£¼íƒ**: `backend/data/raw/sohouse/`
- **ê³µë™ì²´ì£¼íƒ**: `backend/data/raw/cohouse/`
- **ì²­ë…„ì£¼íƒ**: `backend/data/raw/youth/`

## ğŸ”‘ API í‚¤ ì„¤ì •

### ì„œìš¸ ì—´ë¦°ë°ì´í„°ê´‘ì¥

1. [ì„œìš¸ ì—´ë¦°ë°ì´í„°ê´‘ì¥](https://data.seoul.go.kr/) íšŒì›ê°€ì…
2. API í‚¤ ë°œê¸‰ ì‹ ì²­
3. `.env` íŒŒì¼ì— `SEOUL_API_KEY` ì„¤ì •

### ë¡œì»¬ë°ì´í„° í¬í„¸ (ì„ íƒì‚¬í•­)

1. [ë¡œì»¬ë°ì´í„° í¬í„¸](https://www.localdata.go.kr/) íšŒì›ê°€ì…
2. API í‚¤ ë°œê¸‰ ì‹ ì²­
3. `.env` íŒŒì¼ì— `LOCALDATA_API_KEY` ì„¤ì •

## ğŸ› ï¸ ë¬¸ì œ í•´ê²°

### Import ì˜¤ë¥˜ í•´ê²°

```bash
# uv ì‚¬ìš©
uv pip install -e .

# pip ì‚¬ìš©
pip install -e .
```

### API í‚¤ ì˜¤ë¥˜

- `.env` íŒŒì¼ì´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìˆëŠ”ì§€ í™•ì¸
- API í‚¤ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
- API í‚¤ ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸

### ë°ì´í„° ì €ì¥ ê²½ë¡œ ì˜¤ë¥˜

- `backend/data/` ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
- ì“°ê¸° ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸

## ğŸ“Š ìˆ˜ì§‘ ê°€ëŠ¥í•œ ë°ì´í„°

### ì„œìš¸ ì—´ë¦°ë°ì´í„°ê´‘ì¥

- ì§€í•˜ì² ì—­ ì •ë³´ (SearchSTNBySubwayLineInfo)
- ì•½êµ­ ìš´ì˜ ì •ë³´ (TbPharmacyOperateInfo)
- ì–´ë¦°ì´ì§‘ ì •ë³´ (ChildCareInfo)
- ì´ˆë“±í•™êµ ì •ë³´ (childSchoolInfo)
- í•™êµ ì •ë³´ (neisSchoolInfo)
- ëŒ€í•™êµ ì •ë³´ (SebcCollegeInfoKor)
- ê³µì› ì •ë³´ (SearchParkInfoService)

### í¬ë¡¤ë§ ë°ì´í„°

- ì‚¬íšŒì£¼íƒ ê³µê³ 
- ê³µë™ì²´ì£¼íƒ ê³µê³ 
- ì²­ë…„ì£¼íƒ ê³µê³ 
- LH ê³µê³ 
- SH ê³µê³ 

### ì§ì ‘ CLI ëª¨ë“ˆ ì‹¤í–‰ (ê³ ê¸‰ ì‚¬ìš©ììš©)

```bash
# í¬ë¡¤ë§ ëª¨ë“ˆ ì§ì ‘ ì‹¤í–‰
python -m backend.services.data_collection.cli.crawl_platforms sohouse --fresh
python -m backend.services.data_collection.cli.crawl_platforms cohouse --fresh
python -m backend.services.data_collection.cli.crawl_platforms youth --fresh

# API ìˆ˜ì§‘ ëª¨ë“ˆ ì§ì ‘ ì‹¤í–‰
python -m backend.services.data_collection.public-api.run --source seoul --service all --csv
python -m backend.services.data_collection.public-api.run --source localdata --csv

# ì •ê·œí™” CLI ì§ì ‘ ì‹¤í–‰
python -m backend.services.data_collection.cli.normalized_cli process

# ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ (ê¶Œì¥: sha-db ì‚¬ìš©)
sha-db create              # ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„±
sha-db list                # ëª¨ë“  í…Œì´ë¸” ëª©ë¡
sha-db test                # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸
sha-db migrate-pg          # PostgreSQLë¡œ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
sha-db load-mysql          # MySQLì— ë°ì´í„° ë¡œë“œ
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
SeoulHousingAssistBot/
â”œâ”€â”€ backend/                     # ë°±ì—”ë“œ (Python)
â”‚   â”œâ”€â”€ services/               # ì„œë¹„ìŠ¤ ë ˆì´ì–´
â”‚   â”‚   â””â”€â”€ data_collection/    # ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤
â”‚   â”‚       â”œâ”€â”€ cli/            # CLI ëª…ë ¹ì–´
â”‚   â”‚       â”‚   â”œâ”€â”€ __main__.py # ë©”ì¸ CLI ì§„ì…ì 
â”‚   â”‚       â”‚   â”œâ”€â”€ api_cli.py  # API ìˆ˜ì§‘ CLI
â”‚   â”‚       â”‚   â””â”€â”€ crawl_platforms_raw.py # í¬ë¡¤ë§ CLI
â”‚   â”‚       â”œâ”€â”€ crawlers/       # í¬ë¡¤ë§ ì„œë¹„ìŠ¤
â”‚   â”‚       â”‚   â”œâ”€â”€ base.py     # ê¸°ë³¸ í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤
â”‚   â”‚       â”‚   â”œâ”€â”€ so.py       # ì‚¬íšŒì£¼íƒ í¬ë¡¤ëŸ¬
â”‚   â”‚       â”‚   â”œâ”€â”€ co.py       # ê³µë™ì²´ì£¼íƒ í¬ë¡¤ëŸ¬
â”‚   â”‚       â”‚   â”œâ”€â”€ youth.py    # ì²­ë…„ì£¼íƒ í¬ë¡¤ëŸ¬
â”‚   â”‚       â”‚   â”œâ”€â”€ sh.py       # SH ê³µê³  í¬ë¡¤ëŸ¬
â”‚   â”‚       â”‚   â””â”€â”€ lh.py       # LH ê³µê³  í¬ë¡¤ëŸ¬
â”‚   â”‚       â”œâ”€â”€ public-api/       # ê³µê³µ API ìˆ˜ì§‘
â”‚   â”‚       â”‚   â”œâ”€â”€ run.py      # API ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”‚       â”‚   â”œâ”€â”€ api_client.py # API í´ë¼ì´ì–¸íŠ¸
â”‚   â”‚       â”‚   â”œâ”€â”€ config.py   # API ì„¤ì •
â”‚   â”‚       â”‚   â”œâ”€â”€ pipeline.py # ë°ì´í„° íŒŒì´í”„ë¼ì¸
â”‚   â”‚       â”‚   â”œâ”€â”€ transform.py # ë°ì´í„° ë³€í™˜
â”‚   â”‚       â”‚   â””â”€â”€ db.py       # ë°ì´í„° ì €ì¥
â”‚   â”‚       â”œâ”€â”€ parsers/        # ë°ì´í„° íŒŒì‹±
â”‚   â”‚       â”‚   â”œâ”€â”€ parsers.py      # HTML/JSON íŒŒì‹± (ì£¼íƒ ê³µê³  ë°ì´í„°)
â”‚   â”‚       â”‚   â””â”€â”€ data_analyzer.py # RAW ë°ì´í„° ë¶„ì„ ë° í†µê³„
â”‚   â”‚       â””â”€â”€ normalized/     # ë°ì´í„° ì •ì œ
â”‚   â”‚           â””â”€â”€ normalizer.py # ë°ì´í„° ì •ê·œí™”
â”‚   â”œâ”€â”€ db/                     # ë°ì´í„°ë² ì´ìŠ¤
â”‚   â”‚   â”œâ”€â”€ postgresql/         # PostgreSQL ìŠ¤í‚¤ë§ˆ
â”‚   â”‚   â””â”€â”€ db_manager.py       # DB ê´€ë¦¬
â”‚   â”œâ”€â”€ data/                   # ë°ì´í„° ì €ì¥ì†Œ
â”‚   â”‚   â”œâ”€â”€ raw/               # í¬ë¡¤ë§ ì›ë³¸ ë°ì´í„°
â”‚   â”‚   â”‚   â”œâ”€â”€ sohouse/       # ì‚¬íšŒì£¼íƒ ë°ì´í„°
â”‚   â”‚   â”‚   â”œâ”€â”€ cohouse/       # ê³µë™ì²´ì£¼íƒ ë°ì´í„°
â”‚   â”‚   â”‚   â””â”€â”€ youth/         # ì²­ë…„ì£¼íƒ ë°ì´í„°
â”‚   â”‚   â””â”€â”€ public-api/          # API ìˆ˜ì§‘ ë°ì´í„°
â”‚   â”‚       â”œâ”€â”€ openseoul/     # ì„œìš¸ ì—´ë¦°ë°ì´í„°
â”‚   â”‚       â””â”€â”€ localdata/     # ë¡œì»¬ë°ì´í„° í¬í„¸
â”‚   â”œâ”€â”€ logs/                   # ë¡œê·¸ íŒŒì¼
â”‚   â”œâ”€â”€ docs/                   # ë¬¸ì„œ
â”‚   â”œâ”€â”€ tests/                  # í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ config/                 # ì„¤ì • íŒŒì¼
â”‚   â””â”€â”€ src/                    # ì†ŒìŠ¤ ì½”ë“œ
â”‚       â””â”€â”€ cli/                # CLI ëª¨ë“ˆ
â”‚           â”œâ”€â”€ __main__.py     # ë©”ì¸ CLI ì§„ì…ì 
â”‚           â”œâ”€â”€ crawl_platforms.py  # í¬ë¡¤ë§ CLI
â”‚           â”œâ”€â”€ analyze_raw_data.py # ë¶„ì„ CLI
â”‚           â””â”€â”€ migrate_database.py # ë§ˆì´ê·¸ë ˆì´ì…˜ CLI
â”‚   â”œâ”€â”€ requirements.txt        # Python ì˜ì¡´ì„±
â”‚   â””â”€â”€ Dockerfile              # ë°±ì—”ë“œ Docker ì´ë¯¸ì§€
â”œâ”€â”€ frontend/                    # í”„ë¡ íŠ¸ì—”ë“œ (React)
â”‚   â”œâ”€â”€ src/                    # React ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”œâ”€â”€ public/                 # ì •ì  íŒŒì¼
â”‚   â”œâ”€â”€ package.json            # Node.js ì˜ì¡´ì„±
â”‚   â””â”€â”€ Dockerfile              # í”„ë¡ íŠ¸ì—”ë“œ Docker ì´ë¯¸ì§€
â”œâ”€â”€ nginx/                      # Nginx ì„¤ì •
â”‚   â””â”€â”€ nginx.conf              # ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ ì„¤ì •
â”œâ”€â”€ docker-compose.yml          # Docker Compose ì„¤ì •
â””â”€â”€ README.md                   # í”„ë¡œì íŠ¸ ë¬¸ì„œ
```

### ğŸ—ï¸ ì•„í‚¤í…ì²˜ ì„¤ê³„ ì›ì¹™

#### **1. ì—­í•  ë¶„ë‹´ (Separation of Concerns)**

- **BaseCrawler**: ê³µí†µ ê¸°ëŠ¥ë§Œ ë‹´ë‹¹, í”Œë«í¼ë³„ íŠ¹í™” ë¡œì§ ì œê±°
- **Platform Crawlers**: ê° í”Œë«í¼ë³„ íŠ¹í™” ë¡œì§ë§Œ ë‹´ë‹¹
- **Parsers**: ìˆœìˆ˜í•œ ë°ì´í„° íŒŒì‹±/ì •ì œ í•¨ìˆ˜ë“¤

#### **2. í™•ì¥ì„± (Extensibility)**

- ìƒˆë¡œìš´ í”Œë«í¼ ì¶”ê°€ ì‹œ BaseCrawler ìƒì†ë§Œ í•˜ë©´ ë¨
- ì¶”ìƒ ë©”ì„œë“œë¡œ í™•ì¥ì  ì œê³µ:
  - `_extract_platform_specific_fields()`
  - `_filter_json_fields()`
  - `_download_images_platform_specific()`
  - `_extract_csv_housing_fields()`

#### **3. ì½”ë“œ ì¤‘ë³µ ì œê±° (DRY Principle)**

- **SO/CO í¬ë¡¤ëŸ¬ í†µí•©**: ë™ì¼í•œ ë¡œì§ì„ `SoCoCrawler`ë¡œ í†µí•©
- **ë³„ì¹­ ì œê³µ**: ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•´ `SoHouseCrawler`, `CoHouseCrawler` ë³„ì¹­ ìœ ì§€
- **ìœ ì§€ë³´ìˆ˜ ìš©ì´**: í•œ ê³³ì—ì„œë§Œ ìˆ˜ì •í•˜ë©´ ë‘ í”Œë«í¼ ëª¨ë‘ ì ìš©

#### **4. ë‹¨ì¼ ì±…ì„ ì›ì¹™ (Single Responsibility)**

- ê° íŒŒì¼ì´ ëª…í™•í•œ í•˜ë‚˜ì˜ ì—­í• ë§Œ ë‹´ë‹¹
- í”Œë«í¼ë³„ ë¡œì§ì´ í•´ë‹¹ í¬ë¡¤ëŸ¬ì—ë§Œ ì¡´ì¬

## ğŸš€ ì‚¬ìš©ë²•

### 1. RAW í¬ë¡¤ë§ (í˜„ì¬ ìš°ì„ ìˆœìœ„)

```bash
# ëª¨ë“  í”Œë«í¼ í¬ë¡¤ë§ ì™„ë£Œ
python -m src.cli crawl all --fresh

# ë˜ëŠ” ê°œë³„ ì‹¤í–‰
python -m src.cli crawl sohouse --fresh
python -m src.cli crawl cohouse --fresh
python -m src.cli crawl youth --fresh
python -m src.cli crawl happy --fresh
python -m src.cli crawl lh-ann --fresh
python -m src.cli crawl sh-ann --fresh

# ê³µê³µë°ì´í„° í¬ë¡¤ë§
python scripts/crawl_public_raw.py rtms_all --from 2020 --to 2024
python scripts/crawl_public_raw.py landprice_files
```

### 1.1. SO/CO í¬ë¡¤ëŸ¬ í†µí•© ì‚¬ìš©ë²•

```python
# ì§ì ‘ ì‚¬ìš© (ê¶Œì¥)
from src.services.crawlers.so_co import SoCoCrawler
from src.services.crawlers.base import Progress

progress = Progress()

# ì‚¬íšŒì£¼íƒ í¬ë¡¤ë§
so_crawler = SoCoCrawler(progress, "sohouse")
so_crawler.crawl()

# ê³µë™ì²´ì£¼íƒ í¬ë¡¤ë§
co_crawler = SoCoCrawler(progress, "cohouse")
co_crawler.crawl()

# ê¸°ì¡´ ë°©ì‹ (í˜¸í™˜ì„± ìœ ì§€)
from src.services.crawlers.so_co import SoHouseCrawler, CoHouseCrawler

so_crawler = SoHouseCrawler(progress)  # sohouse
co_crawler = CoHouseCrawler(progress)  # cohouse
```

### 2. í¬ë¡¤ë§ ê¸°ëŠ¥ ê°œì„ ì‚¬í•­

#### **ğŸ“ í´ë” êµ¬ì¡° ê°œì„ **

- ë‚ ì§œë³„ í´ë” ìƒì„±: `data/raw/YYYY-MM-DD/platform_name/`
- ì¼ê´€ëœ ì¶œë ¥ êµ¬ì¡°ë¡œ ëª¨ë“  í”Œë«í¼ í†µì¼

#### **ğŸ”§ SO/CO í¬ë¡¤ëŸ¬ í†µí•©**

- **ì½”ë“œ ì¤‘ë³µ ì œê±°**: ë™ì¼í•œ ë¡œì§ì„ `SoCoCrawler`ë¡œ í†µí•©
- **í”Œë«í¼ íƒ€ì… ì„ íƒ**: `platform_type` ë§¤ê°œë³€ìˆ˜ë¡œ "sohouse" ë˜ëŠ” "cohouse" ì„ íƒ
- **í˜¸í™˜ì„± ìœ ì§€**: ê¸°ì¡´ `SoHouseCrawler`, `CoHouseCrawler` ë³„ì¹­ ì œê³µ
- **ìœ ì§€ë³´ìˆ˜ ê°œì„ **: í•œ ê³³ì—ì„œë§Œ ìˆ˜ì •í•˜ë©´ ë‘ í”Œë«í¼ ëª¨ë‘ ì ìš©

#### **ğŸ–¼ï¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ê°œì„ **

- **ì§‘ ì´ë¯¸ì§€ì™€ í‰ë©´ë„ êµ¬ë¶„ ì €ì¥**:
  - `images/`: ì§‘ ìƒì„¸ ì´ë¯¸ì§€
  - `floor_plans/`: í‰ë©´ë„ ì´ë¯¸ì§€
- **íŒŒì¼ëª… ê°œì„ **: `detail_0001_ì£¼íƒëª…_house_image_ìƒì„¸ì†Œê°œ_a1b2c3d4.jpg`
- **FK ì°¸ì¡° ê°€ëŠ¥**: íŒŒì¼ëª…ì— ì£¼íƒ ì •ë³´ í¬í•¨

#### **ğŸ“„ í…ìŠ¤íŠ¸ ì •ë¦¬**

- ìƒë‹¨ ë¶ˆí•„ìš”í•œ ë„¤ë¹„ê²Œì´ì…˜ ë©”ë‰´ ìë™ ì œê±°
- ì‹¤ì œ ì£¼íƒ ì •ë³´ë§Œ ì¶”ì¶œí•˜ì—¬ ì €ì¥

#### **ğŸ“ ì²¨ë¶€íŒŒì¼ í•„í„°ë§**

- ì‹¤ì œ ì²¨ë¶€íŒŒì¼ë§Œ ë‹¤ìš´ë¡œë“œ (HWP, PDF ë“±)
- HTMLê³¼ ì²¨ë¶€íŒŒì¼ êµ¬ë¶„ ì €ì¥

#### **ğŸ  ì£¼íƒ ë¶„ë¥˜ í•„ë“œ ì¶”ê°€**

- CSV ì»¬ëŸ¼ìœ¼ë¡œ ìŠ¹ê²©: `ì£¼íƒìœ í˜•`, `ì£¼ê±°í˜•íƒœ`, `ì§€í•˜ì² ì—­`, `êµí†µ`
- JSONì—ëŠ” ìƒˆë¡œìš´ ì •ë³´ë§Œ ì €ì¥ (ì¤‘ë³µ ì œê±°)

#### **ğŸ“Š í…Œì´ë¸” ë°ì´í„° ìµœì í™”**

- **occupancy í…Œì´ë¸”ë§Œ ì €ì¥**: `info_table_csv` ì¤‘ë³µ ì œê±°
- **ë°ì´í„° ì¼ê´€ì„±**: ì…ì£¼í˜„í™© í…Œì´ë¸”ë§Œ CSVë¡œ ì €ì¥í•˜ì—¬ ì¤‘ë³µ ë°©ì§€
- **ì €ì¥ ê³µê°„ ì ˆì•½**: ë¶ˆí•„ìš”í•œ info í…Œì´ë¸” ìƒì„± ì œê±°

### 3. ë°ì´í„° ë¶„ì„ (í¬ë¡¤ë§ ì™„ë£Œ í›„)

```bash
# í¬ë¡¤ë§ëœ ë°ì´í„° ë¶„ì„
python -m src.cli analyze
```

### 4. ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ (ë¶„ì„ í›„)

```bash
# ìƒˆë¡œìš´ í…Œì´ë¸” ìƒì„±
mysql -u root -p < db/create_tables_improved.sql

# ê¸°ì¡´ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
python -m src.cli migrate

# ë°ì´í„° ê²€ì¦
python -m src.cli.migrate_database --validate
```

## ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ (JSONB ê·œì¹™)

### í•µì‹¬ ì›ì¹™: Two-Lane Approach

1. **raw_payload (Lane A)**: ì›ë¬¸ ìŠ¤ëƒ…ìƒ· (ì¬í˜„Â·ê°ì‚¬ ìš©)

   - ì›ë³¸ API ì‘ë‹µ, íŒŒì‹±ëœ ë°ì´í„°
   - HTMLì€ ë³„ë„ ì €ì¥ì†Œì— ì €ì¥í•˜ê³  í•´ì‹œë¡œ ì°¸ì¡°
   - ë©”íƒ€ë°ì´í„° í¬í•¨ (URL, íŒŒì„œ ë²„ì „, ìˆ˜ì§‘ ì‹œê°)

2. **extra_attrs (Lane B)**: ì •ë¦¬ëœ ë°˜ì •í˜• í•„ë“œ

   - íƒ€ì…ì´ ì •í•´ì§„ ê°€ë²¼ìš´ ì‚¬ì „
   - ë‹¨ìœ„ í‘œì¤€í™” (ë©´ì ì€ ã¡, ê°€ê²©ì€ KRW)
   - ì–•ì€ ì¤‘ì²© (1-2 depth)
   - í”Œë«í¼ë³„ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ (sohouse*\*, lh*\*)

### ğŸ“Š ë°ì´í„° êµ¬ì¡° ê°œì„ ì‚¬í•­

#### **CSV ì»¬ëŸ¼ í™•ì¥**

- ê¸°ì¡´: `platform`, `house_name`, `address`, `image_paths` ë“±
- **ì‹ ê·œ ì¶”ê°€**: `ì£¼íƒìœ í˜•`, `ì£¼ê±°í˜•íƒœ`, `ì§€í•˜ì² ì—­`, `êµí†µ`
- **ì¤‘ë³µ ì œê±°**: CSVì— ìˆëŠ” í•„ë“œëŠ” JSONì—ì„œ ì œì™¸

#### **ì´ë¯¸ì§€ íŒŒì¼ êµ¬ì¡° ê°œì„ **

```
data/raw/2025-09-10/sohouse/
â”œâ”€â”€ images/                    # ì§‘ ìƒì„¸ ì´ë¯¸ì§€
â”‚   â””â”€â”€ detail_0001_ì£¼íƒëª…_house_image_ìƒì„¸ì†Œê°œ_a1b2c3d4.jpg
â”œâ”€â”€ floor_plans/              # í‰ë©´ë„ ì´ë¯¸ì§€
â”‚   â””â”€â”€ detail_0001_ì£¼íƒëª…_floor_plan_í‰ë©´ë„_b2c3d4e5.jpg
â””â”€â”€ attachments/              # ì²¨ë¶€íŒŒì¼ (HWP, PDF ë“±)
    â””â”€â”€ detail_0001_ê³µê³ ë¬¸.hwp
```

#### **í…ìŠ¤íŠ¸ ì •ë¦¬**

- ìƒë‹¨ ë„¤ë¹„ê²Œì´ì…˜ ë©”ë‰´ ìë™ ì œê±°
- ì‹¤ì œ ì£¼íƒ ì •ë³´ë§Œ ì¶”ì¶œí•˜ì—¬ ì €ì¥
- ë¶ˆí•„ìš”í•œ ë°˜ë³µ í…ìŠ¤íŠ¸ ì œê±°

### JSONB ë°ì´í„° ì˜ˆì‹œ

#### extra_attrs (ì •ë¦¬ëœ ë°ì´í„°)

```json
{
  "_meta": {
    "source": "sohouse",
    "schema": "v1",
    "fetched_at": "2025-01-15T10:00:00+09:00"
  },
  "room_count": 2,
  "floor": 5,
  "heating_type": "central",
  "pet_ok": false,
  "move_in_date": "2025-10-01",
  "amenities": ["laundry_room", "bike_storage"],
  "sohouse_notice_id": "SH-2025-00123"
}
```

#### raw_payload (ì›ë¬¸ ìŠ¤ëƒ…ìƒ·)

```json
{
  "_meta": {
    "url": "https://soco.seoul.go.kr/soHouse/...",
    "parser": "v1",
    "fetched_at": "2025-01-15T10:00:00+09:00"
  },
  "original_data": {
    "title": "ì„œìš¸ì‹œ ì‚¬íšŒì£¼íƒ ëª¨ì§‘ê³µê³ ",
    "address": "ì„œìš¸ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 123"
  },
  "html_ref": {
    "sha256": "abc123def456",
    "store": "s3://bucket/html/abc123def456"
  }
}
```

## ğŸ”§ ì£¼ìš” ê°œì„ ì‚¬í•­

### 1. ëª¨ë“ˆí™”

- **ì‹¤í–‰ ë¡œì§ê³¼ ì„œë¹„ìŠ¤ ë¡œì§ ë¶„ë¦¬**: CLIëŠ” ì‹¤í–‰ë§Œ, ì„œë¹„ìŠ¤ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
- **í”Œë«í¼ë³„ í¬ë¡¤ëŸ¬ ë¶„ë¦¬**: ê° í”Œë«í¼ë³„ë¡œ ë…ë¦½ì ì¸ í¬ë¡¤ëŸ¬
- **ê³µí†µ ê¸°ëŠ¥ ì¶”ìƒí™”**: BaseCrawler, ê³µí†µ ìœ í‹¸ë¦¬í‹°

### 2. JSONB í™œìš©

- **Two-Lane Approach**: raw_payload + extra_attrs
- **íƒ€ì… ì•ˆì „ì„±**: JSONB ë°ì´í„° ê²€ì¦
- **ì„±ëŠ¥ ìµœì í™”**: í•„ìš”í•œ ê²½ë¡œë§Œ ì¸ë±ì‹±
- **í™•ì¥ì„±**: ìƒˆë¡œìš´ í•„ë“œ ì¶”ê°€ ìš©ì´

### 3. ë°ì´í„° ë¬´ê²°ì„±

- **ì œì•½ ì¡°ê±´**: JSONB ë°ì´í„° íƒ€ì… ê²€ì¦
- **HTML ë¶„ë¦¬ ì €ì¥**: ëŒ€ìš©ëŸ‰ HTMLì€ ë³„ë„ í…Œì´ë¸”
- **ì¤‘ë³µ ë°©ì§€**: SHA256 ê¸°ë°˜ ì¤‘ë³µ ì œê±°

## ğŸ“Š êµ¬í˜„ëœ í¬ë¡¤ëŸ¬

- âœ… **ì‚¬íšŒì£¼íƒ (sohouse)**: ì™„ì „ êµ¬í˜„ (SoCoCrawler í†µí•©)
- âœ… **ê³µë™ì²´ì£¼íƒ (cohouse)**: ì™„ì „ êµ¬í˜„ (SoCoCrawler í†µí•©)
- ğŸ‘©ğŸ»â€ğŸ’» **ì²­ë…„ì£¼íƒ (youth)**: êµ¬í˜„ ì¤‘
- ğŸ‘©ğŸ»â€ğŸ’» **í–‰ë³µì£¼íƒ (happy)**: êµ¬í˜„ ì˜ˆì •
- ğŸ‘©ğŸ»â€ğŸ’» **SH ê³µê³  (sh-ann)**: êµ¬í˜„ ì˜ˆì •
- ğŸ‘©ğŸ»â€ğŸ’» **LH ê³µê³  (lh-ann)**: êµ¬í˜„ ì˜ˆì •

### ğŸ”§ SO/CO í¬ë¡¤ëŸ¬ í†µí•© ì¥ì 

#### **1. ì½”ë“œ ì¤‘ë³µ ì œê±°**

- ë™ì¼í•œ ë¡œì§ì„ `SoCoCrawler` í•˜ë‚˜ë¡œ í†µí•©
- ì•½ 400ì¤„ì˜ ì¤‘ë³µ ì½”ë“œ ì œê±°
- ìœ ì§€ë³´ìˆ˜ ë¹„ìš© 50% ê°ì†Œ

#### **2. ì¼ê´€ì„± ë³´ì¥**

- ë‘ í”Œë«í¼ì´ í•­ìƒ ë™ì¼í•œ ë¡œì§ ì‚¬ìš©
- ë²„ê·¸ ìˆ˜ì • ì‹œ í•œ ë²ˆë§Œ ìˆ˜ì •í•˜ë©´ ë‘ í”Œë«í¼ ëª¨ë‘ ì ìš©
- ê¸°ëŠ¥ ì¶”ê°€ ì‹œ ì¼ê´€ëœ ë™ì‘ ë³´ì¥

#### **3. í˜¸í™˜ì„± ìœ ì§€**

- ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • ì—†ì´ ì‚¬ìš© ê°€ëŠ¥
- `SoHouseCrawler`, `CoHouseCrawler` ë³„ì¹­ ì œê³µ
- ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ëŠ¥

#### **4. í™•ì¥ì„± í–¥ìƒ**

- ìƒˆë¡œìš´ í”Œë«í¼ íƒ€ì… ì¶”ê°€ ìš©ì´
- ê³µí†µ ë¡œì§ ì¬ì‚¬ìš© ê°€ëŠ¥
- í…ŒìŠ¤íŠ¸ ì½”ë“œ ì¤‘ë³µ ì œê±°

## ğŸ“‹ ë°ì´í„° êµ¬ì¡°

ê° í¬ë¡¤ëŸ¬ëŠ” ë‹¤ìŒ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤:

- **ì£¼íƒëª…**: ê³µê³ ëª… ë˜ëŠ” ì‹œì„¤ëª…
- **ì£¼ì†Œ**: ìƒì„¸ ì£¼ì†Œ ì •ë³´
- **ì…ì£¼íƒ€ì…**: ì›ë£¸, íˆ¬ë£¸ ë“±
- **ì…ì£¼ìê²©**: ì…ì£¼ ëŒ€ìƒì ì •ë³´
- **ì²¨ë¶€íŒŒì¼**: PDF, HWP ë“± ê³µê³  ê´€ë ¨ íŒŒì¼
- **ì´ë¯¸ì§€**: ê´€ë ¨ ì´ë¯¸ì§€ íŒŒì¼

## ğŸ“ ì¶œë ¥ í˜•ì‹

í¬ë¡¤ë§ ê²°ê³¼ëŠ” `data/raw/{platform}/` ë””ë ‰í† ë¦¬ì— ì €ì¥ë©ë‹ˆë‹¤:

```
data/raw/{platform}/
â”œâ”€â”€ raw.csv              # ë©”ì¸ ë°ì´í„° (CSV)
â”œâ”€â”€ html/               # HTML íŒŒì¼ë“¤
â”œâ”€â”€ images/             # ì´ë¯¸ì§€ íŒŒì¼ë“¤
â”œâ”€â”€ attachments/        # ì²¨ë¶€íŒŒì¼ë“¤
â””â”€â”€ tables/             # í…Œì´ë¸” ë°ì´í„° (CSV)
```

## ğŸ¯ ê°œë°œ ìƒíƒœ

### âœ… ì™„ë£Œëœ ì‘ì—…

#### **1. ì½”ë“œ êµ¬ì¡° ê°œì„ **

- âœ… BaseCrawlerì—ì„œ í”Œë«í¼ë³„ íŠ¹í™” ë¡œì§ ì œê±°
- âœ… ì—­í•  ë¶„ë‹´ ëª…í™•í™” (BaseCrawler, Platform Crawlers, Parsers)
- âœ… ì¶”ìƒ ë©”ì„œë“œë¡œ í™•ì¥ì„± í™•ë³´
- âœ… SO/CO í¬ë¡¤ëŸ¬ í†µí•©ìœ¼ë¡œ ì½”ë“œ ì¤‘ë³µ ì œê±°

#### **2. í¬ë¡¤ë§ ê¸°ëŠ¥ ê°œì„ **

- âœ… ë‚ ì§œë³„ í´ë” êµ¬ì¡° í†µì¼ (`data/raw/YYYY-MM-DD/platform_name/`)
- âœ… ì´ë¯¸ì§€ì™€ í‰ë©´ë„ êµ¬ë¶„ ì €ì¥
- âœ… íŒŒì¼ëª…ì— ì£¼íƒ ì •ë³´ í¬í•¨ (FK ì°¸ì¡° ê°€ëŠ¥)
- âœ… í…ìŠ¤íŠ¸ ìƒë‹¨ ë¶ˆí•„ìš”í•œ ë‚´ìš© ìë™ ì œê±°
- âœ… ì²¨ë¶€íŒŒì¼ í•„í„°ë§ ê°œì„ 
- âœ… ì£¼íƒ ë¶„ë¥˜ í•„ë“œ CSV ì»¬ëŸ¼ìœ¼ë¡œ ìŠ¹ê²©
- âœ… í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ì‹œì  ë¬¸ì œ í•´ê²° (detail_text ì§ì ‘ ì „ë‹¬)
- âœ… í…Œì´ë¸” ë°ì´í„° ìµœì í™” (info_table_csv ì¤‘ë³µ ì œê±°)

### ğŸ”„ í˜„ì¬ ì§„í–‰ ì¤‘

#### **RAW í¬ë¡¤ë§ ì™„ë£Œ**

```bash
# ê°„ë‹¨í•œ ì‹¤í–‰ (ê¶Œì¥)
python -m src.cli all --fresh

# ë˜ëŠ” ê°œë³„ ì‹¤í–‰
python -m src.cli crawl sohouse --fresh
python -m src.cli crawl cohouse --fresh
python -m src.cli crawl youth --fresh
python -m src.cli crawl happy --fresh
python -m src.cli crawl lh-ann --fresh
python -m src.cli crawl sh-ann --fresh
```

### ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„: ë°ì´í„° ë¶„ì„ (í¬ë¡¤ë§ ì™„ë£Œ í›„)

```bash
# í¬ë¡¤ë§ëœ ë°ì´í„° ë¶„ì„
python -m src.cli analyze
```

### 3ë‹¨ê³„: ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ í…Œì´ë¸” ì„¤ê³„

- ì‹¤ì œ ë°ì´í„°ë¥¼ ë³´ê³  ìµœì ì˜ í…Œì´ë¸” êµ¬ì¡° ê²°ì •

## ğŸ’¡ í•µì‹¬ ì›ì¹™

### **scripts/ (RAW ë‹¨ê³„)**

- ì›¹ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
- HTML, ì´ë¯¸ì§€, ì²¨ë¶€íŒŒì¼ ì €ì¥
- ê¸°ë³¸ì ì¸ ë°ì´í„° ì¶”ì¶œ

### **src/ (PARSED ë‹¨ê³„)**

- ìˆ˜ì§‘ëœ ë°ì´í„° ì •ì œ ë° êµ¬ì¡°í™”
- ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
- ë°ì´í„° ê²€ì¦ ë° ë¶„ì„
- ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì²˜ë¦¬

## ğŸ“¦ ì˜ì¡´ì„±

- Python 3.8+
- Playwright
- BeautifulSoup4
- PyYAML
- PyMySQL

## ğŸ”§ ì„¤ì¹˜

```bash
pip install -r requirements.txt
playwright install chromium
```

## ğŸ“š ë¬¸ì„œ

- `parsed_README.md`: PARSED ë‹¨ê³„ ì‘ì—… ê°€ì´ë“œ
- `í¬ë¡¤ë§_ë°ì´í„°_ê²€ì¦_ë¦¬í¬íŠ¸.md`: ë°ì´í„° ê²€ì¦ ë¦¬í¬íŠ¸

## ğŸ³ Docker & PostgreSQL ì•„í‚¤í…ì²˜

### ë°±ì—”ë“œ/í”„ë¡ íŠ¸ì—”ë“œ ë¶„ë¦¬ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   Backend       â”‚    â”‚   PostgreSQL    â”‚
â”‚   (React)       â”‚â—„â”€â”€â–ºâ”‚   (FastAPI)     â”‚â—„â”€â”€â–ºâ”‚   Database      â”‚
â”‚   Port: 3000    â”‚    â”‚   Port: 8000    â”‚    â”‚   Port: 5432    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Nginx         â”‚    â”‚   Redis         â”‚    â”‚   Grafana       â”‚
â”‚   (Reverse      â”‚    â”‚   (Cache)       â”‚    â”‚   (Monitoring)  â”‚
â”‚   Proxy)        â”‚    â”‚   Port: 6379    â”‚    â”‚   Port: 3001    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸš€ Docker ì‹¤í–‰

```bash
# ì „ì²´ ìŠ¤íƒ ì‹¤í–‰
docker-compose up -d

# íŠ¹ì • ì„œë¹„ìŠ¤ë§Œ ì‹¤í–‰
docker-compose up -d postgres redis backend

# ë¡œê·¸ í™•ì¸
docker-compose logs -f backend

# ì„œë¹„ìŠ¤ ì¤‘ì§€
docker-compose down
```

### ğŸ—„ï¸ PostgreSQL íŠ¹ì§•

- **JSONB ì§€ì›**: ì›ë³¸ ë°ì´í„°ì™€ ì •ë¦¬ëœ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥
- **ì „ì²´ í…ìŠ¤íŠ¸ ê²€ìƒ‰**: í•œêµ­ì–´ ì§€ì›ìœ¼ë¡œ ì£¼íƒëª…, ì£¼ì†Œ ê²€ìƒ‰ ìµœì í™”
- **ë°°ì—´ íƒ€ì…**: ì´ë¯¸ì§€ ê²½ë¡œ, ì²¨ë¶€íŒŒì¼ ê²½ë¡œë¥¼ ë°°ì—´ë¡œ ì €ì¥
- **ì¸ë±ì‹±**: GIN ì¸ë±ìŠ¤ë¡œ JSONBì™€ ê²€ìƒ‰ ë²¡í„° ìµœì í™”
- **íŠ¸ë¦¬ê±°**: ìë™ ì—…ë°ì´íŠ¸ ì‹œê°„ ë° ê²€ìƒ‰ ë²¡í„° ê´€ë¦¬

### ğŸ”§ ê°œë°œ í™˜ê²½ ì„¤ì •

```bash
# 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
cp env.example .env

# 2. Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker-compose up -d

# 3. ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ (MySQL â†’ PostgreSQL)
python scripts/migrate_to_postgresql.py

# 4. ë°±ì—”ë“œ API ë¬¸ì„œ í™•ì¸
open http://localhost:8000/docs

# 5. í”„ë¡ íŠ¸ì—”ë“œ í™•ì¸
open http://localhost:3000
```

## ğŸ“ ë³€ê²½ ë¡œê·¸

### v1.5.1 (2025-01-15) - í…Œì´ë¸” ë°ì´í„° ìµœì í™”

#### ğŸ”§ ê°œì„ ì‚¬í•­

- **í…Œì´ë¸” ì¤‘ë³µ ì œê±°**: `info_table_csv`ì™€ `occupancy_table_csv` ì¤‘ë³µ ë¬¸ì œ í•´ê²°
- **occupancy í…Œì´ë¸”ë§Œ ì €ì¥**: ì…ì£¼í˜„í™© í…Œì´ë¸”ë§Œ CSVë¡œ ì €ì¥í•˜ì—¬ ë°ì´í„° ì¼ê´€ì„± í–¥ìƒ
- **ì €ì¥ ê³µê°„ ì ˆì•½**: ë¶ˆí•„ìš”í•œ info í…Œì´ë¸” ìƒì„± ì œê±°ë¡œ ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
- **ë°ì´í„° ì •í•©ì„±**: ë™ì¼í•œ ì •ë³´ê°€ ì—¬ëŸ¬ í…Œì´ë¸”ì— ì¤‘ë³µ ì €ì¥ë˜ëŠ” ë¬¸ì œ í•´ê²°

### v1.5.0 (2025-01-15) - src.cli í†µí•© ì•„í‚¤í…ì²˜

#### âœ¨ ìƒˆë¡œìš´ ê¸°ëŠ¥

- **src.cli í†µí•©**: ëª¨ë“  í¬ë¡¤ë§ì„ `src.cli` ëª¨ë“ˆë¡œ í†µí•© ê´€ë¦¬
- **main.py ê°„ì†Œí™”**: `main.py`ê°€ `src.cli` ëª¨ë“ˆë“¤ì„ í˜¸ì¶œí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë³€ê²½
- **ì¼ê´€ëœ ì‹¤í–‰ ë°©ì‹**: `python -m src.cli` ëª…ë ¹ì–´ë¡œ ëª¨ë“  ê¸°ëŠ¥ ì‹¤í–‰
- **ì§ì ‘ CLI ì‹¤í–‰**: `python -m src.cli` ë°©ì‹ìœ¼ë¡œ ê°œë³„ ëª¨ë“ˆ ì‹¤í–‰ ê°€ëŠ¥

#### ğŸ”§ ê°œì„ ì‚¬í•­

- **ì½”ë“œ ì¤‘ë³µ ì œê±°**: `main.py`ì—ì„œ ì¤‘ë³µëœ í¬ë¡¤ë§ ë¡œì§ ì œê±°
- **ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ**: `src.cli` ëª¨ë“ˆì—ì„œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê´€ë¦¬
- **í™•ì¥ì„± í–¥ìƒ**: ìƒˆë¡œìš´ CLI ëª¨ë“ˆ ì¶”ê°€ ì‹œ `main.py` ìˆ˜ì • ìµœì†Œí™”
- **ì¼ê´€ëœ ì‚¬ìš©ë²•**: READMEì˜ ëª¨ë“  ëª…ë ¹ì–´ê°€ `python -m src.cli` ë°©ì‹ìœ¼ë¡œ í†µì¼

### v1.4.0 (2025-01-15) - Docker & PostgreSQL ì•„í‚¤í…ì²˜

#### âœ¨ ìƒˆë¡œìš´ ê¸°ëŠ¥

- **Docker ì»¨í…Œì´ë„ˆí™”**: ì „ì²´ ìŠ¤íƒì„ Dockerë¡œ í†µí•© ê´€ë¦¬
- **PostgreSQL ë§ˆì´ê·¸ë ˆì´ì…˜**: MySQLì—ì„œ PostgreSQLë¡œ ë°ì´í„°ë² ì´ìŠ¤ ì „í™˜
- **ë°±ì—”ë“œ/í”„ë¡ íŠ¸ì—”ë“œ ë¶„ë¦¬**: FastAPI + React ì•„í‚¤í…ì²˜
- **Nginx ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ**: APIì™€ ì›¹ ì„œë²„ í†µí•© ê´€ë¦¬
- **Redis ìºì‹±**: ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ìºì‹± ë ˆì´ì–´
- **Grafana ëª¨ë‹ˆí„°ë§**: ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ë° ëŒ€ì‹œë³´ë“œ

#### ğŸ”§ ê°œì„ ì‚¬í•­

- **JSONB ìµœì í™”**: PostgreSQLì˜ JSONB íƒ€ì…ìœ¼ë¡œ ë°ì´í„° ì €ì¥ íš¨ìœ¨ì„± í–¥ìƒ
- **ì „ì²´ í…ìŠ¤íŠ¸ ê²€ìƒ‰**: í•œêµ­ì–´ ì§€ì› ê²€ìƒ‰ ê¸°ëŠ¥
- **ìë™ ìŠ¤ì¼€ì¼ë§**: Docker Composeë¡œ ì„œë¹„ìŠ¤ í™•ì¥ ìš©ì´
- **ë³´ì•ˆ ê°•í™”**: Nginxë¥¼ í†µí•œ ë³´ì•ˆ í—¤ë” ë° SSL ì§€ì›
- **ê°œë°œ í™˜ê²½ í†µì¼**: Dockerë¡œ ê°œë°œ/í”„ë¡œë•ì…˜ í™˜ê²½ ì¼ì¹˜

### v1.3.0 (2025-01-15) - ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ í†µí•©

#### âœ¨ ìƒˆë¡œìš´ ê¸°ëŠ¥

- **main.py í†µí•©**: ëª¨ë“  í¬ë¡¤ë§ì„ í•˜ë‚˜ì˜ ìŠ¤í¬ë¦½íŠ¸ë¡œ í†µí•©
- **all ì˜µì…˜**: ëª¨ë“  í”Œë«í¼ì„ í•œ ë²ˆì— í¬ë¡¤ë§í•˜ëŠ” `all` ì˜µì…˜ ì¶”ê°€
- **ê°„ë‹¨í•œ ì‚¬ìš©ë²•**: `python main.py platform --fresh` í˜•íƒœë¡œ ë‹¨ìˆœí™”

#### ğŸ”§ ê°œì„ ì‚¬í•­

- **ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ**: ë³µì¡í•œ ëª¨ë“ˆ ê²½ë¡œ ëŒ€ì‹  ê°„ë‹¨í•œ ëª…ë ¹ì–´ ì‚¬ìš©
- **ì—ëŸ¬ ì²˜ë¦¬**: EPIPE ì˜¤ë¥˜ ì¬ì‹œë„ ë¡œì§ í¬í•¨
- **ì§„í–‰ ìƒí™© í‘œì‹œ**: ê° í”Œë«í¼ë³„ í¬ë¡¤ë§ ì§„í–‰ ìƒí™© ëª…í™•íˆ í‘œì‹œ
- **í˜¸í™˜ì„± ìœ ì§€**: ê¸°ì¡´ `src/cli`ì™€ `scripts` ë°©ì‹ ëª¨ë‘ ì§€ì›

### v1.2.0 (2025-01-15) - SO/CO í¬ë¡¤ëŸ¬ í†µí•©

#### âœ¨ ìƒˆë¡œìš´ ê¸°ëŠ¥

- **SO/CO í¬ë¡¤ëŸ¬ í†µí•©**: `SoCoCrawler` í´ë˜ìŠ¤ë¡œ ì‚¬íšŒì£¼íƒê³¼ ê³µë™ì²´ì£¼íƒ í¬ë¡¤ëŸ¬ í†µí•©
- **í”Œë«í¼ íƒ€ì… ì„ íƒ**: `platform_type` ë§¤ê°œë³€ìˆ˜ë¡œ "sohouse" ë˜ëŠ” "cohouse" ì„ íƒ ê°€ëŠ¥
- **í˜¸í™˜ì„± ë³„ì¹­**: ê¸°ì¡´ `SoHouseCrawler`, `CoHouseCrawler` ë³„ì¹­ ì œê³µ

#### ğŸ”§ ê°œì„ ì‚¬í•­

- **ì½”ë“œ ì¤‘ë³µ ì œê±°**: ì•½ 400ì¤„ì˜ ì¤‘ë³µ ì½”ë“œ ì œê±°
- **í…ìŠ¤íŠ¸ íŒŒì¼ ë¬¸ì œ í•´ê²°**: `detail_text` ë§¤ê°œë³€ìˆ˜ë¥¼ ì§ì ‘ ì „ë‹¬í•˜ì—¬ ìƒì„± ì‹œì  ë¬¸ì œ í•´ê²°
- **ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ**: í•œ ê³³ì—ì„œë§Œ ìˆ˜ì •í•˜ë©´ ë‘ í”Œë«í¼ ëª¨ë‘ ì ìš©
- **ì¼ê´€ì„± ë³´ì¥**: ë‘ í”Œë«í¼ì´ í•­ìƒ ë™ì¼í•œ ë¡œì§ ì‚¬ìš©

#### ğŸ› ë²„ê·¸ ìˆ˜ì •

- í…ìŠ¤íŠ¸ íŒŒì¼ì´ ìƒì„±ë˜ê¸° ì „ì— ì ‘ê·¼í•˜ë ¤ë˜ ë¬¸ì œ í•´ê²°
- `_extract_platform_specific_fields` ë©”ì„œë“œì— `detail_text` ë§¤ê°œë³€ìˆ˜ ì¶”ê°€

### v1.2.0 (2025-09-18) - API ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ êµ¬ì¶•

#### âœ¨ ìƒˆë¡œìš´ ê¸°ëŠ¥

- **API ë°ì´í„° ìˆ˜ì§‘**: ì„œìš¸ ì—´ë¦°ë°ì´í„°ê´‘ì¥ API í†µí•©
- **ë¡œì»¬ë°ì´í„° í¬í„¸**: ë¡œì»¬ë°ì´í„° í¬í„¸ API ì§€ì›
- **CLI ëª…ë ¹ì–´**: `data_collection api` ëª…ë ¹ì–´ë¡œ API ë°ì´í„° ìˆ˜ì§‘
- **ìë™ ì €ì¥**: CSV í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ìë™ ì €ì¥
- **í™˜ê²½ë³€ìˆ˜ ì§€ì›**: `.env` íŒŒì¼ì„ í†µí•œ API í‚¤ ê´€ë¦¬

#### ğŸ”§ ê°œì„ ì‚¬í•­

- **Import ì˜¤ë¥˜ í•´ê²°**: ìƒëŒ€ import ë¬¸ ìˆ˜ì •
- **ê²½ë¡œ ë¬¸ì œ í•´ê²°**: ë°ì´í„° ì €ì¥ ê²½ë¡œ ì •ê·œí™”
- **ì—ëŸ¬ ì²˜ë¦¬**: XML ì‘ë‹µ ë° API ì˜¤ë¥˜ ì²˜ë¦¬ ê°œì„ 
- **ë¬¸ì„œí™”**: README ì—…ë°ì´íŠ¸ ë° ì„¤ì¹˜ ê°€ì´ë“œ ì¶”ê°€

#### ğŸ“Š ìˆ˜ì§‘ ê°€ëŠ¥í•œ ë°ì´í„°

- **ì„œìš¸ ì—´ë¦°ë°ì´í„°**: ì§€í•˜ì² ì—­, ì•½êµ­, ì–´ë¦°ì´ì§‘, í•™êµ, ê³µì› ì •ë³´
- **ë¡œì»¬ë°ì´í„° í¬í„¸**: ë³€ë™ë¶„ ë°ì´í„° (API ê¶Œí•œ í•„ìš”)

### v1.1.0 (2025-01-10) - í¬ë¡¤ë§ ê¸°ëŠ¥ ê°œì„ 

#### âœ¨ ìƒˆë¡œìš´ ê¸°ëŠ¥

- ë‚ ì§œë³„ í´ë” êµ¬ì¡° í†µì¼
- ì´ë¯¸ì§€ì™€ í‰ë©´ë„ êµ¬ë¶„ ì €ì¥
- ì£¼íƒ ë¶„ë¥˜ í•„ë“œ CSV ì»¬ëŸ¼ìœ¼ë¡œ ìŠ¹ê²©

#### ğŸ”§ ê°œì„ ì‚¬í•­

- íŒŒì¼ëª…ì— ì£¼íƒ ì •ë³´ í¬í•¨ (FK ì°¸ì¡° ê°€ëŠ¥)
- í…ìŠ¤íŠ¸ ìƒë‹¨ ë¶ˆí•„ìš”í•œ ë‚´ìš© ìë™ ì œê±°
- ì²¨ë¶€íŒŒì¼ í•„í„°ë§ ê°œì„ 
