#!/usr/bin/env python3
"""
ì¤‘ë³µ ì œê±° ë¡œì§ í…ŒìŠ¤íŠ¸
"""

import json
from pathlib import Path

def extract_unique_addresses(failed_jsonl_path: Path) -> dict:
    """JSONL íŒŒì¼ì—ì„œ ì¤‘ë³µ ì œê±°í•˜ì—¬ ê³ ìœ í•œ ì£¼ì†Œë§Œ ì¶”ì¶œ"""
    unique_addresses = {}
    
    with open(failed_jsonl_path, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            if line.strip():
                try:
                    failed_data = json.loads(line.strip())
                    # ê³ ìœ  í‚¤: facility_type + facility_name + address_raw
                    unique_key = f"{failed_data['facility_type']}|{failed_data['facility_name']}|{failed_data['address_raw']}"
                    
                    if unique_key not in unique_addresses:
                        unique_addresses[unique_key] = failed_data
                except json.JSONDecodeError:
                    continue
    
    return unique_addresses

def count_lines(file_path: Path) -> int:
    """íŒŒì¼ì˜ ì´ ë¼ì¸ ìˆ˜ ê³„ì‚°"""
    count = 0
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                count += 1
    return count

def get_duplicate_count(failed_jsonl_path: Path, facility_key: str) -> int:
    """íŠ¹ì • facility_keyì˜ ì¤‘ë³µ ê°œìˆ˜ ê³„ì‚°"""
    count = 0
    facility_type, facility_name, address_raw = facility_key.split('|', 2)
    
    with open(failed_jsonl_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                try:
                    failed_data = json.loads(line.strip())
                    if (failed_data['facility_type'] == facility_type and 
                        failed_data['facility_name'] == facility_name and 
                        failed_data['address_raw'] == address_raw):
                        count += 1
                except json.JSONDecodeError:
                    continue
    
    return count

if __name__ == "__main__":
    failed_jsonl_path = Path("data/normalized/infra/failed_addresses.jsonl")
    
    if not failed_jsonl_path.exists():
        print(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {failed_jsonl_path}")
        exit(1)
    
    print("ğŸ” ì¤‘ë³µ ì œê±° í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # ì „ì²´ ë¼ì¸ ìˆ˜
    total_lines = count_lines(failed_jsonl_path)
    print(f"ğŸ“Š ì „ì²´ ë¼ì¸ ìˆ˜: {total_lines}")
    
    # ê³ ìœ í•œ ì£¼ì†Œ ì¶”ì¶œ
    unique_addresses = extract_unique_addresses(failed_jsonl_path)
    unique_count = len(unique_addresses)
    print(f"ğŸ“Š ê³ ìœ í•œ ì£¼ì†Œ ìˆ˜: {unique_count}")
    print(f"ğŸ“Š ì¤‘ë³µ ì œê±°ìœ¨: {((total_lines - unique_count) / total_lines * 100):.1f}%")
    
    # ìƒìœ„ 10ê°œ ì¤‘ë³µ ë°ì´í„° í™•ì¸
    print("\nğŸ” ìƒìœ„ 10ê°œ ì¤‘ë³µ ë°ì´í„°:")
    duplicate_counts = []
    for facility_key in unique_addresses.keys():
        dup_count = get_duplicate_count(failed_jsonl_path, facility_key)
        if dup_count > 1:
            duplicate_counts.append((facility_key, dup_count))
    
    # ì¤‘ë³µ ê°œìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    duplicate_counts.sort(key=lambda x: x[1], reverse=True)
    
    for i, (facility_key, dup_count) in enumerate(duplicate_counts[:10], 1):
        facility_type, facility_name, address_raw = facility_key.split('|', 2)
        print(f"{i:2d}. {facility_name} ({facility_type}) - {dup_count}íšŒ ì¤‘ë³µ")
        print(f"    ì£¼ì†Œ: {address_raw}")
    
    print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {len(duplicate_counts)}ê°œ ì£¼ì†Œê°€ ì¤‘ë³µë¨")
