import requests
import xml.etree.ElementTree as ET
import csv
import time
import logging
import os
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ğŸ”‘ ì¸ì¦í‚¤ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
API_KEY = os.getenv('SEOUL_API_KEY')
if not API_KEY:
    logger.error("SEOUL_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    exit(1)

# ğŸ“‹ ë‹¤ìš´ë¡œë“œí•  ì„œë¹„ìŠ¤ ëª©ë¡
SERVICES = [
    "busStopLocationXyInfo",      # ë²„ìŠ¤ì •ë¥˜ì¥ ìœ„ì¹˜ì •ë³´
    "subwayStationMaster",        # ì§€í•˜ì² ì—­ ë§ˆìŠ¤í„°ì •ë³´
    "ChildCareInfo",              # ì–´ë¦°ì´ì§‘ ì •ë³´
    "childSchoolInfo",            # ìœ ì¹˜ì› ì •ë³´
    "neisSchoolInfo",             # ì´ˆì¤‘ê³ ë“±í•™êµ ì •ë³´
    "SearchParkInfoService",      # ê³µì› ì •ë³´
    "SearchSTNBySubwayLineInfo",  # ì§€í•˜ì² ì—­ ì •ë³´
    "SebcCollegeInfoKor",         # ëŒ€í•™êµ ì •ë³´
    "StationAdresTelno",          # ì§€í•˜ì² ì—­ ì£¼ì†Œ/ì „í™”ë²ˆí˜¸
    "TbPharmacyOperateInfo"       # ì•½êµ­ ìš´ì˜ì •ë³´
]

TYPE = "xml"

# ğŸ’¡ í•œ ë²ˆì— ê°€ì ¸ì˜¬ ë°ì´í„° ìˆ˜ (ì„œìš¸ì‹œ ê¸°ì¤€ max 1000 ì´í•˜ ê¶Œì¥)
PAGE_SIZE = 1000

def fetch_total_count(service):
    """ì „ì²´ ë°ì´í„° ê±´ìˆ˜ ì¡°íšŒ"""
    url = f"http://openapi.seoul.go.kr:8088/{API_KEY}/{TYPE}/{service}/1/5"
    try:
        logger.info(f"ì „ì²´ ê±´ìˆ˜ ì¡°íšŒ ì¤‘: {url}")
        res = requests.get(url, timeout=30)
        res.raise_for_status()
        root = ET.fromstring(res.content)
        total = root.findtext(".//list_total_count")
        if total:
            logger.info(f"ì „ì²´ ê±´ìˆ˜: {total}")
            return int(total)
        else:
            logger.error("ì „ì²´ ê±´ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return 0
    except requests.RequestException as e:
        logger.error(f"API ìš”ì²­ ì‹¤íŒ¨: {e}")
        return 0
    except ET.ParseError as e:
        logger.error(f"XML íŒŒì‹± ì‹¤íŒ¨: {e}")
        return 0

def fetch_data(service, start_index, end_index):
    """ì§€ì •ëœ ë²”ìœ„ì˜ ë°ì´í„° ì¡°íšŒ"""
    url = f"http://openapi.seoul.go.kr:8088/{API_KEY}/{TYPE}/{service}/{start_index}/{end_index}"
    try:
        logger.info(f"ë°ì´í„° ì¡°íšŒ ì¤‘: {start_index}~{end_index}")
        res = requests.get(url, timeout=30)
        res.raise_for_status()
        root = ET.fromstring(res.content)
        
        # API ì˜¤ë¥˜ ì²´í¬
        result = root.find(".//RESULT")
        if result is not None:
            code = result.findtext("CODE")
            message = result.findtext("MESSAGE")
            if code != "INFO-000":
                logger.error(f"API ì˜¤ë¥˜: {code} - {message}")
                return []
        
        rows = []
        for row in root.iter("row"):
            row_data = {child.tag: child.text for child in row}
            rows.append(row_data)
        
        logger.info(f"ì¡°íšŒëœ ë°ì´í„°: {len(rows)}ê±´")
        return rows
        
    except requests.RequestException as e:
        logger.error(f"API ìš”ì²­ ì‹¤íŒ¨: {e}")
        return []
    except ET.ParseError as e:
        logger.error(f"XML íŒŒì‹± ì‹¤íŒ¨: {e}")
        return []

def save_to_csv(all_rows, filename):
    """ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
    if not all_rows:
        logger.warning("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    try:
        with open(filename, "w", newline="", encoding="utf-8-sig") as f:
            writer = csv.DictWriter(f, fieldnames=all_rows[0].keys())
            writer.writeheader()
            writer.writerows(all_rows)
        logger.info(f"ì´ {len(all_rows)}ê±´ ì €ì¥ ì™„ë£Œ: {filename}")
        return True
    except Exception as e:
        logger.error(f"CSV ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def download_service_data(service):
    """ê°œë³„ ì„œë¹„ìŠ¤ ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
    logger.info(f"ğŸ“¡ {service} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    
    # ì „ì²´ ê±´ìˆ˜ ì¡°íšŒ
    total_count = fetch_total_count(service)
    if total_count == 0:
        logger.warning(f"âš ï¸ {service}: ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    logger.info(f"ğŸ” {service} ì „ì²´ ê±´ìˆ˜: {total_count}")

    # ë°ì´í„° ìˆ˜ì§‘
    all_rows = []
    for start in range(1, total_count + 1, PAGE_SIZE):
        end = min(start + PAGE_SIZE - 1, total_count)
        logger.info(f"ğŸ“¦ {service} {start} ~ {end} ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        
        rows = fetch_data(service, start, end)
        if rows:
            all_rows.extend(rows)
        else:
            logger.warning(f"âš ï¸ {service} {start}~{end} ë²”ìœ„ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
        
        time.sleep(0.3)  # ê³¼ë„í•œ ìš”ì²­ ë°©ì§€ (ì„œìš¸ì‹œ ì„œë²„ì— ì˜ˆì˜ ìˆê²Œ)

    if not all_rows:
        logger.error(f"âŒ {service}: ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì • (í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ê²Œ)
    output_dir = Path(__file__).resolve().parents[3] / "data" / "public-api" / "openseoul"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # íŒŒì¼ëª…ì— íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
    timestamp = datetime.now().strftime("%Y%m%d")
    filename = f"seoul_{service}_{timestamp}.csv"
    output_path = output_dir / filename
    
    # CSV ì €ì¥
    if save_to_csv(all_rows, str(output_path)):
        logger.info(f"âœ… {service} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(all_rows)}ê±´")
        return True
    else:
        logger.error(f"âŒ {service} CSV ì €ì¥ ì‹¤íŒ¨")
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ğŸš€ ì„œìš¸ì‹œ ê³µê³µë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    
    success_count = 0
    total_count = len(SERVICES)
    
    for i, service in enumerate(SERVICES, 1):
        logger.info(f"ğŸ“Š ì§„í–‰ë¥ : {i}/{total_count} - {service}")
        
        if download_service_data(service):
            success_count += 1
        
        logger.info("-" * 50)  # êµ¬ë¶„ì„ 
    
    logger.info(f"ğŸ‰ ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ: {success_count}/{total_count} ì„œë¹„ìŠ¤ ì„±ê³µ")

if __name__ == "__main__":
    main()
