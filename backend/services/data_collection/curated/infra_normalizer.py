#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì¸í”„ë¼ ë°ì´í„° ì •ê·œí™” ëª¨ë“ˆ
ì„œìš¸ ì—´ë¦°ë°ì´í„°ê´‘ì¥ API ë°ì´í„°ë¥¼ infra ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ì •ê·œí™”
"""

import pandas as pd
from pathlib import Path
import os
from typing import List, Dict, Optional, Any
import logging
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

from backend.services.data_collection.curated.address_api import normalize_address, AddressNormalizerError

logger = logging.getLogger(__name__)

def preprocess_address(addr_raw: str) -> str:
    """ì£¼ì†Œ ì „ì²˜ë¦¬ - JUSO API ë§¤ì¹­ë¥  í–¥ìƒì„ ìœ„í•œ ì •ë¦¬"""
    if not addr_raw:
        return addr_raw
    
    import re
    
    # 0. ì¤‘ë³µ ì£¼ì†Œ ì œê±° (ê°€ì¥ ë¨¼ì € ì ìš©)
    # ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ ì–‘ì²œêµ¬ ëª©ë™ì¤‘ì•™ë³¸ë¡œ20ê¸¸33 (ëª©ë™, ëª©ë™ê³¨ë“ ë¹Œ) ì„œìš¸íŠ¹ë³„ì‹œ ì–‘ì²œêµ¬ ëª©ë™ì¤‘ì•™ë³¸ë¡œ20ê¸¸33 (ëª©ë™, ëª©ë™ê³¨ë“ ë¹Œ)" 
    # -> "ì„œìš¸íŠ¹ë³„ì‹œ ì–‘ì²œêµ¬ ëª©ë™ì¤‘ì•™ë³¸ë¡œ20ê¸¸33 (ëª©ë™, ëª©ë™ê³¨ë“ ë¹Œ)"
    # ë” ì •í™•í•œ ì¤‘ë³µ ì œê±°: ìµœì†Œ 5ê¸€ì ì´ìƒì˜ ì˜ë¯¸ìˆëŠ” ì¤‘ë³µë§Œ ì œê±°
    addr_raw = re.sub(r'(.{5,}?)\s+\1\s*.*$', r'\1', addr_raw)  # ê³µë°± ìˆëŠ” ì¤‘ë³µ (5ê¸€ì ì´ìƒ)
    # ê³µë°± ì—†ëŠ” ì¤‘ë³µì€ ë” ì—„ê²©í•˜ê²Œ: ìµœì†Œ 10ê¸€ì ì´ìƒ
    addr_raw = re.sub(r'(.{10,}?)\1.*$', r'\1', addr_raw)  # ê³µë°± ì—†ëŠ” ì¤‘ë³µ (10ê¸€ì ì´ìƒ)
    
    # 0-1. ì¤‘ë³µ ì£¼ì†Œ ì œê±° (ë” ê°„ë‹¨í•˜ê³  íš¨ê³¼ì ì¸ ë°©ë²•)
    # ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ ì–‘ì²œêµ¬ ëª©ë™ì¤‘ì•™ë³¸ë¡œ20ê¸¸33 (ëª©ë™, ëª©ë™ê³¨ë“ ë¹Œ) ì„œìš¸íŠ¹ë³„ì‹œ ì–‘ì²œêµ¬ ëª©ë™ì¤‘ì•™ë³¸ë¡œ20ê¸¸33 (ëª©ë™, ëª©ë™ê³¨ë“ ë¹Œ)"
    # -> "ì„œìš¸íŠ¹ë³„ì‹œ ì–‘ì²œêµ¬ ëª©ë™ì¤‘ì•™ë³¸ë¡œ20ê¸¸33 (ëª©ë™, ëª©ë™ê³¨ë“ ë¹Œ)"
    
    # ì„œìš¸íŠ¹ë³„ì‹œë¡œ ì‹œì‘í•˜ëŠ” ì£¼ì†Œì˜ ì¤‘ë³µ ì œê±°
    addr_raw = re.sub(r'(ì„œìš¸íŠ¹ë³„ì‹œ\s+[^ì„œìš¸íŠ¹ë³„ì‹œ]*?)\s+ì„œìš¸íŠ¹ë³„ì‹œ\s+.*$', r'\1', addr_raw)
    
    # ì„œìš¸ë¡œ ì‹œì‘í•˜ëŠ” ì£¼ì†Œì˜ ì¤‘ë³µ ì œê±°
    addr_raw = re.sub(r'(ì„œìš¸\s+[^ì„œìš¸]*?)\s+ì„œìš¸\s+.*$', r'\1', addr_raw)
    
    # 1. ê±´ë¬¼ë²ˆí˜¸ê°€ ë¹„ì •ìƒì ìœ¼ë¡œ í° ê²½ìš° ìˆ˜ì • (ì˜ˆ: 217 912 -> 217)
    # ë„ë¡œëª… + ê±´ë¬¼ë²ˆí˜¸ íŒ¨í„´ ì°¾ê¸°
    road_pattern = r'([ê°€-í£]+ë¡œ\d*[ê°€-í£]*)\s+(\d+)\s+(\d{3,})'
    match = re.search(road_pattern, addr_raw)
    if match:
        road_name = match.group(1)
        building_num = match.group(2)
        large_num = match.group(3)
        # í° ë²ˆí˜¸ë¥¼ ì œê±°í•˜ê³  ë„ë¡œëª… + ê±´ë¬¼ë²ˆí˜¸ë§Œ ì‚¬ìš©
        addr_raw = re.sub(road_pattern, f'{road_name} {building_num}', addr_raw)
        logger.info(f"ì£¼ì†Œ ì „ì²˜ë¦¬: ê±´ë¬¼ë²ˆí˜¸ ì •ë¦¬ -> {addr_raw}")
    
    # 2. ì§€ë²ˆ ì£¼ì†ŒëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ (JUSO APIê°€ ì§€ë²ˆ ì£¼ì†Œë„ ì²˜ë¦¬ ê°€ëŠ¥)
    # ë‹¤ë§Œ ë¶ˆí•„ìš”í•œ ì •ë³´ë§Œ ì œê±°
    
    # 3. ë¶ˆí•„ìš”í•œ ì¸µìˆ˜ ì •ë³´ ì œê±°
    addr_raw = re.sub(r'\s+\d+\s*ì¸µ.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+ì „ì¸µ.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+\d+\s*~\s*\d+\s*ì¸µ.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+\d+,\d+.*ì¸µ.*$', '', addr_raw)  # 2,3,4,5ì¸µ íŒ¨í„´
    addr_raw = re.sub(r'\s+\d+[Ff].*$', '', addr_raw)  # 1F, 2f íŒ¨í„´
    # ì¶”ê°€ ì¸µìˆ˜ íŒ¨í„´ë“¤
    addr_raw = re.sub(r'\s+ì§€ìƒ\d+\s*~\s*\d+\s*ì¸µ.*$', '', addr_raw)  # ì§€ìƒ1ì¸µ~3ì¸µ
    addr_raw = re.sub(r'\s+ì§€í•˜\d+\s*~\s*\d+\s*ì¸µ.*$', '', addr_raw)  # ì§€í•˜1ì¸µ~3ì¸µ
    addr_raw = re.sub(r'\s+ì§€ìƒ\d+\s*ì¸µ.*$', '', addr_raw)  # ì§€ìƒ1ì¸µ
    addr_raw = re.sub(r'\s+ì§€í•˜\d+\s*ì¸µ.*$', '', addr_raw)  # ì§€í•˜1ì¸µ
    
    # 4. ê±´ë¬¼ëª… ì œê±° (ê´„í˜¸ ì•ˆì˜ ë‚´ìš©)
    addr_raw = re.sub(r'\s*\([^)]*\)\s*', ' ', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ìƒí™œ.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ë¹Œ.*$', '', addr_raw)
    # ì¶”ê°€ ê±´ë¬¼ëª… íŒ¨í„´ë“¤
    addr_raw = re.sub(r'\s+ì• ìŠ¤íŠ¸ë¦¬\d+.*$', '', addr_raw)  # ì• ìŠ¤íŠ¸ë¦¬23
    addr_raw = re.sub(r'\s+ì‚¬ëŠ”ìë¦¬.*$', '', addr_raw)  # ì‚¬ëŠ”ìë¦¬
    addr_raw = re.sub(r'\s+ì¨ë“œí”Œë ˆì´ìŠ¤.*$', '', addr_raw)  # ì¨ë“œí”Œë ˆì´ìŠ¤ í™ì€7
    addr_raw = re.sub(r'\s+ì½”ì´ë…¸ë‹ˆì•„.*$', '', addr_raw)  # ì½”ì´ë…¸ë‹ˆì•„ìŠ¤í…Œì´
    addr_raw = re.sub(r'\s+ë§‘ì€êµ¬ë¦„ì§‘.*$', '', addr_raw)  # ë§‘ì€êµ¬ë¦„ì§‘
    addr_raw = re.sub(r'\s+ë„ˆë‚˜ë“¤ì´.*$', '', addr_raw)  # ë„ˆë‚˜ë“¤ì´
    addr_raw = re.sub(r'\s+í™”ê³¡ë™.*$', '', addr_raw)  # í™”ê³¡ë™ ê³µë™ì²´ì£¼íƒ
    # ì¶”ê°€ ê±´ë¬¼ëª… íŒ¨í„´ë“¤ (sohouse ì‹¤íŒ¨ ì¼€ì´ìŠ¤)
    addr_raw = re.sub(r'\s+ë…¹ìƒ‰ì¹œêµ¬ë“¤.*$', '', addr_raw)  # ë…¹ìƒ‰ì¹œêµ¬ë“¤ ëŒ€ì¡°, ë…¹ìƒ‰ì¹œêµ¬ë“¤ ì°½ì²œ
    addr_raw = re.sub(r'\s+í•¨ê»˜ì£¼íƒ.*$', '', addr_raw)  # í•¨ê»˜ì£¼íƒ6í˜¸, í•¨ê»˜ì£¼íƒ5í˜¸
    addr_raw = re.sub(r'\s+ì£¼ìƒë³µí•©ê±´ë¬¼.*$', '', addr_raw)  # ì£¼ìƒë³µí•©ê±´ë¬¼
    
    # 5. ì§€ë²ˆì£¼ì†Œ ì •ë¦¬ (~ë™ ìˆ«ì-ìˆ«ì ë’¤ì˜ ëª¨ë“  ë¬¸ì ì œê±°)
    # ì˜ˆ: "ì„œìš¸ ì¢…ë¡œêµ¬ ë™ìˆ­ë™ 192-6 1" -> "ì„œìš¸ ì¢…ë¡œêµ¬ ë™ìˆ­ë™ 192-6"
    addr_raw = re.sub(r'([ê°€-í£]+ë™\s+\d+-\d+)\s+.*$', r'\1', addr_raw)
    
    # 6. ë„ë¡œëª…+ê±´ë¬¼ë²ˆí˜¸ ë¶„ë¦¬ (ì¼ë°˜í™”ëœ íŒ¨í„´)
    # 6-1. *ë¡œ*ê¸¸+ìˆ«ì -> *ë¡œ*ê¸¸ ìˆ«ì (ì˜ˆ: ë¶ì•…ì‚°ë¡œ3ê¸¸44 -> ë¶ì•…ì‚°ë¡œ3ê¸¸ 44)
    # ë” ì •í™•í•œ íŒ¨í„´ìœ¼ë¡œ ìˆ˜ì •: ~ë¡œë¡œ ëë‚˜ê³  ~ê¸¸ë¡œ ëë‚˜ëŠ” íŒ¨í„´
    addr_raw = re.sub(r'([ê°€-í£]+ë¡œ\d*[ê°€-í£]*ê¸¸)(\d+[-\d]*)', r'\1 \2', addr_raw)
    
    # 6-2. *ë¡œ+ìˆ«ì -> *ë¡œ ìˆ«ì (ê¸¸ì´ ì—†ëŠ” ê²½ìš°ë§Œ)
    # ë‹¨, ~ê¸¸ì´ í¬í•¨ëœ ê²½ìš°ëŠ” ì œì™¸ (ì—°í¬ë¡œ18ê¸¸ -> ì—°í¬ë¡œ18ê¸¸ ìœ ì§€)
    if 'ê¸¸' not in addr_raw:
        addr_raw = re.sub(r'([ê°€-í£]+ë¡œ)(\d+[-\d]*)', r'\1 \2', addr_raw)
    
    # 7. ë„ë¡œëª…ì£¼ì†Œ ì •ë¦¬ (~ê¸¸ìˆ«ì(-ìˆ«ì) ë˜ëŠ” ~ê¸¸ ìˆ«ì(-ìˆ«ì) ë’¤ì˜ ëª¨ë“  ë¬¸ì ì œê±°)
    # ì˜ˆ: "ì„œìš¸ ì„œëŒ€ë¬¸êµ¬ ì—°í¬ë¡œ18ê¸¸ 36 ì• ìŠ¤íŠ¸ë¦¬23" -> "ì„œìš¸ ì„œëŒ€ë¬¸êµ¬ ì—°í¬ë¡œ18ê¸¸ 36"
    # ~ê¸¸ìˆ«ì(-ìˆ«ì) íŒ¨í„´ ë’¤ì˜ ëª¨ë“  ë¬¸ì ì œê±°
    addr_raw = re.sub(r'([ê°€-í£]+ê¸¸\d+[-\d]*)\s+.*$', r'\1', addr_raw)
    # ~ê¸¸ ìˆ«ì(-ìˆ«ì) íŒ¨í„´ ë’¤ì˜ ëª¨ë“  ë¬¸ì ì œê±°
    addr_raw = re.sub(r'([ê°€-í£]+ê¸¸\s+\d+[-\d]*)\s+.*$', r'\1', addr_raw)
    # ~ë¡œ ìˆ«ì(-ìˆ«ì) íŒ¨í„´ ë’¤ì˜ ëª¨ë“  ë¬¸ì ì œê±° (ê¸¸ì´ ì—†ëŠ” ê²½ìš°)
    addr_raw = re.sub(r'([ê°€-í£]+ë¡œ\s+\d+[-\d]*)\s+.*$', r'\1', addr_raw)
    
    # 8. ~ë¡œ ì£¼ì†Œì—ì„œ ~ë¡œ ì œê±° (ê¸¸ì´ ì—†ëŠ” ê²½ìš°)
    # ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ ë§ˆí¬êµ¬ ì™€ìš°ì‚°ë¡œ ìƒìˆ˜ë™ 321-6" -> "ì„œìš¸íŠ¹ë³„ì‹œ ë§ˆí¬êµ¬ ìƒìˆ˜ë™ 321-6"
    # ~ê¸¸ì´ ì—†ëŠ” ì£¼ì†Œì—ì„œë§Œ ~ë¡œ ì œê±°
    if 'ê¸¸' not in addr_raw and 'ë¡œ' in addr_raw:
        addr_raw = re.sub(r'([ê°€-í£]+êµ¬)\s+([ê°€-í£]+ë¡œ)\s+([ê°€-í£]+ë™)', r'\1 \3', addr_raw)
    
    # 9. ì§€ë²ˆ ì£¼ì†Œ ë’¤ ì¶”ê°€ ì •ë³´ ì œê±° (ì¦ì‚°ë™ 202-25 ë“±)
    # ì˜ˆ: "ì¦ì‚°ë¡œ9ê¸¸ 26-21 ì¦ì‚°ë™ 202-25" -> "ì¦ì‚°ë¡œ9ê¸¸ 26-21"
    addr_raw = re.sub(r'([ê°€-í£]+ë¡œ\d*[ê°€-í£]*ê¸¸\s+\d+[-\d]*)\s+[ê°€-í£]+ë™\s+\d+[-\d]*.*$', r'\1', addr_raw)
    # ì¶”ê°€ ì§€ë²ˆ ì£¼ì†Œ ì œê±° (ì„œìš¸ì‹œ ê¸ˆì²œêµ¬ ë…ì‚°ë™ 964-42 ë“±)
    addr_raw = re.sub(r'([ê°€-í£]+ë¡œ\d*[ê°€-í£]*ê¸¸\s+\d+[-\d]*)\s+ì„œìš¸[ì‹œíŠ¹ë³„ì‹œ]*\s+[ê°€-í£]+êµ¬\s+[ê°€-í£]+ë™\s+\d+[-\d]*.*$', r'\1', addr_raw)
    
    # 10. ë§ˆì¹¨í‘œ ë° ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
    addr_raw = re.sub(r'\.+$', '', addr_raw)  # ëì˜ ë§ˆì¹¨í‘œ ì œê±°
    addr_raw = re.sub(r'\s+$', '', addr_raw)  # ëì˜ ê³µë°± ì œê±°
    
    # 12. ì•„íŒŒíŠ¸/ê±´ë¬¼ ë‚´ë¶€ ì •ë³´ ì œê±° (infra ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ëŒ€ì‘)
    # ë™/í˜¸ìˆ˜ ì •ë³´ ì œê±° (ì˜ˆ: 101ë™ 102í˜¸, 13ë™ 204í˜¸)
    addr_raw = re.sub(r'\s+\d+ë™\s+\d+í˜¸.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+\d+ë™\s+\d+,\s*\d+í˜¸.*$', '', addr_raw)
    # ì¸µìˆ˜ ì •ë³´ ì œê±° (ì˜ˆ: 4ì¸µ, 3ì¸µ, 1ì¸µ)
    addr_raw = re.sub(r'\s+\d+ì¸µ.*$', '', addr_raw)
    # ë‹¨ì§€/ì•„íŒŒíŠ¸ ë‚´ë¶€ ì •ë³´ ì œê±°
    addr_raw = re.sub(r'\s+ë‹¨ì§€\s*ë‚´.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+ê´€ë¦¬ë™.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+ê´€ë¦¬ì‹¤.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+í‚¤ì¦ˆì„¼í„°\d+ì¸µ.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+í‚¤ì¦ˆí´ëŸ½.*$', '', addr_raw)
    # ìƒì„¸ ìœ„ì¹˜ ì •ë³´ ì œê±° (ì˜ˆ: B113í˜¸, 101-2í˜¸, 206-2í˜¸)
    addr_raw = re.sub(r'\s+[A-Z]\d+í˜¸.*$', '', addr_raw)  # B113í˜¸, A101í˜¸ ë“±
    addr_raw = re.sub(r'\s+\d+-\d+í˜¸.*$', '', addr_raw)  # 101-2í˜¸, 206-2í˜¸ ë“±
    addr_raw = re.sub(r'\s+\d+,\d+í˜¸.*$', '', addr_raw)  # 105,106í˜¸ ë“±
    # ì§€í•˜/ì§€ìƒ ì •ë³´ ì œê±°
    addr_raw = re.sub(r'\s+ì§€í•˜\d+.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+ì§€ìƒ\s*\d+.*$', '', addr_raw)
    # B1ì¸µ, B2ì¸µ ë“± ì œê±°
    addr_raw = re.sub(r'\s+B\d+ì¸µ.*$', '', addr_raw)
    # ìƒê°€/ë¹Œë”© ë‚´ë¶€ ì •ë³´ ì œê±°
    addr_raw = re.sub(r'\s+ìƒê°€ë™.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+ë¹Œë”©.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+íƒ€ì›Œ.*$', '', addr_raw)
    # ì£¼ë¯¼ê³µë™ì‹œì„¤, ì¢…í•©ìƒê°€ ë“± ì œê±°
    addr_raw = re.sub(r'\s+ì£¼ë¯¼ê³µë™ì‹œì„¤.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+ì¢…í•©ìƒê°€.*$', '', addr_raw)
    # ì„¼í„°/ê´€ë ¨ ì •ë³´ ì œê±°
    addr_raw = re.sub(r'\s+ê³ ê°ì„¼í„°\d+ì¸µ.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+ê·¼ë¡œë³µì§€ê´€\d+ì¸µ.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+êµìœ¡ê´€.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+ë¬¸í™”ê±´ê°•ì„¼í„°.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+ì—´ë¦°ë¬¸í™”ì„¼í„°.*$', '', addr_raw)
    
    # 13. ë³µì¡í•œ ê±´ë¬¼ëª… íŒ¨í„´ ì œê±° (infra íŠ¹í™”)
    # ì•„íŒŒíŠ¸ ë‹¨ì§€ëª… ì œê±°
    addr_raw = re.sub(r'\s+[ê°€-í£]+ì•„íŒŒíŠ¸.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+íƒ€ìš´.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ì‹œí‹°.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+íŒŒí¬.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+íìŠ¤.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ìœ„ë¸Œ.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ìì´.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+í‘¸ë¥´ì§€ì˜¤.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+í”„ë ˆìŠ¤í‹°ì§€.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ë‰´íƒ€ìš´.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ë‰´íƒ€ì›Œ.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ë¸Œì´ì›.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ì—ì½”.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ë¦¬ë²„.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ë”í”„ë ˆí‹°ì›€.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ìŠ¤ìœ„ì²¸.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ë¦¬ì²¸ì‹œì•„.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+í”Œë ˆì´ìŠ¤.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ì„¼íŠ¸ëŸ´.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ê·¸ë¼ì‹œì›€.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ì•„ì´íŒŒí¬.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ì•„ì¹´ë°ë¯¸.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ë¸Œì´ì›.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ì—”ì§€ë‹ˆì–´ë§.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ë©”ë””ì»¬.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+í™ˆìºìŠ¤íŠ¸.*$', '', addr_raw)
    addr_raw = re.sub(r'\s+[ê°€-í£]+ìŠ¤ìœ„íŠ¸.*$', '', addr_raw)
    
    # 14. ê´„í˜¸ ì•ˆì˜ ìƒì„¸ ì •ë³´ ì œê±° (ì˜ˆ: (ë§ìš°ë³¸ë™), (ì •ë¦‰ë™))
    addr_raw = re.sub(r'\s*\([^)]*ë™[^)]*\)\s*', ' ', addr_raw)
    addr_raw = re.sub(r'\s*\([^)]*ê°€[^)]*\)\s*', ' ', addr_raw)
    
    # 15. ê³µë°± ì •ë¦¬
    addr_raw = re.sub(r'\s+', ' ', addr_raw).strip()



    # --- ğŸ”¥ [ì¶”ê°€: ì£¼íƒ ì •ê·œí™” ì „ìš© ê·œì¹™] ---
    # 1. ì‰¼í‘œ(,) ë’¤ ìƒì„¸ì •ë³´ ì œê±° â†’ "ì„œìš¸ ì„±ë¶êµ¬ ë™ì†Œë¬¸ë¡œ 305, ì§€ì¸µ" â†’ "ì„œìš¸ ì„±ë¶êµ¬ ë™ì†Œë¬¸ë¡œ 305"
    addr_raw = re.sub(r',\s*[^,]+$', '', addr_raw)

    # 2. 'ì§€ìƒ', 'ì§€í•˜', 'ì¸µ', 'í˜¸' ë“± ì„¸ë¶€ìœ„ì¹˜ ì œê±°
    addr_raw = re.sub(r'\s*ì§€[ìƒí•˜]\d*ì¸µ?', '', addr_raw)
    addr_raw = re.sub(r'\s*\d+ì¸µ', '', addr_raw)
    addr_raw = re.sub(r'\s*\d+í˜¸', '', addr_raw)
    addr_raw = re.sub(r'\s*\d+ë™', '', addr_raw)

    # 3. ê´„í˜¸ ì•ˆì— ìˆëŠ” ë™/ê°€/ê±´ë¬¼ëª… ì œê±°
    addr_raw = re.sub(r'\([^)]*(ë™|ê°€|ì•„íŒŒíŠ¸|ë¹Œë¼|ë‹¨ì§€|ìƒê°€|íƒ€ì›Œ)[^)]*\)', '', addr_raw)

    # 4. "ì•", "ë‚´", "ê´€ë¦¬ë™", "ê´€ë¦¬ì‹¤" ë“± ë¶ˆí•„ìš”í•œ ë‹¨ì–´ ì œê±°
    addr_raw = re.sub(r'\s*(ì•|ë‚´|ê´€ë¦¬ë™|ê´€ë¦¬ì‹¤|ì£¼ë¯¼ì„¼í„°|í‚¤ì¦ˆì„¼í„°\d*ì¸µ?|ë¬¸í™”ì„¼í„°).*$', '', addr_raw)

    # 5. ì£¼ì†Œ ë ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
    addr_raw = re.sub(r'[-,\s]+$', '', addr_raw)

    # 6. ë„ë¡œëª… + ë„ë¡œëª…ì£¼ì†Œë¶€ë²ˆê¹Œì§€ë§Œ ì¸ì‹í•˜ê³  ê·¸ ë’¤ëŠ” ëª¨ë‘ ì œê±°
    # ~ê¸¸ + ìˆ«ì íŒ¨í„´ (ë„ë¡œëª…ì£¼ì†Œë¶€ë²ˆê¹Œì§€) - ë” ì •í™•í•œ íŒ¨í„´
    addr_raw = re.sub(r'([ê°€-í£]+ê¸¸\d*[ê°€-í£]*\s+\d+[-\d]*)\s+[ê°€-í£].*$', r'\1', addr_raw)
    # ~ë¡œ + ìˆ«ì íŒ¨í„´ (ë„ë¡œëª…ì£¼ì†Œë¶€ë²ˆê¹Œì§€) - ê¸¸ì´ ì—†ëŠ” ê²½ìš°ë§Œ
    if 'ê¸¸' not in addr_raw:
        addr_raw = re.sub(r'([ê°€-í£]+ë¡œ\d*[ê°€-í£]*\s+\d+[-\d]*)\s+[ê°€-í£].*$', r'\1', addr_raw)
    
    # 6-1. íŠ¹ìˆ˜ ì¼€ì´ìŠ¤: ë„ë¡œëª…ì´ ë„ˆë¬´ êµ¬ì²´ì ì¸ ê²½ìš° ë” ê°„ë‹¨í•˜ê²Œ
    # ê´‘í‰ë¡œ34ê¸¸ -> ê´‘í‰ë¡œë¡œ ë‹¨ìˆœí™”
    addr_raw = re.sub(r'([ê°€-í£]+ë¡œ)\d+ê¸¸', r'\1', addr_raw)
    # ë„ë¡œëª… + ìˆ«ì ë’¤ì˜ ëª¨ë“  ê²ƒ ì œê±°
    addr_raw = re.sub(r'([ê°€-í£]+ë¡œ\s+\d+[-\d]*)\s+[ê°€-í£].*$', r'\1', addr_raw)
    
    # 7. ì–´ë¦°ì´ì§‘/ìœ ì¹˜ì› ë“± ì‹œì„¤ëª… ì œê±° (ë” êµ¬ì²´ì ì¸ íŒ¨í„´)
    # ~ê¸¸/ë¡œ + ìˆ«ì + ì‹œì„¤ëª… íŒ¨í„´
    addr_raw = re.sub(r'([ê°€-í£]+ê¸¸\d*[ê°€-í£]*\s+\d+)\s+[ê°€-í£]*(ì–´ë¦°ì´ì§‘|ìœ ì¹˜ì›|í•™êµ|ë³‘ì›|ì•½êµ­|ë§ˆíŠ¸|í¸ì˜ì |ê³µì›|ì²´ìœ¡ê´€|ë¬¸í™”ì„¼í„°|ì£¼ë¯¼ì„¼í„°|ì„¼í„°|ê´€ë¦¬ë™|ê´€ë¦¬ì‹¤|í‚¤ì¦ˆì„¼í„°|í‚¤ì¦ˆí´ëŸ½).*$', r'\1', addr_raw)
    addr_raw = re.sub(r'([ê°€-í£]+ë¡œ\d*[ê°€-í£]*\s+\d+)\s+[ê°€-í£]*(ì–´ë¦°ì´ì§‘|ìœ ì¹˜ì›|í•™êµ|ë³‘ì›|ì•½êµ­|ë§ˆíŠ¸|í¸ì˜ì |ê³µì›|ì²´ìœ¡ê´€|ë¬¸í™”ì„¼í„°|ì£¼ë¯¼ì„¼í„°|ì„¼í„°|ê´€ë¦¬ë™|ê´€ë¦¬ì‹¤|í‚¤ì¦ˆì„¼í„°|í‚¤ì¦ˆí´ëŸ½).*$', r'\1', addr_raw)
    
    # ì¼ë°˜ì ì¸ ì‹œì„¤ëª… ì œê±° (ê¸¸/ë¡œ íŒ¨í„´ì´ ì—†ëŠ” ê²½ìš°)
    addr_raw = re.sub(r'\s+[ê°€-í£]*(ì–´ë¦°ì´ì§‘|ìœ ì¹˜ì›|í•™êµ|ë³‘ì›|ì•½êµ­|ë§ˆíŠ¸|í¸ì˜ì |ê³µì›|ì²´ìœ¡ê´€|ë¬¸í™”ì„¼í„°|ì£¼ë¯¼ì„¼í„°|ì„¼í„°|ê´€ë¦¬ë™|ê´€ë¦¬ì‹¤|í‚¤ì¦ˆì„¼í„°|í‚¤ì¦ˆí´ëŸ½).*$', '', addr_raw)
    
    # 7. ê³µë°± ì •ë¦¬
    addr_raw = re.sub(r'\s+', ' ', addr_raw).strip()

    # 8. ì¶”ê°€ ì£¼ì†Œì •ê·œí™” ê·œì¹™ (ì‚° í‘œê¸°, ë™/í˜¸ìˆ˜, ë‹¨ì§€ëª… ì œê±° ë“±)
    # 8-1. 'ì‚°' ë’¤ ìˆ«ì ê³µë°± ì‚½ì… (ì˜ˆ: ì‚°19 -> ì‚° 19)
    addr_raw = re.sub(r"(ì‚°)(\d+)", r"\1 \2", addr_raw)

    # 8-2. ì„¸ë¶€ ë™Â·í˜¸ìˆ˜ ì œê±° (ì˜ˆ: 106-101, 101-102)
    addr_raw = re.sub(r"\d+-\d+$", "", addr_raw)

    # 8-3. ì¸µ/í˜¸/ìƒì„¸ ìœ„ì¹˜ ì œê±°
    addr_raw = re.sub(r"\d+ì¸µ", "", addr_raw)      # 3ì¸µ, 2ì¸µ
    addr_raw = re.sub(r"\d+í˜¸", "", addr_raw)      # 101í˜¸, 201í˜¸
    addr_raw = re.sub(r"B\d+", "", addr_raw)       # B113í˜¸ ê°™ì€ íŒ¨í„´
    addr_raw = re.sub(r"(ìƒê°€|ë³¸ê´€|ê´€ë¦¬ë™).*", "", addr_raw)  # ê´€ë¦¬ë™, ìƒê°€ 2ì¸µ ë“±

    # 8-4. ë‹¨ì§€ëª…/ì•„íŒŒíŠ¸ëª… ì œê±° (ê³µí†µ ì•„íŒŒíŠ¸ ë¸Œëœë“œëª…)
    apt_keywords = [
        "ìì´", "í‘¸ë¥´ì§€ì˜¤", "íìŠ¤í…Œì´íŠ¸", "ë˜ë¯¸ì•ˆ",
        "ì•„ì´íŒŒí¬", "ë¦¬ì²¸ì‹œì•„", "ë¡¯ë°ìºìŠ¬", "eí¸í•œì„¸ìƒ",
        "ì„¼íŠ¸ë ˆë¹Œ", "ìœ„ë¸Œ", "ë”ìƒµ", "SKë·°", "ì— ë²¨ë¦¬"
    ]
    for kw in apt_keywords:
        addr_raw = re.sub(rf"\s*{kw}\S*", "", addr_raw)

    # 8-5. ê´„í˜¸/ì‰¼í‘œ ì•ˆì˜ ë¶€ê°€ì„¤ëª… ì œê±°
    addr_raw = re.sub(r"\(.*?\)", "", addr_raw)
    addr_raw = re.sub(r",.*", "", addr_raw)

    # 8-6. ê±´ë¬¼ëª…/ì‹œì„¤ëª… ì œê±° (E3, Aë™, Bë™ ë“±)
    addr_raw = re.sub(r"\s+[A-Z]\d*$", "", addr_raw)  # E3, A1, B2 ë“±
    addr_raw = re.sub(r"\s+[ê°€-í£]*ë™$", "", addr_raw)  # Aë™, Bë™ ë“±
    
    # 8-7. ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
    addr_raw = re.sub(r"\s+", " ", addr_raw).strip()

    # âœ… ì£¼íƒ ì£¼ì†Œ ì „ìš© ê°•ì œ ì •ê·œí™” (ë§ˆì§€ë§‰ ë‹¨ê³„)
    # -------------------
    # 1. ê´„í˜¸ ì œê±°
    addr = re.sub(r'\([^)]*\)', '', addr_raw)

    # 2. ì‰¼í‘œ ë’¤ ìƒì„¸ì •ë³´ ì œê±°
    addr = re.sub(r',.*$', '', addr)

    # 3. "ì¸µ", "í˜¸", "ë™" ê°™ì€ ì„¸ë¶€ ìœ„ì¹˜ ì œê±°
    addr = re.sub(r'\s*\d+ì¸µ.*$', '', addr)
    addr = re.sub(r'\s*\d+í˜¸.*$', '', addr)
    addr = re.sub(r'\s*\d+ë™.*$', '', addr)
    addr = re.sub(r'\s*ì§€í•˜\d*ì¸µ?', '', addr)
    addr = re.sub(r'\s*ì§€ìƒ\d*ì¸µ?', '', addr)

    # 4. ë„ë¡œëª…+ë²ˆì§€ê¹Œì§€ë§Œ ë‚¨ê¸°ê¸°
    # ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë¶êµ¬ ë™ì†Œë¬¸ë¡œ 305 ì§€ì¸µ" -> "ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë¶êµ¬ ë™ì†Œë¬¸ë¡œ 305"
    addr = re.sub(r'([ê°€-í£]+ë¡œ\s*\d+[-\d]*).*$', r'\1', addr)
    addr = re.sub(r'([ê°€-í£]+ê¸¸\s*\d+[-\d]*).*$', r'\1', addr)

    # 5. ê³µë°± ì •ë¦¬
    addr = re.sub(r'\s+', ' ', addr).strip()

    return addr

class InfraNormalizer:
    """ì¸í”„ë¼ ë°ì´í„° ì •ê·œí™” í´ë˜ìŠ¤"""
    
    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.normalized_facilities: List[Dict] = []
        self.normalized_subway_stations: List[Dict] = []
        self.failed_addresses: List[Dict] = []  # ì‹¤íŒ¨í•œ ì£¼ì†Œ ì •ê·œí™” ë°ì´í„°
        
        # facility_categories ë§¤í•‘ (DBì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ í•˜ë“œì½”ë”©)
        # ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” DBì—ì„œ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
        self.category_map = {
            'hospital': 1,
            'school': 2,           # ì´ˆì¤‘ê³  + ëŒ€í•™
            'kindergarten': 3,     # ì–´ë¦°ì´ì§‘ â†’ childcare(ID 3)
            'childSchool': 11,     # ìœ ì¹˜ì› â†’ childSchool (ID 11)
            'park': 4,
            'mart': 5,
            'convenience': 6,
            'pharmacy': 7,
            'subway': 8,
            'bus': 9,              # ë²„ìŠ¤ì •ë¥˜ì†Œ
            'gym': 10,             # ê³µê³µì²´ìœ¡ì‹œì„¤
            'college': 2,          # schoolë¡œ í†µí•©
            'bus_stop': 9          # busë¡œ í†µí•©
        }
        
        # ì£¼ì†Œ ì •ê·œí™” API í‚¤ ë¡œë“œ
        self.juso_api_key = os.getenv("JUSO_API_KEY")
        if not self.juso_api_key:
            logger.warning("JUSO_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì£¼ì†Œ ì •ê·œí™” ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # í•„ìš”í•œ ì¹´í…Œê³ ë¦¬ í™•ì¸ ë° ì¶”ê°€
        self._ensure_categories_exist()

    def _ensure_categories_exist(self):
        """í•„ìš”í•œ ì¹´í…Œê³ ë¦¬ê°€ DBì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ì¶”ê°€"""
        try:
            from backend.db.db_utils_pg import get_engine
            from sqlalchemy import text
            
            engine = get_engine()
            with engine.connect() as conn:
                # ID 11 (childSchool - ìœ ì¹˜ì›) í™•ì¸
                result = conn.execute(text("""
                    SELECT id FROM infra.facility_categories 
                    WHERE id = 11 AND code = 'childSchool'
                """)).fetchone()
                
                if not result:
                    # ID 11 ìœ ì¹˜ì› ì¹´í…Œê³ ë¦¬ ì¶”ê°€
                    conn.execute(text("""
                        INSERT INTO infra.facility_categories (id, code, name, description, created_at) 
                        VALUES (11, 'childSchool', 'ìœ ì¹˜ì›', 'êµìœ¡ì‹œì„¤', NOW())
                    """))
                    conn.commit()
                    logger.info("âœ… ìœ ì¹˜ì› ì¹´í…Œê³ ë¦¬(ID: 11) ì¶”ê°€ ì™„ë£Œ")
                else:
                    logger.info("âœ… ìœ ì¹˜ì› ì¹´í…Œê³ ë¦¬(ID: 11) ì´ë¯¸ ì¡´ì¬")
                    
        except Exception as e:
            logger.warning(f"âš ï¸ ì¹´í…Œê³ ë¦¬ í™•ì¸/ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {e}")

    def _get_category_id(self, code: str) -> Optional[int]:
        """ì‹œì„¤ ì¹´í…Œê³ ë¦¬ ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ IDë¥¼ ì¡°íšŒ"""
        return self.category_map.get(code)

    def _safe_int(self, value) -> Optional[int]:
        """ì•ˆì „í•˜ê²Œ ì •ìˆ˜ë¡œ ë³€í™˜"""
        if pd.isna(value) or value == '' or value is None:
            return None
        try:
            return int(float(str(value)))
        except (ValueError, TypeError):
            return None

    def _safe_float(self, value) -> Optional[float]:
        """ì•ˆì „í•˜ê²Œ ì‹¤ìˆ˜ë¡œ ë³€í™˜"""
        if pd.isna(value) or value == '' or value is None:
            return None
        try:
            return float(str(value))
        except (ValueError, TypeError):
            return None

    def _normalize_address(self, address_raw: str, facility_name: str = "", facility_type: str = "") -> Dict[str, Any]:
        """ì£¼ì†Œ ì •ê·œí™” - housingê³¼ ë™ì¼í•œ ë°©ì‹"""
        if not address_raw or address_raw.strip() == '':
            return {
                'address_raw': address_raw,
                'address_norm': None,
                'si_do': None,
                'si_gun_gu': None,
                'si_gun_gu_dong': None,
                'road_full': None,
                'jibun_full': None,
                'lat': None,
                'lon': None,
                'geo_extra': None
            }
        
        logger.info(f"ì›ë³¸ ì£¼ì†Œ: {address_raw}")
        
        # ì„œìš¸íŠ¹ë³„ì‹œ ì¶”ì¶œ (ëª¨ë“  ì£¼ì†Œì— ê³µí†µ ì ìš©)
        si_do = None
        if 'ì„œìš¸íŠ¹ë³„ì‹œ' in address_raw:
            si_do = 'ì„œìš¸íŠ¹ë³„ì‹œ'
        elif 'ì„œìš¸' in address_raw:
            si_do = 'ì„œìš¸íŠ¹ë³„ì‹œ'
        
        # ì‚°ì´ í¬í•¨ëœ ì£¼ì†Œì˜ ê²½ìš° ì§ì ‘ íŒŒì‹±
        if 'ì‚°' in address_raw:
            logger.info(f"ì‚° í¬í•¨ ì£¼ì†Œ ì§ì ‘ íŒŒì‹±: {address_raw}")
            result = self._parse_mountain_address(address_raw)
            result['si_do'] = si_do  # ì„œìš¸íŠ¹ë³„ì‹œ ì •ë³´ ë®ì–´ì“°ê¸°
            return result
        
        # ê³µì› ì£¼ì†Œì˜ ê²½ìš° ë¯¸ë¦¬ ì²´í¬
        is_park = facility_name and 'ê³µì›' in facility_name
        
        # ì£¼ì†Œ ì „ì²˜ë¦¬
        addr_processed = preprocess_address(address_raw)
        logger.info(f"ì „ì²˜ë¦¬ëœ ì£¼ì†Œ: {addr_processed}")
        
        # ì—¬ëŸ¬ íŒ¨í„´ìœ¼ë¡œ ì£¼ì†Œ ì •ê·œí™” ì‹œë„
        success = False
        result = None  # result ë³€ìˆ˜ ì´ˆê¸°í™”
        dong = None    # dong ë³€ìˆ˜ ì´ˆê¸°í™”
        
        for attempt, addr_to_try in enumerate([addr_processed, address_raw]):
            if attempt > 0:
                logger.info(f"ì£¼ì†Œ ì •ê·œí™” ì¬ì‹œë„ ({attempt+1}): {addr_to_try}")
            else:
                logger.info(f"ì£¼ì†Œ ì •ê·œí™” ì‹œë„: {addr_to_try}")
            
            try:
                result = normalize_address(addr_to_try)
                
                # ë²•ì •ë™ ì¶”ì¶œ (JUSO APIì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°)
                dong = result.get('eupmyeon_dong', '')  # JUSO APIì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
                
                logger.info(f"ì£¼ì†Œ ì •ê·œí™” ì„±ê³µ: {result}")
                success = True
                break
            except AddressNormalizerError as e:
                logger.warning(f"ì£¼ì†Œ ì •ê·œí™” ì‹¤íŒ¨ (ì‹œë„ {attempt+1}): {addr_to_try} - {e}")
                if attempt == 1:  # ë§ˆì§€ë§‰ ì‹œë„
                    logger.error(f"ì£¼ì†Œ ì •ê·œí™” ìµœì¢… ì‹¤íŒ¨: {address_raw} - {e}")
                    
                    # ê³µì›ì¸ ê²½ìš° ì§ì ‘ íŒŒì‹± ì‹œë„
                    if is_park:
                        logger.info(f"ê³µì› ì£¼ì†Œ ì§ì ‘ íŒŒì‹± ì‹œë„: {address_raw}")
                        result = self._parse_park_address(address_raw)
                        result['si_do'] = si_do  # ì„œìš¸íŠ¹ë³„ì‹œ ì •ë³´ ë®ì–´ì“°ê¸°
                        return result
                    
                    # ì‹¤íŒ¨í•œ ì£¼ì†Œ ì •ë³´ ìˆ˜ì§‘
                    failed_data = {
                        "facility_type": facility_type,
                        "facility_name": facility_name,
                        "address_raw": address_raw,
                        "address_processed": addr_processed,
                        "error_reason": str(e),
                        "timestamp": pd.Timestamp.now().isoformat()
                    }
                    self.failed_addresses.append(failed_data)
        
        if success and result:  # resultê°€ ì¡´ì¬í•  ë•Œë§Œ
            # í˜„ì¬ resultì—ì„œ ì£¼ì†Œ ì •ë³´ ì¶”ì¶œ
            road_full = result.get("road_full", "")
            jibun_full = result.get("jibun_full", "")
            
            # ë„ë¡œëª…ì£¼ì†Œê°€ ìˆìœ¼ë©´ ì§€ë²ˆì£¼ì†Œ ì¡°íšŒ ì‹œë„
            if road_full:
                try:
                    jibun_result = normalize_address(road_full, reverse=True)
                    jibun_full = jibun_result.get("jibun_full", jibun_full)
                except:
                    pass  # ê¸°ì¡´ jibun_full ìœ ì§€
            
            # ì§€ë²ˆì£¼ì†Œê°€ ìˆìœ¼ë©´ ë„ë¡œëª…ì£¼ì†Œ ì¡°íšŒ ì‹œë„
            if jibun_full:
                try:
                    road_result = normalize_address(jibun_full)
                    road_full = road_result.get("road_full", road_full)
                except:
                    pass  # ê¸°ì¡´ road_full ìœ ì§€
            
            return {
                'address_raw': address_raw,
                'address_norm': road_full or jibun_full,
                'si_do': si_do or result.get('sido'),  # ì„œìš¸íŠ¹ë³„ì‹œ ìš°ì„  ì ìš©
                'si_gun_gu': result.get('sigungu'),
                'si_gun_gu_dong': dong,  # JUSO APIì—ì„œ ê°€ì ¸ì˜¨ ë™ ì •ë³´
                'road_full': road_full,  # ìƒˆë¡œ ì¶”ê°€
                'jibun_full': jibun_full,  # ìƒˆë¡œ ì¶”ê°€
                'lat': result.get('y'),  # API returns y(lat), x(lon)
                'lon': result.get('x'),
                'geo_extra': result.get('geo_extra')
            }
        else:
            # JUSO API ì™„ì „ ì‹¤íŒ¨ ì‹œ ìµœì†Œí•œ ì‹œë„/êµ¬ë§Œì´ë¼ë„ íŒŒì‹±
            logger.info(f"JUSO API ì™„ì „ ì‹¤íŒ¨, ìµœì†Œ íŒŒì‹± ì‹œë„: {address_raw}")
            result = self._parse_minimal_address(address_raw)
            result['si_do'] = si_do  # ì„œìš¸íŠ¹ë³„ì‹œ ì •ë³´ ë®ì–´ì“°ê¸°
            return result

    def _parse_mountain_address(self, address_raw: str) -> Dict[str, Any]:
        """ì‚°ì´ í¬í•¨ëœ ì£¼ì†Œ ì§ì ‘ íŒŒì‹±"""
        result = self._parse_common_address(address_raw, create_norm=False)
        result['address_norm'] = address_raw  # ì‚° ì£¼ì†ŒëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        logger.info(f"ì‚° ì£¼ì†Œ íŒŒì‹± ê²°ê³¼: si_do={result['si_do']}, si_gun_gu={result['si_gun_gu']}, si_gun_gu_dong={result['si_gun_gu_dong']}")
        return result

    def _parse_park_address(self, address_raw: str) -> Dict[str, Any]:
        """ê³µì› ì£¼ì†Œ ì§ì ‘ íŒŒì‹± (JUSO API ì‹¤íŒ¨ ì‹œ) - ì—¬ëŸ¬ ë™ ëª¨ë‘ ì¶”ì¶œ"""
        result = self._parse_common_address(address_raw, create_norm=False, extract_all_dongs=True)
        result['address_norm'] = address_raw  # ê³µì› ì£¼ì†ŒëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        logger.info(f"ê³µì› ì£¼ì†Œ íŒŒì‹± ê²°ê³¼: si_do={result['si_do']}, si_gun_gu={result['si_gun_gu']}, si_gun_gu_dong={result['si_gun_gu_dong']}, all_dongs={result.get('si_gun_gu_dongs', [])}")
        return result

    def _parse_minimal_address(self, address_raw: str) -> Dict[str, Any]:
        """ìµœì†Œí•œì˜ ì£¼ì†Œ íŒŒì‹± (JUSO API ì™„ì „ ì‹¤íŒ¨ ì‹œ)"""
        result = self._parse_common_address(address_raw, create_norm=False)
        result['address_norm'] = address_raw  # ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        result['si_gun_gu_dong'] = None  # ë™ ì •ë³´ëŠ” ì¶”ì¶œí•˜ì§€ ì•ŠìŒ
        logger.info(f"ìµœì†Œ íŒŒì‹± ê²°ê³¼: si_do={result['si_do']}, si_gun_gu={result['si_gun_gu']}")
        return result

    def _parse_common_address(self, address_raw: str, create_norm: bool = True, extract_all_dongs: bool = False) -> Dict[str, Any]:
        """ê³µí†µ ì£¼ì†Œ íŒŒì‹± í•¨ìˆ˜ (ëª¨ë“  ë°ì´í„°ì…‹ì—ì„œ ì‚¬ìš©) - ì„œìš¸íŠ¹ë³„ì‹œëŠ” _normalize_addressì—ì„œ ì²˜ë¦¬"""
        import re
        
        # êµ¬ ì¶”ì¶œ
        si_gun_gu = None
        gu_pattern = r'([ê°€-í£]+êµ¬)'
        gu_match = re.search(gu_pattern, address_raw)
        if gu_match:
            si_gun_gu = gu_match.group(1)
        
        # ë™/ê°€ ì¶”ì¶œ (ì‚° ë²ˆí˜¸ ë“±ì€ ì œì™¸)
        si_gun_gu_dong = None
        si_gun_gu_dongs = []  # ì—¬ëŸ¬ ë™ ì €ì¥ìš©
        
        # ~ë™ìœ¼ë¡œ ëë‚˜ëŠ” ê²ƒë§Œ ì¶”ì¶œ (ì‚° ë²ˆí˜¸, ê±´ë¬¼ ë²ˆí˜¸ ë“± ì œì™¸)
        dong_pattern = r'([ê°€-í£]+ë™+" ")'
        dong_matches = re.findall(dong_pattern, address_raw)
        
        if dong_matches:
            if extract_all_dongs:
                # ëª¨ë“  ë™ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥
                si_gun_gu_dongs = dong_matches
                si_gun_gu_dong = dong_matches[0] if dong_matches else None  # ì²« ë²ˆì§¸ ë™ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ
            else:
                # ì²« ë²ˆì§¸ ë™ë§Œ ì €ì¥ (ê¸°ì¡´ ë°©ì‹)
                si_gun_gu_dong = dong_matches[0]
        
        # address_norm ìƒì„± (ì •ê·œí™”ëœ ì£¼ì†Œ)
        address_norm = address_raw
        if create_norm and si_gun_gu and si_gun_gu_dong:
            # "ê°•ë‚¨êµ¬ ì—­ì‚¼ë™" í˜•íƒœë¡œ ì •ê·œí™” (ì„œìš¸íŠ¹ë³„ì‹œëŠ” _normalize_addressì—ì„œ ì¶”ê°€)
            address_norm = f"{si_gun_gu} {si_gun_gu_dong}"
        elif create_norm and si_gun_gu:
            # "ê°•ë‚¨êµ¬" í˜•íƒœë¡œ ì •ê·œí™”
            address_norm = si_gun_gu
        
        logger.info(f"ê³µí†µ ì£¼ì†Œ íŒŒì‹± ê²°ê³¼: si_gun_gu={si_gun_gu}, si_gun_gu_dong={si_gun_gu_dong}, all_dongs={si_gun_gu_dongs if extract_all_dongs else None}")
        
        result = {
            'address_raw': address_raw,
            'address_norm': address_norm,
            'si_do': None,  # _normalize_addressì—ì„œ ì²˜ë¦¬
            'si_gun_gu': si_gun_gu,
            'si_gun_gu_dong': si_gun_gu_dong,
            'road_full': None,
            'jibun_full': None,
            'lat': None,
            'lon': None,
            'geo_extra': None
        }
        
        # ì—¬ëŸ¬ ë™ì´ ìˆëŠ” ê²½ìš° ì¶”ê°€ ì •ë³´ë¡œ ì €ì¥
        if extract_all_dongs and si_gun_gu_dongs:
            result['si_gun_gu_dongs'] = si_gun_gu_dongs
        
        return result

    def _normalize_childcare_centers(self, file_path: Path):
        """ì–´ë¦°ì´ì§‘ ë°ì´í„° ì •ê·œí™”"""
        if not file_path.exists():
            logger.warning(f"ì–´ë¦°ì´ì§‘ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
            return

        df = pd.read_csv(file_path, encoding='utf-8')
        logger.info(f"ì–´ë¦°ì´ì§‘ ë°ì´í„° ì •ê·œí™” ì‹œì‘: {len(df)}ê°œ")

        for _, row in df.iterrows():
            address_raw = str(row.get('CRADDR', ''))
            facility_name = str(row.get('CRNAME', ''))
            address_info = self._normalize_address(address_raw, facility_name, 'childcare')
            
            facility_data = {
                'category_id': self._get_category_id('kindergarten'),
                'name': facility_name,
                'address_raw': address_info['address_raw'],
                'address_norm': address_info['address_norm'],
                'si_do': address_info['si_do'],
                'si_gun_gu': address_info['si_gun_gu'],
                'si_gun_gu_dong': address_info.get('si_gun_gu_dong'),
                'road_full': address_info.get('road_full'),
                'jibun_full': address_info.get('jibun_full'),
                'lat': address_info['lat'] or self._safe_float(row.get('LA')),
                'lon': address_info['lon'] or self._safe_float(row.get('LO')),
                'phone': str(row.get('CRTELNO', '')),
                'website': str(row.get('CRHOME', '')),
                'operating_hours': None,
                'is_24h': False,
                'is_emergency': False,
                'capacity': self._safe_int(row.get('CRCAPAT')),
                'grade_level': None,
                'facility_extra': {
                    'childcare_type': str(row.get('CRTYPENAME', ''))
                },
                'data_source': 'openseoul',
                'geo_extra': address_info['geo_extra']
            }
            self.normalized_facilities.append(facility_data)
        logger.info(f"ì–´ë¦°ì´ì§‘ ë°ì´í„° ì •ê·œí™” ì™„ë£Œ: {len(self.normalized_facilities)}ê°œ")

    def _normalize_schools(self, file_path: Path):
        """í•™êµ ë°ì´í„° ì •ê·œí™”"""
        if not file_path.exists():
            logger.warning(f"í•™êµ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
            return

        df = pd.read_csv(file_path, encoding='utf-8')
        logger.info(f"í•™êµ ë°ì´í„° ì •ê·œí™” ì‹œì‘: {len(df)}ê°œ")

        for _, row in df.iterrows():
            address_raw = str(row.get('ORG_RDNMA', ''))
            facility_name = str(row.get('SCHUL_NM', ''))
            address_info = self._normalize_address(address_raw, facility_name, 'school')
            
            facility_data = {
                'category_id': self._get_category_id('school'),
                'name': facility_name,
                'address_raw': address_info['address_raw'],
                'address_norm': address_info['address_norm'],
                'si_do': address_info['si_do'],
                'si_gun_gu': address_info['si_gun_gu'],
                'si_gun_gu_dong': address_info.get('si_gun_gu_dong'),
                'road_full': address_info.get('road_full'),
                'jibun_full': address_info.get('jibun_full'),
                'lat': address_info['lat'] or self._safe_float(row.get('LAT')),
                'lon': address_info['lon'] or self._safe_float(row.get('LON')),
                'phone': str(row.get('ORG_TELNO', '')),
                'website': str(row.get('HMPG_ADRES', '')),
                'operating_hours': None,
                'is_24h': False,
                'is_emergency': False,
                'capacity': None,
                'grade_level': str(row.get('SCHUL_CRSE_SC_NM', '')),
                'facility_extra': {
                    'foundation_type': str(row.get('FOND_SC_NM', '')),
                    'special_class_exist': str(row.get('INDST_SPECL_CCCCL_EXST_YN', '')),
                    'high_school_type': str(row.get('HS_GNRL_BUSNS_SC_NM', '')),
                    'special_purpose': str(row.get('SPCLY_PURPS_HS_ORD_NM', ''))
                },
                'data_source': 'seoul_school',
                'geo_extra': address_info['geo_extra']
            }
            self.normalized_facilities.append(facility_data)
        logger.info(f"í•™êµ ë°ì´í„° ì •ê·œí™” ì™„ë£Œ: {len(self.normalized_facilities)}ê°œ")

    def _normalize_parks(self, file_path: Path):
        """ê³µì› ë°ì´í„° ì •ê·œí™”"""
        if not file_path.exists():
            logger.warning(f"ê³µì› íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
            return

        df = pd.read_csv(file_path, encoding='utf-8')
        logger.info(f"ê³µì› ë°ì´í„° ì •ê·œí™” ì‹œì‘: {len(df)}ê°œ")

        for _, row in df.iterrows():
            address_raw = str(row.get('P_ADDR', ''))
            facility_name = str(row.get('P_PARK', ''))
            address_info = self._normalize_address(address_raw, facility_name, 'park')
            
            facility_data = {
                'category_id': self._get_category_id('park'),
                'name': facility_name,
                'address_raw': address_info['address_raw'],
                'address_norm': address_info['address_norm'],
                'si_do': address_info['si_do'],
                'si_gun_gu': address_info['si_gun_gu'],
                'si_gun_gu_dong': address_info.get('si_gun_gu_dong'),
                'road_full': address_info.get('road_full'),
                'jibun_full': address_info.get('jibun_full'),
                'lat': address_info['lat'] or self._safe_float(row.get('LATITUDE')),
                'lon': address_info['lon'] or self._safe_float(row.get('LONGITUDE')),
                'phone': str(row.get('P_ADMINTEL', '')),
                'website': str(row.get('TEMPLATE_URL', '')),
                'operating_hours': None,
                'is_24h': False,
                'is_emergency': False,
                'capacity': None,
                'grade_level': None,
                'facility_extra': {
                    'description': str(row.get('P_LIST_CONTENT', '')),
                    'area': self._safe_float(row.get('AREA')),
                    'open_date': str(row.get('OPEN_DT', '')),
                    'main_equipment': str(row.get('MAIN_EQUIP', '')),
                    'main_plants': str(row.get('MAIN_PLANTS', '')),
                    'guidance': str(row.get('GUIDANCE', '')),
                    'visit_road': str(row.get('VISIT_ROAD', '')),
                    'use_refer': str(row.get('USE_REFER', '')),
                    'all_dongs': address_info.get('si_gun_gu_dongs', [])  # ì—¬ëŸ¬ ë™ ì •ë³´ ì €ì¥
                },
                'data_source': 'openseoul',
                'geo_extra': address_info['geo_extra']
            }
            self.normalized_facilities.append(facility_data)
        logger.info(f"ê³µì› ë°ì´í„° ì •ê·œí™” ì™„ë£Œ: {len(self.normalized_facilities)}ê°œ")

    def _normalize_subway_stations(self, file_path: Path):
        """ì§€í•˜ì² ì—­ ë°ì´í„° ì •ê·œí™” (ì—­ì •ë³´ + ì£¼ì†Œ CSV ë§¤í•‘ + ì£¼ì†Œ ì •ê·œí™”)"""
        if not file_path.exists():
            logger.warning(f"ì§€í•˜ì² ì—­ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
            return

        # 1. ì§€í•˜ì² ì—­ ì •ë³´ íŒŒì¼ ë¡œë“œ
        df_stn = pd.read_csv(file_path, encoding="utf-8", dtype=str)
        logger.info(f"ì§€í•˜ì² ì—­ ë°ì´í„° ë¡œë“œ: {len(df_stn)}ê°œ")

        # 2. ì£¼ì†Œ ì •ë³´ íŒŒì¼ ë¡œë“œ (StationAdresTelno)
        addr_file = self.data_dir / "seoul_StationAdresTelno_20250921.csv"
        addr_map = {}
        if addr_file.exists():
            df_addr = pd.read_csv(addr_file, encoding="utf-8", dtype=str)

            # ì£¼ì†Œ ì»¬ëŸ¼ ìë™ íƒìƒ‰
            addr_col_candidates = ["OLD_ADDR", "OLD_ADDRESS", "ADDR", "ADDRESS"]
            addr_col = next((c for c in addr_col_candidates if c in df_addr.columns), None)

            if not addr_col:
                raise ValueError(f"ì£¼ì†Œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. df_addr.columns={df_addr.columns.tolist()}")

            if "SBWY_STNS_NM" not in df_addr.columns:
                raise ValueError(f"'SBWY_STNS_NM' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. df_addr.columns={df_addr.columns.tolist()}")

            # "ì—­" ì œê±° ë° ê´„í˜¸ ë‚´ìš© ì œê±° í›„ ë§¤í•‘
            import re
            station_names_cleaned = df_addr["SBWY_STNS_NM"].astype(str).str.replace("ì—­", "").str.strip()
            # ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì œê±° (ì˜ˆ: "ì¶©ì •ë¡œ(ê²½ê¸°ëŒ€ì…êµ¬)" â†’ "ì¶©ì •ë¡œ")
            station_names_cleaned = station_names_cleaned.apply(lambda x: re.sub(r'\([^)]*\)', '', x).strip())
            
            addr_map = dict(
                zip(
                    station_names_cleaned,
                    df_addr[addr_col].astype(str).str.strip()
                )
            )
            logger.info(f"ì§€í•˜ì² ì—­ ì£¼ì†Œ ë°ì´í„° ë¡œë“œ: {len(addr_map)}ê°œ")
        else:
            logger.warning(f"ì§€í•˜ì² ì—­ ì£¼ì†Œ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {addr_file}")

        # 3. ì§€í•˜ì² ì—­ ë°ì´í„° ìˆœíšŒ
        for _, row in df_stn.iterrows():
            # (1) ì—­ëª…
            station_name_raw = str(row.get("STATION_NM", "")).strip()

            # (2) ì£¼ì†Œ ë§¤í•‘ (ì„œìš¸ë§Œ ì„±ê³µ â†’ ì„œìš¸ ì™¸ ì§€ì—­ì€ ë¹ˆê°’)
            address_raw = addr_map.get(station_name_raw, "")
            
            # (2-1) ì§€í•˜ì² ì—­ ì£¼ì†Œ ì „ì²˜ë¦¬
            if address_raw:
                # ì˜¤íƒ€ ìˆ˜ì •
                address_raw = address_raw.replace("ì„œìš¸íˆ­ë³„ì‹œ", "ì„œìš¸íŠ¹ë³„ì‹œ")
                # ì—­ëª… ì œê±° (ì˜ˆ: "ë´‰ì²œì—­(2í˜¸ì„ )" â†’ "ë´‰ì²œ")
                import re
                address_raw = re.sub(r'[ê°€-í£]+ì—­\([^)]*\)', '', address_raw).strip()
                # ê´„í˜¸ ì œê±°
                address_raw = re.sub(r'\([^)]*\)', '', address_raw).strip()
                # ê³µë°± ì •ë¦¬
                address_raw = re.sub(r'\s+', ' ', address_raw).strip()
            
            # (3) ì£¼ì†Œ ì •ê·œí™” (ì§€í•˜ì² ì—­ì€ ê°„ë‹¨í•œ íŒŒì‹±ë§Œ ì‚¬ìš©)
            if address_raw:
                address_info = self._parse_common_address(address_raw, create_norm=True)
                # ì„œìš¸íŠ¹ë³„ì‹œ ì •ë³´ ì¶”ê°€
                if 'ì„œìš¸íŠ¹ë³„ì‹œ' in address_raw or 'ì„œìš¸' in address_raw:
                    address_info['si_do'] = 'ì„œìš¸íŠ¹ë³„ì‹œ'
                    # address_normì— ì„œìš¸íŠ¹ë³„ì‹œ ì¶”ê°€
                    if address_info['address_norm'] and address_info['si_gun_gu']:
                        address_info['address_norm'] = f"ì„œìš¸íŠ¹ë³„ì‹œ {address_info['address_norm']}"
            else:
                address_info = {
                    'address_raw': address_raw,
                    'address_norm': None,
                    'si_do': None,
                    'si_gun_gu': None,
                    'si_gun_gu_dong': None,
                    'road_full': None,
                    'jibun_full': None,
                    'lat': None,
                    'lon': None,
                    'geo_extra': None
                }

            # (4) í˜¸ì„  ì •ë³´ (CSV ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜ì˜)
            line_name = str(row.get("LINE_NUM", "")).strip()

            # (5) í™˜ìŠ¹ ì²˜ë¦¬
            transfer_lines = []
            is_transfer = False
            if "," in line_name:
                transfer_lines = [ln.strip() for ln in line_name.split(",")]
                is_transfer = True

            # (6) ìµœì¢… ë°ì´í„° êµ¬ì„± (ì£¼ì†Œ í•„ë“œ ìˆœì„œ í†µì¼)
            station_data = {
                "station_name": station_name_raw,
                "line_name": line_name,  # âœ… CSV ì›ë³¸ ë°˜ì˜
                "station_code": str(row.get("FR_CODE", "")),
                "address_raw": address_info['address_raw'],
                "address_norm": address_info['address_norm'],
                "si_do": address_info['si_do'],
                "si_gun_gu": address_info['si_gun_gu'],
                "si_gun_gu_dong": address_info.get('si_gun_gu_dong'),
                "road_full": address_info.get('road_full'),
                "jibun_full": address_info.get('jibun_full'),
                "address_id": None,  # FKëŠ” DB ì ì¬ ë‹¨ê³„ì—ì„œ ì²˜ë¦¬
                "lat": address_info['lat'],
                "lon": address_info['lon'],
                "exit_count": None,
                "is_transfer": is_transfer,
                "transfer_lines": transfer_lines,
                "station_extra": {
                    "station_name_eng": str(row.get("STATION_NM_ENG", "")),
                    "station_name_chn": str(row.get("STATION_NM_CHN", "")),
                    "station_name_jpn": str(row.get("STATION_NM_JPN", "")),
                    "subway_code": str(row.get("SBWY_STNS_NM", "")),
                    "route_code": str(row.get("SBWY_ROUT_LN", "")),
                },
                "data_source": "seoul_subway",
                "geo_extra": address_info['geo_extra']
            }
            self.normalized_subway_stations.append(station_data)

        logger.info(f"ì§€í•˜ì² ì—­ ë°ì´í„° ì •ê·œí™” ì™„ë£Œ: {len(self.normalized_subway_stations)}ê°œ")

    def _normalize_pharmacies(self, file_path: Path):
        """ì•½êµ­ ë°ì´í„° ì •ê·œí™”"""
        if not file_path.exists():
            logger.warning(f"ì•½êµ­ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
            return

        df = pd.read_csv(file_path, encoding='utf-8')
        logger.info(f"ì•½êµ­ ë°ì´í„° ì •ê·œí™” ì‹œì‘: {len(df)}ê°œ")

        for _, row in df.iterrows():
            address_raw = str(row.get('DUTYADDR', ''))
            facility_name = str(row.get('DUTYNAME', ''))
            address_info = self._normalize_address(address_raw, facility_name, 'pharmacy')
            
            facility_data = {
                'category_id': self._get_category_id('pharmacy'),
                'name': facility_name,
                'address_raw': address_info['address_raw'],
                'address_norm': address_info['address_norm'],
                'si_do': address_info['si_do'],
                'si_gun_gu': address_info['si_gun_gu'],
                'si_gun_gu_dong': address_info.get('si_gun_gu_dong'),
                'road_full': address_info.get('road_full'),
                'jibun_full': address_info.get('jibun_full'),
                'lat': address_info['lat'] or self._safe_float(row.get('WGS84LAT')),
                'lon': address_info['lon'] or self._safe_float(row.get('WGS84LON')),
                'phone': str(row.get('DUTYTEL1', '')),
                'website': None,
                'operating_hours': None,
                'is_24h': False,
                'is_emergency': False,
                'capacity': None,
                'grade_level': None,
                'facility_extra': {
                    'pharmacy_id': str(row.get('HOSID', '')),
                    'district': str(row.get('SIGUN_NM', ''))
                },
                'data_source': 'openseoul',
                'geo_extra': address_info['geo_extra']
            }
            self.normalized_facilities.append(facility_data)
        logger.info(f"ì•½êµ­ ë°ì´í„° ì •ê·œí™” ì™„ë£Œ: {len(self.normalized_facilities)}ê°œ")

    def _normalize_kindergartens(self, file_path: Path):
        """ìœ ì¹˜ì› ë°ì´í„° ì •ê·œí™”"""
        if not file_path.exists():
            logger.warning(f"ìœ ì¹˜ì› íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
            return

        df = pd.read_csv(file_path, encoding='utf-8')
        logger.info(f"ìœ ì¹˜ì› ë°ì´í„° ì •ê·œí™” ì‹œì‘: {len(df)}ê°œ")

        for _, row in df.iterrows():
            address_raw = str(row.get('ADDR', ''))
            facility_name = str(row.get('KDGT_NM', ''))
            address_info = self._normalize_address(address_raw, facility_name, 'kindergarten')
            
            facility_data = {
                'category_id': self._get_category_id('childSchool'),
                'name': facility_name,
                'address_raw': address_info['address_raw'],
                'address_norm': address_info['address_norm'],
                'si_do': address_info['si_do'],
                'si_gun_gu': address_info['si_gun_gu'],
                'si_gun_gu_dong': address_info.get('si_gun_gu_dong'),
                'road_full': address_info.get('road_full'),
                'jibun_full': address_info.get('jibun_full'),
                'lat': address_info['lat'],
                'lon': address_info['lon'],
                'phone': str(row.get('TELNO', '')),
                'website': str(row.get('HMPG', '')),
                'operating_hours': None,
                'is_24h': False,
                'is_emergency': False,
                'capacity': self._safe_int(row.get('MIX_TDL_CNT')),
                'grade_level': None,
                'facility_extra': {
                    'foundation_type': str(row.get('FNDN_TYPE', ''))
                },
                'data_source': 'openseoul',
                'geo_extra': address_info['geo_extra']
            }
            self.normalized_facilities.append(facility_data)
        logger.info(f"ìœ ì¹˜ì› ë°ì´í„° ì •ê·œí™” ì™„ë£Œ: {len(self.normalized_facilities)}ê°œ")

    def _normalize_colleges(self, file_path: Path):
        """ëŒ€í•™ ë°ì´í„° ì •ê·œí™”"""
        if not file_path.exists():
            logger.warning(f"ëŒ€í•™ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
            return

        df = pd.read_csv(file_path, encoding='utf-8')
        logger.info(f"ëŒ€í•™ ë°ì´í„° ì •ê·œí™” ì‹œì‘: {len(df)}ê°œ")

        for _, row in df.iterrows():
            address_raw = str(row.get('ADD_KOR_ROAD', ''))
            facility_name = str(row.get('NAME_KOR', ''))
            address_info = self._normalize_address(address_raw, facility_name, 'college')
            
            facility_data = {
                'category_id': self._get_category_id('college'),
                'name': facility_name,
                'address_raw': address_info['address_raw'],
                'address_norm': address_info['address_norm'],
                'si_do': address_info['si_do'],
                'si_gun_gu': address_info['si_gun_gu'],
                'si_gun_gu_dong': address_info.get('si_gun_gu_dong'),
                'road_full': address_info.get('road_full'),
                'jibun_full': address_info.get('jibun_full'),
                'lat': address_info['lat'],
                'lon': address_info['lon'],
                'phone': str(row.get('TEL', '')),
                'website': str(row.get('HP', '')),
                'operating_hours': None,
                'is_24h': False,
                'is_emergency': False,
                'capacity': None,
                'grade_level': None,
                'facility_extra': {
                    'category': str(row.get('CATE1_NAME', '')),
                    'branch': str(row.get('BRANCH', '')),
                    'type': str(row.get('TYPE', ''))
                },
                'data_source': 'openseoul',
                'geo_extra': address_info['geo_extra']
            }
            self.normalized_facilities.append(facility_data)
        logger.info(f"ëŒ€í•™ ë°ì´í„° ì •ê·œí™” ì™„ë£Œ: {len(self.normalized_facilities)}ê°œ")


    def _normalize_bus_stops(self, file_path: Path):
        """ë²„ìŠ¤ì •ë¥˜ì†Œ ë°ì´í„° ì •ê·œí™” - ê²½ë„,ìœ„ë„ í˜•ì‹ìœ¼ë¡œ address_raw ì €ì¥"""
        if not file_path.exists():
            logger.warning(f"ë²„ìŠ¤ì •ë¥˜ì†Œ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
            return

        df = pd.read_csv(file_path, encoding='utf-8')
        logger.info(f"ë²„ìŠ¤ì •ë¥˜ì†Œ ë°ì´í„° ì •ê·œí™” ì‹œì‘: {len(df)}ê°œ")

        for _, row in df.iterrows():
            # ê²½ë„(XCRD), ìœ„ë„(YCRD)ë¥¼ 'ê²½ë„,ìœ„ë„' í˜•ì‹ìœ¼ë¡œ address_rawì— ì €ì¥
            x_coord = self._safe_float(row.get('XCRD'))
            y_coord = self._safe_float(row.get('YCRD'))
            
            if x_coord is not None and y_coord is not None:
                address_raw = f"{x_coord},{y_coord}"
            else:
                address_raw = ""
            
            facility_data = {
                'category_id': self._get_category_id('bus_stop'),
                'name': str(row.get('STOPS_NM', '')),  # ì •ë¥˜ì†Œëª…
                'address_raw': address_raw,
                'address_norm': None,  # ì¢Œí‘œ ê¸°ë°˜ì´ë¯€ë¡œ ì •ê·œí™” ë¶ˆê°€
                'si_do': None,
                'si_gun_gu': None,
                'si_gun_gu_dong': None,
                'road_full': None,
                'jibun_full': None,
                'lat': y_coord,  # ìœ„ë„
                'lon': x_coord,  # ê²½ë„
                'phone': None,
                'website': None,
                'operating_hours': None,
                'is_24h': False,
                'is_emergency': False,
                'capacity': None,
                'grade_level': None,
                'facility_extra': {
                    'stops_no': str(row.get('STOPS_NO', '')),
                    'node_id': str(row.get('NODE_ID', '')),
                    'stops_type': str(row.get('STOPS_TYPE', '')),
                    'x_coord': x_coord,
                    'y_coord': y_coord
                },
                'data_source': 'seoul_bus_stop',
                'geo_extra': None
            }
            self.normalized_facilities.append(facility_data)
        logger.info(f"ë²„ìŠ¤ì •ë¥˜ì†Œ ë°ì´í„° ì •ê·œí™” ì™„ë£Œ: {len(self.normalized_facilities)}ê°œ")

    def normalize_openseoul_data(self) -> Dict[str, List[Dict]]:
        """OpenSeoul CSV íŒŒì¼ë“¤ì„ ì •ê·œí™”"""
        openseoul_dir = self.data_dir  # backend/data/public-api/openseoul

        # ì–´ë¦°ì´ì§‘ ë°ì´í„°
        childcare_file = openseoul_dir / "seoul_ChildCareInfo_20250919.csv"
        self._normalize_childcare_centers(childcare_file)
        
        # ìœ ì¹˜ì› ë°ì´í„°
        kindergarten_file = openseoul_dir / "seoul_childSchoolInfo_20250919.csv"
        self._normalize_kindergartens(kindergarten_file)
        
        # í•™êµ ë°ì´í„° (ì´ˆì¤‘ê³ )
        school_file = openseoul_dir / "seoul_neisSchoolInfo_20250919.csv"
        self._normalize_schools(school_file)
        
        # ëŒ€í•™ ë°ì´í„°
        college_file = openseoul_dir / "seoul_SebcCollegeInfoKor_20250919.csv"
        self._normalize_colleges(college_file)
        
        # ê³µì› ë°ì´í„°
        park_file = openseoul_dir / "seoul_SearchParkInfoService_20250919.csv"
        self._normalize_parks(park_file)
        
        # ì§€í•˜ì² ì—­ ë°ì´í„°
        subway_file = openseoul_dir / "seoul_SearchSTNBySubwayLineInfo_20250919.csv"
        self._normalize_subway_stations(subway_file)
        
        # ì•½êµ­ ë°ì´í„°
        pharmacy_file = openseoul_dir / "seoul_TbPharmacyOperateInfo_20250919.csv"
        self._normalize_pharmacies(pharmacy_file)
        
        # ëŒ€í•™ ë°ì´í„°
        college_file = openseoul_dir / "seoul_SebcCollegeInfoKor_20250919.csv"
        self._normalize_colleges(college_file)


        # ë²„ìŠ¤ì •ë¥˜ì†Œ ë°ì´í„° (ìµœê·¼ ìˆ˜ì§‘ëœ íŒŒì¼)
        bus_stop_file = openseoul_dir / "seoul_busStopLocationXyInfo_20250921.csv"
        self._normalize_bus_stops(bus_stop_file)

        logger.info(f"ì´ {len(self.normalized_facilities)}ê°œì˜ ì‹œì„¤ ë°ì´í„°ì™€ {len(self.normalized_subway_stations)}ê°œì˜ ì§€í•˜ì² ì—­ ë°ì´í„° ì •ê·œí™” ì™„ë£Œ.")
        
        return {
            "public_facilities": self.normalized_facilities,
            "subway_stations": self.normalized_subway_stations,
            "failed_addresses": self.failed_addresses
        }
    
    def save_normalized_data(self, output_dir: Path) -> Path:
        """ì •ê·œí™”ëœ ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        import json
        from datetime import datetime
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ì •ê·œí™”ëœ ë°ì´í„° êµ¬ì„±
        # ì •ê·œí™”ëœ ë°ì´í„° êµ¬ì¡°í™”
        public_facilities_data = {
            "public_facilities": self.normalized_facilities,
            "metadata": {
                "normalized_at": datetime.now().isoformat(),
                "facilities_count": len(self.normalized_facilities),
                "failed_addresses_count": len(self.failed_addresses)
            }
        }
        
        subway_stations_data = {
            "subway_stations": self.normalized_subway_stations,
            "metadata": {
                "normalized_at": datetime.now().isoformat(),
                "subway_stations_count": len(self.normalized_subway_stations)
            }
        }
        
        # JSON íŒŒì¼ë¡œ ì €ì¥ (ë³„ë„ íŒŒì¼)
        public_facilities_file = output_dir / "public_facilities.json"
        with open(public_facilities_file, 'w', encoding='utf-8') as f:
            json.dump(public_facilities_data, f, ensure_ascii=False, indent=2)
        
        subway_stations_file = output_dir / "subway_stations.json"
        with open(subway_stations_file, 'w', encoding='utf-8') as f:
            json.dump(subway_stations_data, f, ensure_ascii=False, indent=2)
        
        # ì‹¤íŒ¨í•œ ì£¼ì†Œ ì •ê·œí™” ë°ì´í„° CSVë¡œ ì €ì¥
        if self.failed_addresses:
            failed_file = output_dir / "failed_addresses.csv"
            df_failed = pd.DataFrame(self.failed_addresses)
            df_failed.to_csv(failed_file, index=False, encoding='utf-8')
            logger.info(f"ì‹¤íŒ¨í•œ ì£¼ì†Œ ì •ê·œí™” ë°ì´í„° ì €ì¥: {failed_file}")
        
        # ë©”íƒ€ë°ì´í„° íŒŒì¼ ì €ì¥
        metadata_file = output_dir / "metadata.json"
        combined_metadata = {
            "normalized_at": datetime.now().isoformat(),
            "public_facilities_count": len(self.normalized_facilities),
            "subway_stations_count": len(self.normalized_subway_stations),
            "failed_addresses_count": len(self.failed_addresses)
        }
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(combined_metadata, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ì •ê·œí™”ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ:")
        logger.info(f"  - public_facilities.json: {len(self.normalized_facilities)}ê°œ")
        logger.info(f"  - subway_stations.json: {len(self.normalized_subway_stations)}ê°œ")
        logger.info(f"  - metadata.json: ë©”íƒ€ë°ì´í„°")
        
        return public_facilities_file, subway_stations_file

    def retry_failed_addresses(self, failed_csv_path: Path) -> Dict[str, List[Dict]]:
        """ì‹¤íŒ¨í•œ ì£¼ì†Œë“¤ë§Œ ë‹¤ì‹œ ì •ê·œí™” ì‹œë„"""
        logger.info(f"ì‹¤íŒ¨í•œ ì£¼ì†Œ ì¬ì •ê·œí™” ì‹œì‘: {failed_csv_path}")
        
        # ì‹¤íŒ¨í•œ ì£¼ì†Œ CSV ì½ê¸°
        df_failed = pd.read_csv(failed_csv_path, encoding='utf-8')
        logger.info(f"ì¬ì •ê·œí™” ëŒ€ìƒ: {len(df_failed)}ê°œ")
        
        # ì¬ì •ê·œí™”ëœ ë°ì´í„° ì €ì¥ìš©
        retry_facilities = []
        retry_failed_addresses = []
        
        for idx, row in df_failed.iterrows():
            facility_type = row['facility_type']
            facility_name = row['facility_name']
            address_raw = row['address_raw']
            
            logger.info(f"ì¬ì •ê·œí™” ì‹œë„ [{idx+1}/{len(df_failed)}]: {facility_name} - {address_raw}")
            
            # ì£¼ì†Œ ì •ê·œí™” ì‹œë„
            address_info = self._normalize_address(address_raw, facility_name, facility_type)
            
            if address_info['address_norm']:
                # ì •ê·œí™” ì„±ê³µ - ì‹œì„¤ ë°ì´í„° ìƒì„±
                facility_data = {
                    'category_id': self._get_category_id(facility_type),
                    'name': facility_name,
                    'address_raw': address_info['address_raw'],
                    'address_norm': address_info['address_norm'],
                    'si_do': address_info['si_do'],
                    'si_gun_gu': address_info['si_gun_gu'],
                    'si_gun_gu_dong': address_info.get('si_gun_gu_dong'),
                    'road_full': address_info.get('road_full'),
                    'jibun_full': address_info.get('jibun_full'),
                    'lat': address_info['lat'],
                    'lon': address_info['lon'],
                    'phone': None,
                    'website': None,
                    'operating_hours': None,
                    'is_24h': False,
                    'is_emergency': False,
                    'capacity': None,
                    'grade_level': None,
                    'facility_extra': {
                        'retry_success': True,
                        'original_failed_reason': row['error_reason']
                    },
                    'data_source': f'seoul_{facility_type}',
                    'geo_extra': address_info['geo_extra']
                }
                retry_facilities.append(facility_data)
                logger.info(f"âœ… ì¬ì •ê·œí™” ì„±ê³µ: {facility_name}")
            else:
                # ì—¬ì „íˆ ì‹¤íŒ¨
                failed_data = {
                    "facility_type": facility_type,
                    "facility_name": facility_name,
                    "address_raw": address_raw,
                    "address_processed": preprocess_address(address_raw),
                    "error_reason": "Retry failed - No match from Juso API",
                    "timestamp": pd.Timestamp.now().isoformat(),
                    "original_failed_reason": row['error_reason']
                }
                retry_failed_addresses.append(failed_data)
                logger.warning(f"âŒ ì¬ì •ê·œí™” ì‹¤íŒ¨: {facility_name}")
        
        logger.info(f"ì¬ì •ê·œí™” ì™„ë£Œ: ì„±ê³µ {len(retry_facilities)}ê°œ, ì‹¤íŒ¨ {len(retry_failed_addresses)}ê°œ")
        
        return {
            "retry_facilities": retry_facilities,
            "retry_failed_addresses": retry_failed_addresses
        }

# ì˜ˆì‹œ ì‚¬ìš©ë²• (CLIì—ì„œ í˜¸ì¶œë  ë•Œ)
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì‹¤í–‰í•œë‹¤ê³  ê°€ì •
    project_root = Path(__file__).resolve().parents[4]
    openseoul_data_path = project_root / "backend" / "data" / "public-api" / "openseoul"
    
    normalizer = InfraNormalizer(data_dir=openseoul_data_path)
    normalized_data = normalizer.normalize_openseoul_data()
    
    print("\n--- ì •ê·œí™”ëœ ê³µê³µì‹œì„¤ ë°ì´í„° (ì¼ë¶€) ---")
    for i, facility in enumerate(normalized_data["public_facilities"][:5]):
        print(f"{i+1}. {facility['name']} (Category ID: {facility['category_id']})")

    print("\n--- ì •ê·œí™”ëœ ì§€í•˜ì² ì—­ ë°ì´í„° (ì¼ë¶€) ---")
    for i, station in enumerate(normalized_data["subway_stations"][:5]):
        print(f"{i+1}. {station['station_name']} (Line: {station['line_name']})")
