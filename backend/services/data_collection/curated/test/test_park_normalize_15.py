#!/usr/bin/env python3
"""
ê³µì› ë°ì´í„° ë…¸ë§ë¼ì´ì§• í…ŒìŠ¤íŠ¸ (ìƒìœ„ 15ê°œ)
"""

import sys
from pathlib import Path
import json
from datetime import datetime
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent.parent.parent
sys.path.insert(0, str(project_root))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

# íŠ¹ì • ëª¨ë“ˆë“¤ì˜ ë¡œê¹… ë ˆë²¨ì„ INFOë¡œ ì„¤ì •
logging.getLogger('backend.services.data_collection.curated.infra_normalizer').setLevel(logging.INFO)
logging.getLogger('backend.services.data_collection.curated.address_api').setLevel(logging.INFO)

from backend.services.data_collection.curated.infra_normalizer import InfraNormalizer, read_csv_with_auto_encoding

def test_park_normalize_15():
    """ê³µì› ë°ì´í„° ë…¸ë§ë¼ì´ì§• í…ŒìŠ¤íŠ¸ (ìƒìœ„ 15ê°œ)"""
    
    print("ğŸŒ³ ê³µì› ë°ì´í„° ë…¸ë§ë¼ì´ì§• í…ŒìŠ¤íŠ¸ ì‹œì‘ (ìƒìœ„ 15ê°œ)")
    
    # ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì •
    data_dir = Path("backend/data/public-api/openseoul")
    
    # InfraNormalizer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    normalizer = InfraNormalizer(data_dir)
    
    # ê³µì› ë°ì´í„° íŒŒì¼ í™•ì¸
    park_file = data_dir / "seoul_SearchParkInfoService_20250919.csv"
    
    if not park_file.exists():
        print(f"âŒ ê³µì› ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {park_file}")
        return
    
    print(f"ğŸ“ ê³µì› ë°ì´í„° íŒŒì¼: {park_file}")
    
    try:
        # ê³µì› ë°ì´í„° ì½ê¸°
        df = read_csv_with_auto_encoding(park_file)
        print(f"ğŸ“Š ì „ì²´ ê³µì› ë°ì´í„°: {len(df)}ê°œ")
        
        # ìƒìœ„ 15ê°œë§Œ ì²˜ë¦¬
        limited_df = df.head(15)
        print(f"ğŸ¯ ì²˜ë¦¬í•  ê³µì› ë°ì´í„°: {len(limited_df)}ê°œ")
        
        # ê¸°ì¡´ normalized_facilities ì´ˆê¸°í™”
        normalizer.normalized_facilities = []
        
        # ê³µì› ë°ì´í„° ì •ê·œí™”
        for _, row in limited_df.iterrows():
            address_raw = str(row.get('P_ADDR', ''))
            facility_name = str(row.get('P_PARK', ''))
            
            print(f"\nğŸŒ³ ì²˜ë¦¬ ì¤‘: {facility_name}")
            print(f"ğŸ“ ì£¼ì†Œ: {address_raw}")
            
            # InfraNormalizerì˜ _normalize_address í•¨ìˆ˜ ì‚¬ìš©
            address_info = normalizer._normalize_address(address_raw, facility_name, 'park')
            
            # ì›ë³¸ ì¢Œí‘œë„ í™•ì¸ (ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼)
            original_lat = normalizer._safe_float(row.get('LATITUDE'))
            original_lon = normalizer._safe_float(row.get('LONGITUDE'))
            
            # ì¢Œí‘œ ìš°ì„ ìˆœìœ„: ë³€í™˜ëœ ì¢Œí‘œ > ì›ë³¸ ì¢Œí‘œ
            final_lat = address_info.get('lat') or original_lat
            final_lon = address_info.get('lon') or original_lon
            
            # ê³µì› ë°ì´í„° êµ¬ì¡° ìƒì„±
            facility_data = {
                'facility_id': normalizer._generate_facility_id('park'),
                'cd': normalizer._get_facility_cd('park'),
                'name': facility_name,
                'address_raw': address_info.get('address_raw', address_raw),
                'address_nm': address_info.get('address_nm', address_raw),
                'address_id': address_info.get('address_id'),
                'lat': final_lat,
                'lon': final_lon,
                'phone': str(row.get('P_ADMINTEL', '')) if str(row.get('P_ADMINTEL', '')).strip() else None,
                'website': None,
                'operating_hours': None,
                'is_24h': False,
                'is_emergency': False,
                'capacity': None,
                'grade_level': None,
                'facility_extra': {
                    'park_id': str(row.get('P_IDX', '')),
                    'park_type': str(row.get('P_PARK', '')),
                    'district': str(row.get('P_ZONE', '')),
                    'area': str(row.get('AREA', '')),
                    'open_date': str(row.get('OPEN_DT', '')),
                    'main_equip': str(row.get('MAIN_EQUIP', '')),
                    'main_plants': str(row.get('MAIN_PLANTS', '')),
                    'original_lat': original_lat,
                    'original_lon': original_lon
                },
                'data_source': 'openseoul'
            }
            normalizer.normalized_facilities.append(facility_data)
        
        print(f"\nâœ… ê³µì› ë°ì´í„° ì •ê·œí™” ì™„ë£Œ: {len(normalizer.normalized_facilities)}ê°œ")
        
        # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        output_data = {
            "parks": normalizer.normalized_facilities,
            "metadata": {
                "normalized_at": datetime.now().isoformat(),
                "total_parks": len(normalizer.normalized_facilities),
                "source_file": str(park_file),
                "description": "ê³µì› ë°ì´í„° ë…¸ë§ë¼ì´ì§• í…ŒìŠ¤íŠ¸ ê²°ê³¼ (ìƒìœ„ 15ê°œ)",
                "data_source": "openseoul"
            }
        }
        
        # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (test ë””ë ‰í† ë¦¬ ë‚´)
        output_file = Path("backend/services/data_collection/curated/test/park_normalize_15.json")
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
        
        # í†µê³„ ì¶œë ¥
        with_coords = sum(1 for p in normalizer.normalized_facilities if p.get('lat') is not None and p.get('lon') is not None)
        without_coords = len(normalizer.normalized_facilities) - with_coords
        
        print(f"\nğŸ“Š ê³µì› ë°ì´í„° í†µê³„:")
        print(f"   - ì „ì²´ ê³µì› ìˆ˜: {len(normalizer.normalized_facilities)}")
        print(f"   - ì¢Œí‘œ ìˆëŠ” ê³µì›: {with_coords}")
        print(f"   - ì¢Œí‘œ ì—†ëŠ” ê³µì›: {without_coords}")
        print(f"   - ì¢Œí‘œ ì •í™•ë„: {(with_coords/len(normalizer.normalized_facilities)*100):.1f}%")
        
        # ì¢Œí‘œê°€ ìˆëŠ” ê³µì›ë“¤ì˜ ì˜ˆì‹œ ì¶œë ¥
        if with_coords > 0:
            print(f"\nâœ… ì¢Œí‘œê°€ ìˆëŠ” ê³µì› ì˜ˆì‹œ:")
            for park in normalizer.normalized_facilities[:5]:  # ìƒìœ„ 5ê°œë§Œ ì¶œë ¥
                if park.get('lat') is not None and park.get('lon') is not None:
                    coord_source = "ë³€í™˜ëœ ì¢Œí‘œ" if park['facility_extra'].get('original_lat') != park['lat'] else "ì›ë³¸ ì¢Œí‘œ"
                    print(f"   - {park['name']}: lat={park['lat']}, lon={park['lon']} ({coord_source})")
        
        return output_file
        
    except Exception as e:
        print(f"âŒ ê³µì› ë°ì´í„° ì •ê·œí™” ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    result_file = test_park_normalize_15()
    if result_file:
        print(f"\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ê²°ê³¼ íŒŒì¼: {result_file}")
    else:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!")
