"""
- ë¡œì»¬ë°ì´í„° í¬í„¸ ë° ì„œìš¸ì—´ë¦°ë°ì´í„°ê´‘ì¥ API ìš”ì²­ ëª¨ë“ˆ
- config.py ì„¤ì • ê¸°ë°˜ìœ¼ë¡œ ë™ì‘
"""
from .config import (
    build_localdata_url,
    build_seoul_url,
    LOCALDATA_DELTA_START_KEY,
    LOCALDATA_DELTA_END_KEY,
    LOCALDATA_LOCALCODE_KEY,
    LOCALDATA_DEFAULT_PAGE_SIZE,
    LOCALDATA_DEFAULT_MAX_PAGES,
    SEOUL_DEFAULT_START,
    SEOUL_DEFAULT_END,
    CSV_DIR_LOCALDATA,
    CSV_DIR_OPENSEOUL,
    CSV_ENCODING
)

import requests
import logging
from typing import Dict, Any, List
from datetime import datetime, timedelta
import time

logger = logging.getLogger(__name__)

class BaseAPIClient:
    def __init__(self, api_key: str):
        self.api_key = api_key

    def _request_with_retry(self, url: str, params: Dict[str, Any] = None, headers: Dict[str, str] = None) -> requests.Response:
        for attempt in range(1, 4):  # ìµœëŒ€ 3íšŒ ì¬ì‹œë„
            try:
                response = requests.get(url, params=params, headers=headers, timeout=15)
                response.raise_for_status()
                return response
            except Exception as e:
                logger.warning(f"[ì‹œë„ {attempt}/3] ìš”ì²­ ì‹¤íŒ¨: {e}")
                if attempt == 3:
                    raise
                time.sleep(2.0 ** (attempt - 1))


class LocalDataClient(BaseAPIClient):
    def __init__(self, api_key: str):
        super().__init__(api_key)
        self.api_type = "TO0"
        self.default_page_size = LOCALDATA_DEFAULT_PAGE_SIZE
        self.default_max_pages = LOCALDATA_DEFAULT_MAX_PAGES

    def _fetch_single_page(self, url: str, params: Dict[str, Any], page: int) -> List[Dict[str, Any]]:
        response = self._request_with_retry(url, params=params)

        # ğŸ‘‰ ì‘ë‹µì´ JSONì´ ì•„ë‹ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë°©ì–´
        try:
            json_data = response.json()
        except ValueError:
            import xml.etree.ElementTree as ET
            root = ET.fromstring(response.text)
            error_msg = root.findtext(".//message") or "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"
            logger.error(f"[ğŸš« JSON ë””ì½”ë”© ì‹¤íŒ¨] XML ì‘ë‹µ ë©”ì‹œì§€: {error_msg}")
            return []

        # ğŸ‘‰ ì •ìƒ JSON ì‘ë‹µì¸ ê²½ìš° ê³„ì† ì§„í–‰
        if 'records' not in json_data:
            logger.warning(f"í˜ì´ì§€ {page}: 'records' í‚¤ ì—†ìŒ. ì „ì²´ ì‘ë‹µ: {json_data}")
            return []

        return json_data['records']



    def fetch_delta_data(self, start_date: str = None, end_date: str = None,
                        local_code: str = None, page_size: int = None,
                        max_pages: int = None) -> List[Dict[str, Any]]:
        from .config import default_delta_range

        if start_date is None or end_date is None:
            start_date, end_date = default_delta_range()
            logger.info(f"ë‚ ì§œ ë¯¸ì§€ì •ìœ¼ë¡œ ê¸°ë³¸ ë²”ìœ„ ì‚¬ìš©: {start_date} ~ {end_date}")
        if page_size is None:
            page_size = self.default_page_size
        if max_pages is None:
            max_pages = self.default_max_pages

        url = build_localdata_url(self.api_type)
        all_data = []

        logger.info(f"ë¡œì»¬ë°ì´í„° ë³€ë™ë¶„ ì¡°íšŒ ì‹œì‘")
        logger.info(f"  - ê¸°ê°„: {start_date} ~ {end_date}")
        logger.info(f"  - ì§€ìì²´ ì½”ë“œ: {local_code or 'ì „êµ­'}")
        logger.info(f"  - í˜ì´ì§€ í¬ê¸°: {page_size}, ìµœëŒ€ í˜ì´ì§€: {max_pages}")

        for page in range(1, max_pages + 1):
            logger.info(f"í˜ì´ì§€ {page}/{max_pages} ì¡°íšŒ ì¤‘...")
            params = {
                "authKey": self.api_key,
                LOCALDATA_DELTA_START_KEY: start_date,
                LOCALDATA_DELTA_END_KEY: end_date,
                "pageSize": page_size,
                "pageIndex": page
            }
            if local_code:
                params[LOCALDATA_LOCALCODE_KEY] = local_code

            page_data = self._fetch_single_page(url, params, page)

            if not page_data:
                logger.info(f"í˜ì´ì§€ {page}ì—ì„œ ë°ì´í„°ê°€ ì—†ì–´ ì¡°íšŒ ì¢…ë£Œ")
                break

            all_data.extend(page_data)
            logger.info(f"í˜ì´ì§€ {page} ì™„ë£Œ: {len(page_data)}ê±´ ìˆ˜ì§‘ (ëˆ„ì : {len(all_data)}ê±´)")

            if len(page_data) < page_size:
                logger.info(f"í˜ì´ì§€ {page}ê°€ ë§ˆì§€ë§‰ í˜ì´ì§€ (ë°ì´í„° {len(page_data)}ê°œ < í˜ì´ì§€ í¬ê¸° {page_size})")
                break

        logger.info(f"ë¡œì»¬ë°ì´í„° ë³€ë™ë¶„ ì¡°íšŒ ì™„ë£Œ: ì´ {len(all_data)}ê±´")
        return all_data


class SeoulOpenDataClient(BaseAPIClient):
    def __init__(self, api_key: str):
        super().__init__(api_key)

    def fetch_path_data(self, service_name: str = None, start: int = SEOUL_DEFAULT_START
                        , end: int = SEOUL_DEFAULT_END) -> List[Dict[str, Any]]:
        url = build_seoul_url(service_name=service_name, start=start, end=end)
        response = self._request_with_retry(url)
        
        # XML ì‘ë‹µ ì²˜ë¦¬
        if response.text.strip().startswith('<'):
            logger.error(f"API ì‘ë‹µì´ XML í˜•ì‹ì…ë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”: {response.text[:200]}")
            return []
        
        json_data = response.json()

        service_key = next(iter(json_data))
        records = json_data[service_key].get("row", [])

        if not isinstance(records, list):
            logger.warning(f"ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ í˜•ì‹: {records}")
            return []

        return records