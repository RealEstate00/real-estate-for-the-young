#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì¸í”„ë¼ ë°ì´í„° ì¬ì²˜ë¦¬ ëª¨ë“ˆ
ì‹¤íŒ¨í•œ ì£¼ì†Œ ì •ê·œí™” ë°ì´í„°ë¥¼ ì¬ì²˜ë¦¬í•˜ì—¬ ì™„ì „í•œ JSON ë°ì´í„° ìƒì„±
"""

import pandas as pd
from pathlib import Path
import json
import logging
from typing import List, Dict, Optional, Any
from datetime import datetime

from backend.services.data_collection.normalized.infra.infra_normalizer_NoJusoAPI import InfraNormalizer

logger = logging.getLogger(__name__)

class InfraNormalizerRetry:
    """ì¸í”„ë¼ ë°ì´í„° ì¬ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.normalizer = InfraNormalizer(data_dir)
        self.retry_facilities: List[Dict] = []
        self.retry_failed_addresses: List[Dict] = []
    
    def _get_next_facility_id(self, facility_type: str, output_dir: Path) -> str:
        """ê¸°ì¡´ íŒŒì¼ì—ì„œ ë§ˆì§€ë§‰ IDë¥¼ ì°¾ì•„ì„œ ë‹¤ìŒ ID ìƒì„±"""
        prefix = self.normalizer.facility_id_prefix_map.get(facility_type, 'fac')
        facilities_file = output_dir / "public_facilities.jsonl"
        
        if not facilities_file.exists():
            return f"{prefix}0001"
        
        # íŒŒì¼ì—ì„œ ë§ˆì§€ë§‰ ID ì°¾ê¸°
        last_id = None
        with open(facilities_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    data = json.loads(line)
                    if data.get('facility_id', '').startswith(prefix):
                        last_id = data['facility_id']
        
        if not last_id:
            return f"{prefix}0001"
        
        # ë§ˆì§€ë§‰ IDì—ì„œ ë²ˆí˜¸ ì¶”ì¶œí•˜ì—¬ ë‹¤ìŒ ë²ˆí˜¸ ìƒì„±
        last_num = int(last_id.replace(prefix, ''))
        next_num = last_num + 1
        
        return f"{prefix}{next_num:04d}"
    
    def _load_existing_failed_addresses(self, output_dir: Path) -> List[Dict]:
        """ê¸°ì¡´ ì‹¤íŒ¨ ë°ì´í„° ë¡œë“œ"""
        failed_file = output_dir / "failed_addresses.jsonl"
        existing_failed = []
        
        if failed_file.exists():
            with open(failed_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip():
                        existing_failed.append(json.loads(line))
        
        return existing_failed

    def _remove_successful_from_failed(self, output_dir: Path, success_names: List[str]):
        """ì„±ê³µí•œ ì‹œì„¤ë“¤ì„ ì‹¤íŒ¨ ëª©ë¡ì—ì„œ ì œê±°"""
        existing_failed = self._load_existing_failed_addresses(output_dir)
        
        # ì„±ê³µí•œ ì‹œì„¤ë“¤ ì œì™¸
        remaining_failed = [
            failed for failed in existing_failed 
            if failed['facility_name'] not in success_names
        ]
        
        # ì‹¤íŒ¨ íŒŒì¼ ì—…ë°ì´íŠ¸ (ë®ì–´ì“°ê¸°)
        failed_file = output_dir / "failed_addresses.jsonl"
        with open(failed_file, 'w', encoding='utf-8') as f:
            for failed in remaining_failed:
                f.write(json.dumps(failed, ensure_ascii=False) + '\n')
    
    def retry_failed_addresses_from_jsonl(self, failed_jsonl_path: Path, output_dir: Path) -> Dict[str, List[Dict]]:
        """JSONL íŒŒì¼ì—ì„œ ì‹¤íŒ¨í•œ ì£¼ì†Œë“¤ì„ ì½ì–´ì„œ ì¬ì •ê·œí™”"""
        
        if not failed_jsonl_path.exists():
            logger.error(f"ì‹¤íŒ¨ ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {failed_jsonl_path}")
            return {"retry_facilities": [], "retry_failed_addresses": []}
        
        logger.info(f"ì‹¤íŒ¨ ë°ì´í„° ì¬ì²˜ë¦¬ ì‹œì‘: {failed_jsonl_path}")
        
        retry_facilities = []
        retry_failed_addresses = []
        
        # progress.jsonl íŒŒì¼ ê²½ë¡œ ì„¤ì •
        progress_file = output_dir / "progress.jsonl"
        
        # JSONL íŒŒì¼ì„ í•œ ì¤„ì”© ì½ê¸° (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
        with open(failed_jsonl_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                try:
                    failed_data = json.loads(line.strip())
                    
                    # ì›ë³¸ íŒŒì¼ì—ì„œ í•´ë‹¹ í–‰ë§Œ ë¡œë“œ
                    original_file = failed_data['original_file']
                    row_index = failed_data['original_row_index']
                    
                    logger.info(f"ì¬ì²˜ë¦¬ [{line_num}]: {failed_data['facility_name']} - {failed_data['address_raw']}")
                    
                    # ì›ë³¸ CSVì—ì„œ í•´ë‹¹ í–‰ë§Œ ì½ê¸°
                    df = pd.read_csv(original_file, skiprows=range(1, row_index+1), nrows=1)
                    original_row = df.iloc[0]
                    
                    # ì£¼ì†Œ ì •ê·œí™” ì¬ì‹œë„
                    address_info = self.normalizer._normalize_address(
                        failed_data['address_raw'], 
                        failed_data['facility_name'], 
                        failed_data['facility_type']
                    )
                    
                    # progress.jsonlì— ê¸°ë¡ ì €ì¥
                    progress_data = {
                        'timestamp': datetime.now().isoformat(),
                        'operation': 'retry_failed_address',
                        'line_number': line_num,
                        'facility_name': failed_data['facility_name'],
                        'facility_type': failed_data['facility_type'],
                        'address_raw': failed_data['address_raw'],
                        'original_file': original_file,
                        'original_row_index': row_index,
                        'success': address_info.get('normalization_success', False),
                        'address_nm': address_info.get('address_nm'),
                        'lat': address_info.get('lat'),
                        'lon': address_info.get('lon'),
                        'error_reason': failed_data.get('error_reason', '') if not address_info.get('normalization_success', False) else None
                    }
                    
                    # progress.jsonlì— ì¶”ê°€
                    with open(progress_file, 'a', encoding='utf-8') as pf:
                        pf.write(json.dumps(progress_data, ensure_ascii=False) + '\n')
                    
                    if address_info.get('normalization_success', False):  # ì„±ê³µí•œ ê²½ìš°
                        # ì™„ì „í•œ ì‹œì„¤ ë°ì´í„° êµ¬ì„±
                        facility_data = self._build_complete_facility_data(
                            failed_data['facility_type'], 
                            original_row, 
                            address_info
                        )
                        retry_facilities.append(facility_data)
                        logger.info(f"âœ… ì¬ì •ê·œí™” ì„±ê³µ: {failed_data['facility_name']}")
                    else:
                        # ì—¬ì „íˆ ì‹¤íŒ¨
                        retry_failed_addresses.append(failed_data)
                        logger.warning(f"âŒ ì¬ì •ê·œí™” ì‹¤íŒ¨: {failed_data['facility_name']}")
                        
                except Exception as e:
                    logger.error(f"ì¬ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¼ì¸ {line_num}): {e}")
                    
                    # ì˜¤ë¥˜ë„ progress.jsonlì— ê¸°ë¡
                    error_progress_data = {
                        'timestamp': datetime.now().isoformat(),
                        'operation': 'retry_failed_address',
                        'line_number': line_num,
                        'facility_name': failed_data.get('facility_name', '') if 'failed_data' in locals() else '',
                        'facility_type': failed_data.get('facility_type', '') if 'failed_data' in locals() else '',
                        'address_raw': failed_data.get('address_raw', '') if 'failed_data' in locals() else '',
                        'original_file': failed_data.get('original_file', '') if 'failed_data' in locals() else '',
                        'original_row_index': failed_data.get('original_row_index', -1) if 'failed_data' in locals() else -1,
                        'success': False,
                        'error_reason': str(e)
                    }
                    
                    with open(progress_file, 'a', encoding='utf-8') as pf:
                        pf.write(json.dumps(error_progress_data, ensure_ascii=False) + '\n')
                    
                    continue
        
        logger.info(f"ì¬ì²˜ë¦¬ ì™„ë£Œ: ì„±ê³µ {len(retry_facilities)}ê°œ, ì‹¤íŒ¨ {len(retry_failed_addresses)}ê°œ")
        
        return {
            "retry_facilities": retry_facilities,
            "retry_failed_addresses": retry_failed_addresses
        }
    
    def _build_complete_facility_data(self, facility_type: str, original_row: pd.Series, 
                                     address_info: Dict) -> Dict:
        """ì›ë³¸ CSV ë°ì´í„°ì™€ ì •ê·œí™”ëœ ì£¼ì†Œ ì •ë³´ë¡œ ì™„ì „í•œ ì‹œì„¤ ë°ì´í„° êµ¬ì„±"""
        
        if facility_type == 'park':
            return {
                'facility_id': self.normalizer._generate_facility_id('park'),
                'cd': self.normalizer._get_facility_cd('park'),
                'name': original_row.get('P_PARK', ''),
                'address_raw': address_info['address_raw'],
                'address_nm': address_info['address_nm'],
                'address_id': address_info['address_id'],
                'lat': address_info['lat'] or self.normalizer._safe_float(original_row.get('LATITUDE')),
                'lon': address_info['lon'] or self.normalizer._safe_float(original_row.get('LONGITUDE')),
                'phone': original_row.get('P_ADMINTEL', ''),
                'website': original_row.get('TEMPLATE_URL', ''),
                'operating_hours': None,
                'is_24h': False,
                'is_emergency': False,
                'capacity': None,
                'grade_level': None,
                'facility_extra': {
                    'description': original_row.get('P_LIST_CONTENT', ''),
                    'area': self.normalizer._safe_float(original_row.get('AREA')),
                    'open_date': original_row.get('OPEN_DT', ''),
                    'main_equipment': original_row.get('MAIN_EQUIP', ''),
                    'main_plants': original_row.get('MAIN_PLANTS', ''),
                    'guidance': original_row.get('GUIDANCE', ''),
                    'visit_road': original_row.get('VISIT_ROAD', ''),
                    'use_refer': original_row.get('USE_REFER', '')
                },
                'data_source': 'openseoul'
            }
        elif facility_type == 'gym':
            return {
                'facility_id': self.normalizer._generate_facility_id('gym'),
                'cd': self.normalizer._get_facility_cd('gym'),
                'name': original_row.get('ì‹œì„¤ëª…', ''),
                'address_raw': address_info['address_raw'],
                'address_nm': address_info['address_nm'],
                'address_id': address_info['address_id'],
                'lat': address_info['lat'],
                'lon': address_info['lon'],
                'phone': original_row.get('ì—°ë½ì²˜', ''),
                'website': original_row.get('í™ˆí˜ì´ì§€', ''),
                'operating_hours': f"í‰ì¼: {original_row.get('ìš´ì˜ì‹œê°„_í‰ì¼', '')}, ì£¼ë§: {original_row.get('ìš´ì˜ì‹œê°„_ì£¼ë§', '')}, ê³µíœ´ì¼: {original_row.get('ìš´ì˜ì‹œê°„_ê³µíœ´ì¼', '')}",
                'capacity': self.normalizer._safe_int(original_row.get('ì‹œì„¤ê·œëª¨', '')),
                'facility_extra': {
                    'ì‹œì„¤ìœ í˜•': original_row.get('ì‹œì„¤ìœ í˜•', ''),
                    'ìš´ì˜ê¸°ê´€': original_row.get('ìš´ì˜ê¸°ê´€', ''),
                    'ì‹œì„¤ëŒ€ê´€ì—¬ë¶€': original_row.get('ì‹œì„¤ëŒ€ê´€ì—¬ë¶€', ''),
                    'ì‹œì„¤ì‚¬ìš©ë£Œ': original_row.get('ì‹œì„¤ì‚¬ìš©ë£Œ', ''),
                    'ì£¼ì°¨ì •ë³´': original_row.get('ì£¼ì°¨ì •ë³´', ''),
                    'ì‹œì„¤ì¢…ë¥˜': original_row.get('ì‹œì„¤ì¢…ë¥˜', ''),
                    'ì‹œì„¤ìš´ì˜ìƒíƒœ': original_row.get('ì‹œì„¤ìš´ì˜ìƒíƒœ', ''),
                    'ì‹œì„¤í¸ì˜ì‹œì„¤': original_row.get('ì‹œì„¤í¸ì˜ì‹œì„¤', ''),
                    'ë¹„ê³ ': original_row.get('ë¹„ê³ ', '')
                },
                'data_source': 'localdata'
            }
        elif facility_type == 'mart':
            return {
                'facility_id': self.normalizer._generate_facility_id('mart'),
                'cd': self.normalizer._get_facility_cd('mart'),
                'name': original_row.get('ìƒí˜¸ëª…', ''),
                'address_raw': address_info['address_raw'],
                'address_nm': address_info['address_nm'],
                'address_id': address_info['address_id'],
                'lat': address_info['lat'],
                'lon': address_info['lon'],
                'phone': original_row.get('ì „í™”ë²ˆí˜¸', ''),
                'website': original_row.get('í™ˆí˜ì´ì§€', ''),
                'operating_hours': None,
                'is_24h': False,
                'is_emergency': False,
                'capacity': None,
                'grade_level': None,
                'facility_extra': {
                    'ì—…ì¢…': original_row.get('ì—…ì¢…', ''),
                    'ìì¹˜êµ¬': original_row.get('ìì¹˜êµ¬', '')
                },
                'data_source': 'localdata'
            }
        elif facility_type == 'convenience':
            return {
                'facility_id': self.normalizer._generate_facility_id('convenience'),
                'cd': self.normalizer._get_facility_cd('convenience'),
                'name': original_row.get('ì‚¬ì—…ì¥ëª…', ''),
                'address_raw': address_info['address_raw'],
                'address_nm': address_info['address_nm'],
                'address_id': address_info['address_id'],
                'lat': address_info['lat'] or self.normalizer._safe_float(original_row.get('ì¢Œí‘œì •ë³´Y(EPSG5174)')),
                'lon': address_info['lon'] or self.normalizer._safe_float(original_row.get('ì¢Œí‘œì •ë³´X(EPSG5174)')),
                'phone': original_row.get('ì†Œì¬ì§€ì „í™”', ''),
                'website': original_row.get('í™ˆí˜ì´ì§€', ''),
                'operating_hours': None,
                'is_24h': False,
                'is_emergency': False,
                'capacity': None,
                'grade_level': None,
                'facility_extra': {
                    'ì†Œì¬ì§€ë©´ì ': original_row.get('ì†Œì¬ì§€ë©´ì ', ''),
                    'ë„ë¡œëª…ì „ì²´ì£¼ì†Œ': original_row.get('ë„ë¡œëª…ì „ì²´ì£¼ì†Œ', '')
                },
                'data_source': 'localdata'
            }
        elif facility_type == 'hospital':
            return {
                'facility_id': self.normalizer._generate_facility_id('hospital'),
                'cd': self.normalizer._get_facility_cd('hospital'),
                'name': original_row.get('ê¸°ê´€ëª…', ''),
                'address_raw': address_info['address_raw'],
                'address_nm': address_info['address_nm'],
                'address_id': address_info['address_id'],
                'lat': address_info['lat'],
                'lon': address_info['lon'],
                'phone': original_row.get('ì „í™”ë²ˆí˜¸', ''),
                'website': original_row.get('í™ˆí˜ì´ì§€', ''),
                'operating_hours': None,
                'is_24h': False,
                'is_emergency': 'ì‘ê¸‰' in str(original_row.get('ì§„ë£Œê³¼ëª©', '')),
                'facility_extra': {
                    'ì§„ë£Œê³¼ëª©': original_row.get('ì§„ë£Œê³¼ëª©', ''),
                    'ìì¹˜êµ¬': original_row.get('ìì¹˜êµ¬', ''),
                    'ì˜ë£Œê¸°ê´€ì¢…ë³„': original_row.get('ì˜ë£Œê¸°ê´€ì¢…ë³„', '')
                },
                'data_source': 'localdata'
            }
        else:
            # ê¸°ë³¸ êµ¬ì¡°
            return {
                'facility_id': self.normalizer._generate_facility_id(facility_type),
                'cd': self.normalizer._get_facility_cd(facility_type),
                'name': original_row.get('name', ''),
                'address_raw': address_info['address_raw'],
                'address_nm': address_info['address_nm'],
                'address_id': address_info['address_id'],
                'lat': address_info['lat'],
                'lon': address_info['lon'],
                'phone': None,
                'website': None,
                'operating_hours': None,
                'is_24h': False,
                'is_emergency': False,
                'capacity': None,
                'grade_level': None,
                'facility_extra': {},
                'data_source': 'openseoul'
            }
    
    def save_retry_results(self, output_dir: Path, retry_results: Dict[str, List[Dict]]):
        """ì¬ì²˜ë¦¬ ê²°ê³¼ë¥¼ ê¸°ì¡´ íŒŒì¼ì— ëˆ„ì  ì €ì¥"""
        
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. ì„±ê³µí•œ ì¬ì²˜ë¦¬ ë°ì´í„°ë¥¼ ê¸°ì¡´ íŒŒì¼ì— ì¶”ê°€ (append)
        if retry_results["retry_facilities"]:
            facilities_file = output_dir / "public_facilities.jsonl"
            
            # facility_idë¥¼ ê¸°ì¡´ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ë¶€ì—¬í•˜ê³  ì¶”ê°€
            success_names = []
            with open(facilities_file, 'a', encoding='utf-8') as f:  # 'a' = append ëª¨ë“œ
                for facility in retry_results["retry_facilities"]:
                    # facility_id ì¬ë¶€ì—¬
                    facility['facility_id'] = self._get_next_facility_id(
                        facility.get('cd', 'fac'), 
                        output_dir
                    )
                    success_names.append(facility['name'])
                    
                    # íŒŒì¼ì— ì¶”ê°€
                    f.write(json.dumps(facility, ensure_ascii=False) + '\n')
            
            logger.info(f"ì¬ì²˜ë¦¬ ì„±ê³µ ë°ì´í„° ì¶”ê°€: {len(retry_results['retry_facilities'])}ê°œ")
            
            # 2. ì„±ê³µí•œ ì‹œì„¤ë“¤ì„ ì‹¤íŒ¨ ëª©ë¡ì—ì„œ ì œê±°
            self._remove_successful_from_failed(output_dir, success_names)
            logger.info(f"ì‹¤íŒ¨ ëª©ë¡ì—ì„œ ì„±ê³µí•œ {len(success_names)}ê°œ ì œê±°")
        
        # 3. ì—¬ì „íˆ ì‹¤íŒ¨í•œ ë°ì´í„°ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ (ë³„ë„ ì²˜ë¦¬ ì—†ìŒ)
        if retry_results["retry_failed_addresses"]:
            logger.info(f"ì—¬ì „íˆ ì‹¤íŒ¨í•œ ë°ì´í„°: {len(retry_results['retry_failed_addresses'])}ê°œ (ê¸°ì¡´ íŒŒì¼ì— ìœ ì§€)")
        
        # 4. ìµœì¢… ìš”ì•½ì„ progress.jsonlì— ê¸°ë¡
        total_processed = len(retry_results["retry_facilities"]) + len(retry_results["retry_failed_addresses"])
        success_rate = (len(retry_results["retry_facilities"]) / total_processed * 100) if total_processed > 0 else 0
        
        summary_progress_data = {
            'timestamp': datetime.now().isoformat(),
            'operation': 'retry_summary',
            'total_processed': total_processed,
            'success_count': len(retry_results["retry_facilities"]),
            'failure_count': len(retry_results["retry_failed_addresses"]),
            'success_rate': success_rate,
            'summary': f"ì¬ì²˜ë¦¬ ì™„ë£Œ: ì „ì²´ {total_processed}ê°œ ì¤‘ ì„±ê³µ {len(retry_results['retry_facilities'])}ê°œ ({success_rate:.1f}%)"
        }
        
        progress_file = output_dir / "progress.jsonl"
        with open(progress_file, 'a', encoding='utf-8') as pf:
            pf.write(json.dumps(summary_progress_data, ensure_ascii=False) + '\n')
        
        logger.info(f"ğŸ“Š ì¬ì²˜ë¦¬ ìš”ì•½: ì „ì²´ {total_processed}ê°œ ì¤‘ ì„±ê³µ {len(retry_results['retry_facilities'])}ê°œ ({success_rate:.1f}%)")

# ì˜ˆì‹œ ì‚¬ìš©ë²•
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ì—ì„œ ìƒëŒ€ ê²½ë¡œë¡œ ê³„ì‚°
    script_dir = Path(__file__).resolve().parent
    project_root = script_dir.parents[3]  # backend/services/data_collection/normalized/infra -> backend
    data_path = project_root / "data" / "public-api" / "openseoul"
    output_dir = project_root / "data" / "normalized" / "infra"  # ê¸°ì¡´ íŒŒì¼ ìœ„ì¹˜
    
    # ì¬ì²˜ë¦¬ ì‹¤í–‰
    retry_normalizer = InfraNormalizerRetry(data_path)
    failed_jsonl_path = output_dir / "failed_addresses.jsonl"  # ê¸°ì¡´ ì‹¤íŒ¨ íŒŒì¼
    
    retry_results = retry_normalizer.retry_failed_addresses_from_jsonl(failed_jsonl_path, output_dir)
    retry_normalizer.save_retry_results(output_dir, retry_results)  # ê¸°ì¡´ íŒŒì¼ë“¤ ìˆ˜ì •


