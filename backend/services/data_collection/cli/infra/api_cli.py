#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
===========================================
API ë°ì´í„° ìˆ˜ì§‘, ì •ê·œí™” ë° DB ì ì¬ CLI
===========================================
ì„œìš¸ ì—´ë¦°ë°ì´í„°ê´‘ì¥ APIì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘, ì •ê·œí™”í•˜ê³  DBì— ì ì¬í•˜ëŠ” CLI
"""

import argparse
import logging
import sys
from pathlib import Path
from typing import Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).resolve().parents[5]
sys.path.insert(0, str(project_root))

from backend.libs.utils.paths import RAW_DIR, INFRA_NORMALIZED_DIR

# ëª¨ë“ˆ import
from backend.services.data_collection.infra.collector.get_open_csv import main as collect_api_data
from backend.services.data_collection.infra.normalized.infra_normalizer_NoJusoAPI import InfraNormalizer
from backend.services.loading.infra.infra_db_loader import JSONLDBLoader
from backend.services.db.common.db_utils import test_connection

logger = logging.getLogger(__name__)

def setup_logging(verbose: bool = False):
    """ë¡œê¹… ì„¤ì •"""
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

def collect_data(
    service: str = "all",
    output_dir: Optional[Path] = None,
    fresh: bool = False,
    verbose: bool = False
) -> bool:
    """API ë°ì´í„° ìˆ˜ì§‘"""
    setup_logging(verbose)
    
    if output_dir is None:
        output_dir = RAW_DIR / "api"
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    logger.info(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    logger.info(f"ğŸ” ìˆ˜ì§‘ ì„œë¹„ìŠ¤: {service}")
    logger.info(f"ğŸ”„ Fresh ëª¨ë“œ: {fresh}")
    
    try:
        # API ë°ì´í„° ìˆ˜ì§‘ ì‹¤í–‰
        collect_api_data(output_dir=str(output_dir))
        
        logger.info("âœ… API ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def normalize_data(
    csv_dir: Path,
    output_dir: Optional[Path] = None,
    verbose: bool = False
) -> bool:
    """CSV ë°ì´í„°ë¥¼ ì •ê·œí™”"""
    setup_logging(verbose)
    
    if not csv_dir.exists():
        logger.error(f"CSV ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {csv_dir}")
        return False
    
    if output_dir is None:
        output_dir = INFRA_NORMALIZED_DIR
    
    logger.info(f"ğŸ“ ì…ë ¥ CSV ë””ë ‰í† ë¦¬: {csv_dir}")
    logger.info(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    
    try:
        # ì •ê·œí™” ì‹¤í–‰
        normalizer = InfraNormalizer(data_dir=csv_dir)
        normalizer.normalize_openseoul_data(output_dir=output_dir, realtime_mode=True)
        
        logger.info("âœ… ì„œìš¸ API ë°ì´í„° ì •ê·œí™” ì™„ë£Œ!")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ì •ê·œí™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def load_data(
    normalized_dir: Path,
    db_url: Optional[str] = None,
    verbose: bool = False
) -> bool:
    """ì •ê·œí™”ëœ ë°ì´í„°ë¥¼ DBì— ì ì¬"""
    setup_logging(verbose)
    
    if not normalized_dir.exists():
        logger.error(f"ì •ê·œí™”ëœ ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {normalized_dir}")
        return False
    
    logger.info(f"ğŸ“ ì •ê·œí™”ëœ ë°ì´í„° ë””ë ‰í† ë¦¬: {normalized_dir}")
    
    try:
        # DB ì—°ê²° í…ŒìŠ¤íŠ¸
        if not test_connection():
            logger.error("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
            return False
        
        # ë°ì´í„° ë¡œë”©
        loader = JSONLDBLoader(db_url=db_url)
        loader.load_all_jsonl_files(normalized_dir)
        
        logger.info("âœ… ì„œìš¸ API ë°ì´í„° DB ì ì¬ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        logger.error(f"âŒ DB ì ì¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="API ë°ì´í„° ìˆ˜ì§‘, ì •ê·œí™” ë° DB ì ì¬ CLI",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  data-collection-infra api collect
  data-collection-infra api collect --service all
  data-collection-infra api load
  data-collection-infra api all
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´')
    
    # collect ëª…ë ¹ì–´
    collect_parser = subparsers.add_parser('collect', help='API ë°ì´í„° ìˆ˜ì§‘')
    collect_parser.add_argument(
        '--service',
        default='all',
        help='ìˆ˜ì§‘í•  ì„œë¹„ìŠ¤ (ê¸°ë³¸ê°’: all)'
    )
    collect_parser.add_argument(
        '--output-dir',
        type=Path,
        help='ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: backend/data/raw/api)'
    )
    collect_parser.add_argument(
        '--fresh',
        action='store_true',
        help='ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ìƒˆë¡œ ìˆ˜ì§‘'
    )
    collect_parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='ìƒì„¸ ë¡œê·¸ ì¶œë ¥'
    )
    
    
    # load ëª…ë ¹ì–´
    load_parser = subparsers.add_parser('load', help='ì •ê·œí™”ëœ ë°ì´í„°ë¥¼ DBì— ì ì¬')
    load_parser.add_argument(
        '--normalized-dir',
        type=Path,
        default=INFRA_NORMALIZED_DIR,
        help='ì •ê·œí™”ëœ ë°ì´í„° ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: backend/data/normalized/infra)'
    )
    load_parser.add_argument(
        '--db-url',
        help='ë°ì´í„°ë² ì´ìŠ¤ URL (ê¸°ë³¸ê°’: DATABASE_URL í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)'
    )
    load_parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='ìƒì„¸ ë¡œê·¸ ì¶œë ¥'
    )
    
    # all ëª…ë ¹ì–´
    all_parser = subparsers.add_parser('all', help='ìˆ˜ì§‘ ë° DB ì ì¬ ëª¨ë‘ ì‹¤í–‰')
    all_parser.add_argument(
        '--service',
        default='all',
        help='ìˆ˜ì§‘í•  ì„œë¹„ìŠ¤ (ê¸°ë³¸ê°’: all)'
    )
    all_parser.add_argument(
        '--csv-dir',
        type=Path,
        help='CSV ë°ì´í„° ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: backend/data/raw/api)'
    )
    all_parser.add_argument(
        '--normalized-dir',
        type=Path,
        help='ì •ê·œí™”ëœ ë°ì´í„° ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: backend/data/normalized/infra)'
    )
    all_parser.add_argument(
        '--db-url',
        help='ë°ì´í„°ë² ì´ìŠ¤ URL (ê¸°ë³¸ê°’: DATABASE_URL í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)'
    )
    all_parser.add_argument(
        '--fresh',
        action='store_true',
        help='ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ìƒˆë¡œ ìˆ˜ì§‘'
    )
    all_parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='ìƒì„¸ ë¡œê·¸ ì¶œë ¥'
    )
    
    args = parser.parse_args()
    
    if args.command == 'collect':
        success = collect_data(
            service=args.service,
            output_dir=args.output_dir,
            fresh=args.fresh,
            verbose=args.verbose
        )
        sys.exit(0 if success else 1)
        
    elif args.command == 'load':
        success = load_data(
            normalized_dir=args.normalized_dir,
            db_url=args.db_url,
            verbose=args.verbose
        )
        sys.exit(0 if success else 1)
        
    elif args.command == 'all':
        # ìˆ˜ì§‘ ì‹¤í–‰
        csv_dir = args.csv_dir or RAW_DIR / "api"
        success1 = collect_data(
            service=args.service,
            output_dir=csv_dir,
            fresh=args.fresh,
            verbose=args.verbose
        )
        
        if not success1:
            logger.error("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ë¡œ ì¸í•´ DB ì ì¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤")
            sys.exit(1)
        
        # DB ì ì¬ ì‹¤í–‰ (ì •ê·œí™”ëœ ë°ì´í„°ê°€ ì´ë¯¸ ìˆë‹¤ê³  ê°€ì •)
        normalized_dir = args.normalized_dir or INFRA_NORMALIZED_DIR
        success2 = load_data(
            normalized_dir=normalized_dir,
            db_url=args.db_url,
            verbose=args.verbose
        )
        
        sys.exit(0 if success2 else 1)
        
    else:
        parser.print_help()

if __name__ == "__main__":
    main()