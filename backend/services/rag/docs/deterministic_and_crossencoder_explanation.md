# 결정론적 구동(Deterministic Operation)과 Cross-Encoder 설명

## 1. 결정론적 구동(Deterministic Operation)이란?

### 정의

**결정론적 구동**은 동일한 입력에 대해 항상 동일한 출력을 보장하는 시스템 동작 방식입니다. 즉, 랜덤 요소를 제거하여 실행마다 일관된 결과를 생성합니다.

### 현재 구현된 방식

```python
# encoder.py에서 구현된 결정론적 모드
def set_deterministic_mode(seed: int = 42):
    """임베딩 생성의 결정론적 동작 설정"""
    torch.manual_seed(seed)           # PyTorch 랜덤 시드 고정
    np.random.seed(seed)              # NumPy 랜덤 시드 고정
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)  # CUDA 랜덤 시드 고정
        torch.backends.cudnn.deterministic = True   # CUDA 연산 결정론적 보장
        torch.backends.cudnn.benchmark = False       # 최적화 비활성화
```

### 작동 원리

1. **랜덤 시드 고정**: 모든 랜덤 연산의 시작점을 동일하게 설정
2. **CUDA 결정론적 모드**: GPU 연산도 일관된 결과 보장
3. **모델 eval 모드**: Dropout 등 비결정론적 레이어 비활성화

### 장점 (긍정적 측면)

✅ **재현 가능성 (Reproducibility)**

- 동일한 질문에 대해 항상 같은 유사도 점수와 순서를 얻음
- 연구 및 실험에서 필수적
- 버그 추적과 성능 분석이 쉬움

✅ **디버깅 용이성**

- 문제 발생 시 동일한 조건에서 재현 가능
- 결과 비교와 검증이 정확함

✅ **일관된 사용자 경험**

- 사용자가 같은 질문을 반복해도 동일한 결과
- 신뢰성 향상

✅ **테스트 안정성**

- 자동화된 테스트가 안정적으로 작동
- CI/CD 파이프라인에서 신뢰할 수 있는 결과

### 단점 (부정적 측면)

❌ **성능 저하**

- `torch.backends.cudnn.benchmark = False`: CUDA 최적화 비활성화
- 일부 GPU 연산이 10-30% 느려질 수 있음
- 특히 대규모 배치 처리 시 체감 가능

**❌ 약간 다른 연산 결과**

- **비결정론적 연산을 사용하는 일부 최적화가 제한됨**
- **부동소수점 연산의 미세한 차이 가능**

❌ **하드웨어 의존성**

- 다른 하드웨어에서 완벽히 동일한 결과 보장 어려움
- GPU 모델, 드라이버, CUDA 버전에 따라 미세한 차이 가능

❌ **일부 학습 기법 비활성화**

- Dropout 등이 비활성화되어 학습 시 효과 감소 (현재는 추론만 사용하므로 문제 없음)

---

## 2. Cross-Encoder란?

### 정의

**Cross-Encoder**는 쿼리와 문서를 동시에 입력받아 두 텍스트 간의 상호작용(interaction)을 직접 모델링하여 관련성을 점수화하는 모델입니다.

### 현재 시스템: Bi-Encoder vs Cross-Encoder

#### 현재 사용 방식: Bi-Encoder (Dual-Encoder)

```
쿼리: "청년 전세대출 조건"
  ↓ [임베딩 모델]
쿼리 벡터: [0.1, 0.3, 0.5, ...]  (독립적 임베딩)

문서1: "청년 전세대출은..."
  ↓ [임베딩 모델]
문서1 벡터: [0.2, 0.4, 0.3, ...]  (독립적 임베딩)

  ↓ [코사인 유사도 계산]
유사도 점수: 0.85
```

**특징:**

- 쿼리와 문서를 각각 별도로 임베딩
- 벡터 간 유사도만 계산
- 빠른 검색 속도 (임베딩을 미리 계산하여 저장 가능)

#### Cross-Encoder 방식

```
쿼리: "청년 전세대출 조건"
문서1: "청년 전세대출은..."

  ↓ [Cross-Encoder 모델에 함께 입력]
[CLS] 청년 전세대출 조건 [SEP] 청년 전세대출은... [SEP]
  ↓
관련성 점수: 0.92 (더 정확한 상호작용 기반 점수)
```

**특징:**

- 쿼리와 문서를 하나의 입력으로 함께 처리
- Attention 메커니즘으로 단어 간 상호작용 모델링
- 더 정확한 관련성 판단

### Cross-Encoder의 장점

✅ **더 높은 정확도**

- 쿼리와 문서의 실제 의미적 상호작용을 학습
- "같은 단어지만 맥락이 다른 경우" 구분 가능
- 예: "은행" (금융기관) vs "은행" (강둑)

✅ **복잡한 질문 처리**

- 다중 조건, 부정 의미 등을 더 잘 이해
- 예: "청년이 아니면서도 받을 수 있는 전세대출"

✅ **리랭킹에 최적화**

- 검색 후 상위 N개 결과만 재평가하면 됨
- 전체 문서에 적용할 필요 없음

### Cross-Encoder의 단점

❌ **매우 느린 속도**

- 매 쿼리마다 쿼리+문서를 함께 모델에 입력해야 함
- Bi-Encoder보다 100-1000배 느릴 수 있음
- 예: 1000개 문서 검색 시
  - Bi-Encoder: 쿼리 임베딩 1회 + 미리 계산된 문서 임베딩 검색
  - Cross-Encoder: 쿼리+문서 쌍을 1000회 모델 실행

❌ **사전 계산 불가능**

- 문서 임베딩을 미리 계산할 수 없음
- 매번 실시간 계산 필요

❌ **높은 연산 비용**

- GPU 메모리와 연산량이 많음
- 대규모 검색 시스템에는 부적합

### 실제 사용 패턴: Hybrid 방식

대부분의 실용적 시스템은 **Bi-Encoder + Cross-Encoder 하이브리드**를 사용합니다:

```
1단계: Bi-Encoder로 빠른 후보 검색
   → 상위 100-1000개 문서 선별 (빠름)

2단계: Cross-Encoder로 리랭킹
   → 상위 100개만 Cross-Encoder로 재평가 (정확)

최종 결과: 상위 10개 문서 반환
```

### 현재 시스템에 Cross-Encoder 추가 시 고려사항

현재 시스템에는 Cross-Encoder가 없습니다. 추가하려면:

1. **리랭킹 단계에만 사용**

   - 현재 `KeywordReranker`, `SemanticReranker` 대신
   - `CrossEncoderReranker` 추가 가능

2. **모델 선택**

   - 예: `cross-encoder/ms-marco-MiniLM-L-12-v2`
   - 쿼리-문서 쌍을 입력받는 특수 모델

3. **성능 트레이드오프**

   - 정확도: ⬆️ 상승
   - 속도: ⬇️ 감소 (리랭킹 단계만이므로 제한적)

---

## 비교 요약

| 특성          | Bi-Encoder (현재)  | Cross-Encoder  |
| ------------- | ------------------ | -------------- |
| **속도**      | 매우 빠름 (밀리초) | 느림 (초 단위) |
| **정확도**    | 좋음               | 더 좋음        |
| **사전 계산** | 가능 (문서 임베딩) | 불가능         |
| **메모리**    | 적음               | 많음           |
| **사용 시점** | 초기 검색          | 리랭킹         |
| **적용 범위** | 전체 문서          | 상위 N개만     |

---

## 추천 사항

1. **현재는 Bi-Encoder 유지**

   - 대부분의 경우 충분히 좋은 성능
   - 빠른 응답 시간 중요

2. **정확도가 더 필요할 때**

   - Cross-Encoder를 리랭킹 단계에만 추가
   - 상위 20-50개 후보만 재평가

3. **결정론적 모드**

   - 현재대로 유지 (재현성 중요)
   - 성능 저하가 문제되면 선택적 비활성화 가능
