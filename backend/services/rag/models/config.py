#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì„ë² ë”© ëª¨ë¸ ì„¤ì • ë° íŒŒë¼ë¯¸í„° ê´€ë¦¬
5ê°€ì§€ HuggingFace ëª¨ë¸ì„ ì‰½ê²Œ êµì²´í•˜ê³  ë¹„êµí•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±
"""

from dataclasses import dataclass, field
from typing import Dict, Any, Optional
from enum import Enum


class EmbeddingModelType(str, Enum):
    """ì§€ì›í•˜ëŠ” ì„ë² ë”© ëª¨ë¸ íƒ€ì…"""
    MULTILINGUAL_E5_SMALL = "intfloat/multilingual-e5-small"
    KAKAOBANK_DEBERTA = "kakaobank/kf-deberta-base"
    QWEN_EMBEDDING = "Qwen/Qwen3-Embedding-0.6B"
    EMBEDDING_GEMMA = "google/embeddinggemma-300m"


@dataclass
class ModelConfig:
    """ê°œë³„ ëª¨ë¸ ì„¤ì •"""
    model_name: str
    display_name: str
    dimension: int
    max_seq_length: int
    batch_size: int
    normalize_embeddings: bool
    pooling_mode: str  # 'mean', 'cls', 'max', 'last_token'
    trust_remote_code: bool
    device: str = "cuda"  # "cuda" or "cpu"

    # ëª¨ë¸ë³„ íŠ¹ìˆ˜ íŒŒë¼ë¯¸í„°
    extra_params: Dict[str, Any] = field(default_factory=dict)

    # ê²€ìƒ‰ ì„±ëŠ¥ ë©”íƒ€ì •ë³´
    notes: str = ""


# ============================================================================
# ëª¨ë¸ë³„ ìµœì í™” íŒŒë¼ë¯¸í„° ì„¤ì •
# ============================================================================

MODEL_CONFIGS: Dict[EmbeddingModelType, ModelConfig] = {

    # 1. Multilingual E5 Small (ê²½ëŸ‰, ë¹ ë¥¸ ì†ë„)
    EmbeddingModelType.MULTILINGUAL_E5_SMALL: ModelConfig(
        model_name="intfloat/multilingual-e5-small",
        display_name="E5-Small (Multilingual)",
        dimension=384,
        max_seq_length=512,
        batch_size=64,
        normalize_embeddings=True,
        pooling_mode="mean",
        trust_remote_code=False,
        extra_params={
            "query_prefix": "query: ",  # E5 ëª¨ë¸ì€ ì¿¼ë¦¬ì— prefix í•„ìˆ˜
            "passage_prefix": "passage: ",  # ë¬¸ì„œì—ë„ prefix í•„ìˆ˜
            "torch_dtype": "float32"  # E5ëŠ” float32 ê¶Œì¥
        },
        notes="ê²½ëŸ‰ ëª¨ë¸, ë¹ ë¥¸ ì¶”ë¡  ì†ë„, 100ê°œ ì–¸ì–´ ì§€ì›, prefix í•„ìˆ˜ ì‚¬ìš©"
    ),

    # 2. KakaoBank KF-DeBERTa Base (í•œêµ­ì–´ íŠ¹í™”)
    EmbeddingModelType.KAKAOBANK_DEBERTA: ModelConfig(
        model_name="kakaobank/kf-deberta-base",
        display_name="KakaoBank DeBERTa",
        dimension=768,
        max_seq_length=512,
        batch_size=32,
        normalize_embeddings=True,
        pooling_mode="mean",
        trust_remote_code=False,
        extra_params={
            "use_auth_token": False,
            "torch_dtype": "float32"
        },
        notes="í•œêµ­ì–´ ê¸ˆìœµ ë°ì´í„° íŠ¹í™”, MIT ë¼ì´ì„ ìŠ¤, DeBERTa-v2 ì•„í‚¤í…ì²˜"
    ),

    # 3. Qwen3 Embedding 0.6B (ê³ ì„±ëŠ¥, ê¸´ ë¬¸ë§¥)
    EmbeddingModelType.QWEN_EMBEDDING: ModelConfig(
        model_name="Qwen/Qwen3-Embedding-0.6B",
        display_name="Qwen3 Embedding 0.6B",
        dimension=1024,  # ê¸°ë³¸ 1024, MRLë¡œ 32~1024 ê°€ë³€ ì§€ì›
        max_seq_length=32768,  # 32k í† í° ì§€ì› (ë§¤ìš° ê¸´ ë¬¸ë§¥)
        batch_size=16,
        normalize_embeddings=True,
        pooling_mode="last_token",  # Qwen3ëŠ” last token pooling ì‚¬ìš©
        trust_remote_code=True,
        extra_params={
            "padding_side": "left",  # Qwen3ëŠ” left padding í•„ìˆ˜
            "torch_dtype": "float16",  # float16 ê¶Œì¥
            "attn_implementation": "flash_attention_2",  # FlashAttention2 ì§€ì›
            "query_instruction": "Instruct: Given a web search query, retrieve relevant passages that answer the query\nQuery: ",  # ì¿¼ë¦¬ìš© instruction
            "matryoshka_dims": [32, 64, 128, 256, 512, 1024]  # MRL ì§€ì› ì°¨ì›
        },
        notes="MTEB 1ìœ„, 100ê°œ ì–¸ì–´, 32k ë¬¸ë§¥, MRL ì§€ì›, instruction-aware"
    ),

    # 4. Google EmbeddingGemma 300M
    EmbeddingModelType.EMBEDDING_GEMMA: ModelConfig(
        model_name="google/embeddinggemma-300m",
        display_name="EmbeddingGemma 300M",
        dimension=768,  # ê³ ì • 768ì°¨ì› ì‚¬ìš© (MRL ë¹„í™œì„±í™”)
        max_seq_length=2048,  # 2048 í† í°
        batch_size=32,
        normalize_embeddings=True,
        pooling_mode="mean",
        trust_remote_code=True,
        extra_params={
            "torch_dtype": "bfloat16",  # float16 ë¯¸ì§€ì›, bfloat16 ë˜ëŠ” float32 ì‚¬ìš©
            "matryoshka_dims": [768],  # MRL ë¹„í™œì„±í™”, 768ì°¨ì›ë§Œ ì‚¬ìš©
            "task_prompts": {
                "retrieval_query": "task: search result | query: ",
                "retrieval_document": "title: none | text: ",
                "classification": "task: classification | query: ",
                "clustering": "task: clustering | query: ",
                "similarity": "task: sentence similarity | query: "
            }
        },
        notes="Google Gemma3 ê¸°ë°˜, 100ê°œ ì–¸ì–´, task-specific prompts, 768ì°¨ì› ê³ ì •"
    ),

}


# ============================================================================
# ë¹„êµ ì‹¤í—˜ ì„¤ì •
# ============================================================================

@dataclass
class ExperimentConfig:
    """ì„ë² ë”© ëª¨ë¸ ë¹„êµ ì‹¤í—˜ ì„¤ì •"""

    # í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ ëª©ë¡
    models_to_test: list[EmbeddingModelType] = field(
        default_factory=lambda: list(EmbeddingModelType)
    )

    # ê²€ìƒ‰ íŒŒë¼ë¯¸í„°
    top_k: int = 5
    similarity_threshold: float = 0.5

    # ê²°ê³¼ ì €ì¥ ê²½ë¡œ
    results_dir: str = "data/embedding_comparisons"

    # ë¡œê¹…
    save_embeddings: bool = False  # ì„ë² ë”© ë²¡í„° ì €ì¥ ì—¬ë¶€
    save_search_results: bool = True  # ê²€ìƒ‰ ê²°ê³¼ ì €ì¥ ì—¬ë¶€
    save_metrics: bool = True  # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì €ì¥ ì—¬ë¶€


# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================================

def get_model_config(model_type: EmbeddingModelType) -> ModelConfig:
    """ëª¨ë¸ íƒ€ì…ìœ¼ë¡œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°"""
    return MODEL_CONFIGS[model_type]


def get_all_model_names() -> list[str]:
    """ëª¨ë“  ëª¨ë¸ ì´ë¦„ ë°˜í™˜"""
    return [model.value for model in EmbeddingModelType]


def get_model_by_name(model_name: str) -> Optional[ModelConfig]:
    """ëª¨ë¸ ì´ë¦„ìœ¼ë¡œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°"""
    for model_type in EmbeddingModelType:
        if model_type.value == model_name:
            return MODEL_CONFIGS[model_type]
    return None


def print_model_comparison():
    """ëª¨ë¸ ë¹„êµ ì •ë³´ ì¶œë ¥"""
    print("=" * 100)
    print("ì„ë² ë”© ëª¨ë¸ ë¹„êµí‘œ")
    print("=" * 100)
    print(f"{'ëª¨ë¸ëª…':<35} {'ì°¨ì›':>6} {'ìµœëŒ€ê¸¸ì´':>8} {'ë°°ì¹˜':>6} {'Pooling':<12} {'ì„¤ëª…':<30}")
    print("-" * 100)

    for model_type, config in MODEL_CONFIGS.items():
        print(f"{config.display_name:<35} {config.dimension:>6} {config.max_seq_length:>8} "
              f"{config.batch_size:>6} {config.pooling_mode:<12} {config.notes[:28]:<30}")

    print("=" * 100)


def print_usage_recommendations():
    """ëª¨ë¸ë³„ ì‚¬ìš© ê¶Œì¥ì‚¬í•­ ì¶œë ¥"""
    print("\n" + "=" * 100)
    print("ğŸ“Œ ëª¨ë¸ë³„ ì‚¬ìš© ê¶Œì¥ì‚¬í•­")
    print("=" * 100)
    
    recommendations = {
        "E5-Small (Multilingual)": [
            "âœ… ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ ë° í…ŒìŠ¤íŠ¸",
            "âœ… ë¦¬ì†ŒìŠ¤ ì œì•½ í™˜ê²½ (ëª¨ë°”ì¼, ì—£ì§€)",
            "âœ… ë‹¤êµ­ì–´ ì§€ì› í•„ìš”ì‹œ",
            "âš ï¸ ì¿¼ë¦¬ì™€ ë¬¸ì„œì— ë°˜ë“œì‹œ 'query:' 'passage:' prefix ì¶”ê°€ í•„ìš”"
        ],
        "KakaoBank DeBERTa": [
            "âœ… í•œêµ­ì–´ ê¸ˆìœµ/ì£¼íƒ ë„ë©”ì¸ í…ìŠ¤íŠ¸",
            "âœ… ë†’ì€ í•œêµ­ì–´ ì´í•´ë„ í•„ìš”ì‹œ",
            "âœ… ìƒì—…ìš© í”„ë¡œì íŠ¸ (MIT ë¼ì´ì„ ìŠ¤)",
            "âš ï¸ 512 í† í° ì œí•œ"
        ],
        "Qwen3 Embedding 0.6B": [
            "âœ… ê¸´ ë¬¸ì„œ ì²˜ë¦¬ (ìµœëŒ€ 32k í† í°)",
            "âœ… ë†’ì€ ê²€ìƒ‰ ì •í™•ë„ í•„ìš”ì‹œ (MTEB 1ìœ„ê¸‰)",
            "âœ… MRLë¡œ ì„ë² ë”© ì°¨ì› ìœ ì—°í•œ ì¡°ì • í•„ìš”ì‹œ",
            "âš ï¸ left padding ë° instruction í•„ìˆ˜"
        ],
        "EmbeddingGemma 300M": [
            "âœ… task-specific ìµœì í™” í•„ìš”ì‹œ",
            "âœ… Google ìƒíƒœê³„ í†µí•©",
            "âœ… ê· í˜•ì¡íŒ ì„±ëŠ¥/ì†ë„",
            "âš ï¸ float16 ë¯¸ì§€ì› (bfloat16 ë˜ëŠ” float32 ì‚¬ìš©)"
        ],
        "Jina Embeddings v4": [
            "âœ… ë©€í‹°ëª¨ë‹¬ ê²€ìƒ‰ (í…ìŠ¤íŠ¸+ì´ë¯¸ì§€)",
            "âœ… ìµœì‹  ê¸°ìˆ  ë° ìµœê³  ì„±ëŠ¥ í•„ìš”ì‹œ",
            "âœ… ê¸´ ë¬¸ë§¥ ì²˜ë¦¬ (32k)",
            "âš ï¸ í° ëª¨ë¸ í¬ê¸° (3B ê¸°ë°˜), GPU ë©”ëª¨ë¦¬ ìš”êµ¬ëŸ‰ ë†’ìŒ"
        ]
    }
    
    for model_name, recs in recommendations.items():
        print(f"\nğŸ”¹ {model_name}")
        for rec in recs:
            print(f"  {rec}")
    
    print("=" * 100)


if __name__ == "__main__":
    # ëª¨ë¸ ë¹„êµ ì •ë³´ ì¶œë ¥
    print_model_comparison()

    # ê°œë³„ ëª¨ë¸ ì„¤ì • í™•ì¸
    print("\n\n=== ëª¨ë¸ë³„ ìƒì„¸ ì„¤ì • ===\n")
    for model_type in EmbeddingModelType:
        config = get_model_config(model_type)
        print(f"\n{'='*80}")
        print(f"ğŸ”¸ {config.display_name}")
        print(f"{'='*80}")
        print(f"  ëª¨ë¸ëª…: {config.model_name}")
        print(f"  ì°¨ì›: {config.dimension}")
        print(f"  ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´: {config.max_seq_length:,} í† í°")
        print(f"  ë°°ì¹˜ í¬ê¸°: {config.batch_size}")
        print(f"  ì •ê·œí™”: {config.normalize_embeddings}")
        print(f"  Pooling ë°©ì‹: {config.pooling_mode}")
        print(f"  Trust Remote Code: {config.trust_remote_code}")
        print(f"  ì¶”ê°€ íŒŒë¼ë¯¸í„°:")
        for key, value in config.extra_params.items():
            print(f"    - {key}: {value}")
        print(f"  íŠ¹ì§•: {config.notes}")
    
    # ì‚¬ìš© ê¶Œì¥ì‚¬í•­ ì¶œë ¥
    print_usage_recommendations()