#!/usr/bin/env python3
"""
ê°œì„ ëœ ì„ë² ë”© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ë” ì •í™•í•œ í‰ê°€ ë°©ì‹ê³¼ ë‹¨ê³„ë³„ ê²€ì¦
"""

import json
import logging
import csv
import time
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Tuple
import sys
import psycopg2
from psycopg2.extras import RealDictCursor

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ImprovedEmbeddingTester:
    def __init__(self, db_url: str = "postgresql://postgres:post1234@localhost:5432/rey"):
        """ê°œì„ ëœ ì„ë² ë”© í…ŒìŠ¤í„° ì´ˆê¸°í™”"""
        self.db_connection = {
            'host': 'localhost',
            'port': '5432',
            'database': 'rey',
            'user': 'postgres',
            'password': 'post1234'
        }
        
    def test_basic_embedding_operations(self):
        """1ë‹¨ê³„: ê¸°ë³¸ ì„ë² ë”© ì‘ì—… í…ŒìŠ¤íŠ¸"""
        logger.info("=== 1ë‹¨ê³„: ê¸°ë³¸ ì„ë² ë”© ì‘ì—… í…ŒìŠ¤íŠ¸ ===")
        
        try:
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ
            test_docs = [
                {"id": "test_1", "content": "ì‹ í˜¼ë¶€ë¶€ ì„ì°¨ë³´ì¦ê¸ˆ ì´ìì§€ì› ì‹ ì²­ ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤."},
                {"id": "test_2", "content": "ì²­ë…„ ì „ì„¸ëŒ€ì¶œ ì¡°ê±´ê³¼ ê¸ˆë¦¬ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."},
                {"id": "test_3", "content": "ì„œìš¸ì‹œ ì›”ì„¸ ì§€ì› ìê²© ìš”ê±´ì„ í™•ì¸í•˜ì„¸ìš”."}
            ]
            
            # sentence-transformers í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ëª¨ë¸ ì—†ì´ êµ¬ì¡°ë§Œ í™•ì¸)
            logger.info("ì„ë² ë”© ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸...")
            
            # PgVector í…Œì´ë¸” ìƒì„± í…ŒìŠ¤íŠ¸
            conn = psycopg2.connect(**self.db_connection)
            cur = conn.cursor()
            
            # í…ŒìŠ¤íŠ¸ìš© ì„ì‹œ í…Œì´ë¸”
            test_table = "test_embedding_operations"
            cur.execute(f"""
                DROP TABLE IF EXISTS housing.{test_table} CASCADE;
                CREATE TABLE housing.{test_table} (
                    id VARCHAR(255) PRIMARY KEY,
                    content TEXT NOT NULL,
                    embedding vector(768)
                );
            """)
            conn.commit()
            logger.info(f"í…ŒìŠ¤íŠ¸ í…Œì´ë¸” housing.{test_table} ìƒì„± ì™„ë£Œ")
            
            # ë”ë¯¸ ì„ë² ë”© ë°ì´í„° ì‚½ì… í…ŒìŠ¤íŠ¸
            dummy_embedding = [0.1] * 768  # 768ì°¨ì› ë”ë¯¸ ë²¡í„°
            
            for doc in test_docs:
                cur.execute(f"""
                    INSERT INTO housing.{test_table} (id, content, embedding)
                    VALUES (%s, %s, %s)
                """, (doc['id'], doc['content'], dummy_embedding))
            
            conn.commit()
            logger.info(f"{len(test_docs)}ê°œ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ì‚½ì… ì™„ë£Œ")
            
            # ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
            cur.execute(f"""
                SELECT id, content, 
                       1 - (embedding <=> %s) as similarity
                FROM housing.{test_table}
                ORDER BY embedding <=> %s
                LIMIT 3
            """, (dummy_embedding, dummy_embedding))
            
            results = cur.fetchall()
            logger.info(f"ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì„±ê³µ: {len(results)}ê°œ ê²°ê³¼")
            for result in results:
                logger.info(f"  - {result[0]}: {result[2]:.3f}")
            
            # ì •ë¦¬
            cur.execute(f"DROP TABLE IF EXISTS housing.{test_table} CASCADE")
            conn.commit()
            
            cur.close()
            conn.close()
            
            logger.info("âœ… 1ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: ê¸°ë³¸ ì„ë² ë”© ì‘ì—… ì •ìƒ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ 1ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def test_embedding_model_loading(self):
        """2ë‹¨ê³„: ì„ë² ë”© ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸"""
        logger.info("=== 2ë‹¨ê³„: ì„ë² ë”© ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸ ===")
        
        try:
            from sentence_transformers import SentenceTransformer
            
            # í…ŒìŠ¤íŠ¸í•  ëª¨ë¸ë“¤
            test_models = [
                "jhgan/ko-sroberta-multitask",
                "jhgan/ko-sbert-nli"
            ]
            
            results = {}
            
            for model_name in test_models:
                try:
                    logger.info(f"ëª¨ë¸ ë¡œë”© ì¤‘: {model_name}")
                    model = SentenceTransformer(model_name)
                    
                    # í…ŒìŠ¤íŠ¸ ë¬¸ì¥ìœ¼ë¡œ ì„ë² ë”© ìƒì„±
                    test_text = "ì‹ í˜¼ë¶€ë¶€ ì„ì°¨ë³´ì¦ê¸ˆ ì´ìì§€ì›"
                    embedding = model.encode(test_text)
                    
                    results[model_name] = {
                        'dimension': len(embedding),
                        'embedding_sample': embedding[:5].tolist(),  # ì²˜ìŒ 5ê°œ ê°’ë§Œ
                        'status': 'success'
                    }
                    
                    logger.info(f"âœ… {model_name}: {len(embedding)}ì°¨ì›")
                    
                except Exception as e:
                    results[model_name] = {
                        'status': 'failed',
                        'error': str(e)
                    }
                    logger.error(f"âŒ {model_name} ì‹¤íŒ¨: {e}")
            
            # ê²°ê³¼ ìš”ì•½
            successful_models = [name for name, result in results.items() if result['status'] == 'success']
            logger.info(f"ì„±ê³µí•œ ëª¨ë¸: {successful_models}")
            
            return len(successful_models) > 0
            
        except ImportError:
            logger.error("sentence-transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return False
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def test_vector_search_accuracy(self):
        """3ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰ ì •í™•ë„ í…ŒìŠ¤íŠ¸"""
        logger.info("=== 3ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰ ì •í™•ë„ í…ŒìŠ¤íŠ¸ ===")
        
        try:
            from sentence_transformers import SentenceTransformer
            
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°
            test_documents = [
                {"id": "doc_1", "content": "ì‹ í˜¼ë¶€ë¶€ ì„ì°¨ë³´ì¦ê¸ˆ ì´ìì§€ì› ì‹ ì²­ ë°©ë²•ê³¼ ì ˆì°¨ë¥¼ ì•ˆë‚´í•©ë‹ˆë‹¤."},
                {"id": "doc_2", "content": "ì²­ë…„ ì „ì„¸ëŒ€ì¶œ ì¡°ê±´, ê¸ˆë¦¬, ì†Œë“ ê¸°ì¤€ ë“±ì˜ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."},
                {"id": "doc_3", "content": "ì„œìš¸ì‹œ ì›”ì„¸ ì§€ì› ìê²© ìš”ê±´ê³¼ ëŒ€ìƒì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤."},
                {"id": "doc_4", "content": "ë²„íŒ€ëª© ì „ì„¸ìê¸ˆ ëŒ€ì¶œ í•œë„ì™€ ê¸ˆì•¡ ì •ë³´ì…ë‹ˆë‹¤."},
                {"id": "doc_5", "content": "ì£¼ê±°ê¸‰ì—¬ ìˆ˜ê¸‰ì ì„ì°¨ê¸‰ì—¬ ì‹ ì²­ ì¡°ê±´ì„ í™•ì¸í•˜ì„¸ìš”."}
            ]
            
            # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ì™€ ì˜ˆìƒ ê²°ê³¼
            test_cases = [
                {
                    "query": "ì‹ í˜¼ë¶€ë¶€ ì„ì°¨ë³´ì¦ê¸ˆ ì´ìì§€ì› ì‹ ì²­",
                    "expected_doc_id": "doc_1",
                    "min_similarity": 0.7
                },
                {
                    "query": "ì²­ë…„ ì „ì„¸ëŒ€ì¶œ ì¡°ê±´ê³¼ ê¸ˆë¦¬",
                    "expected_doc_id": "doc_2", 
                    "min_similarity": 0.7
                }
            ]
            
            # ëª¨ë¸ ë¡œë“œ
            model = SentenceTransformer("jhgan/ko-sroberta-multitask")
            
            # DB ì—°ê²°
            conn = psycopg2.connect(**self.db_connection)
            cur = conn.cursor()
            
            # í…ŒìŠ¤íŠ¸ í…Œì´ë¸” ìƒì„±
            test_table = "test_accuracy"
            cur.execute(f"""
                DROP TABLE IF EXISTS housing.{test_table} CASCADE;
                CREATE TABLE housing.{test_table} (
                    id VARCHAR(255) PRIMARY KEY,
                    content TEXT NOT NULL,
                    embedding vector(768)
                );
            """)
            
            # ë¬¸ì„œ ì„ë² ë”© ë° ì‚½ì…
            for doc in test_documents:
                embedding = model.encode(doc['content']).tolist()
                cur.execute(f"""
                    INSERT INTO housing.{test_table} (id, content, embedding)
                    VALUES (%s, %s, %s)
                """, (doc['id'], doc['content'], embedding))
            
            conn.commit()
            
            # ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
            passed_tests = 0
            total_tests = len(test_cases)
            
            for test_case in test_cases:
                query_embedding = model.encode(test_case['query']).tolist()
                
                cur.execute(f"""
                    SELECT id, content, 
                           1 - (embedding <=> %s) as similarity
                    FROM housing.{test_table}
                    ORDER BY embedding <=> %s
                    LIMIT 1
                """, (query_embedding, query_embedding))
                
                result = cur.fetchone()
                
                if result:
                    doc_id, content, similarity = result
                    
                    logger.info(f"ì¿¼ë¦¬: '{test_case['query']}'")
                    logger.info(f"  ì˜ˆìƒ ë¬¸ì„œ: {test_case['expected_doc_id']}")
                    logger.info(f"  ì‹¤ì œ ê²°ê³¼: {doc_id} (ìœ ì‚¬ë„: {similarity:.3f})")
                    
                    # ì •í™•ë„ ê²€ì¦
                    if (doc_id == test_case['expected_doc_id'] and 
                        similarity >= test_case['min_similarity']):
                        logger.info(f"  âœ… í…ŒìŠ¤íŠ¸ í†µê³¼")
                        passed_tests += 1
                    else:
                        logger.warning(f"  âš ï¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ (ìœ ì‚¬ë„ ë¶€ì¡± ë˜ëŠ” ë¬¸ì„œ ë¶ˆì¼ì¹˜)")
                else:
                    logger.error(f"  âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            
            # ì •ë¦¬
            cur.execute(f"DROP TABLE IF EXISTS housing.{test_table} CASCADE")
            conn.commit()
            cur.close()
            conn.close()
            
            accuracy = (passed_tests / total_tests) * 100
            logger.info(f"ê²€ìƒ‰ ì •í™•ë„: {passed_tests}/{total_tests} ({accuracy:.1f}%)")
            
            return accuracy >= 50  # 50% ì´ìƒì´ë©´ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
            
        except Exception as e:
            logger.error(f"ë²¡í„° ê²€ìƒ‰ ì •í™•ë„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def run_comprehensive_test(self):
        """ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("ğŸš€ ê°œì„ ëœ ì„ë² ë”© í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        test_results = {
            'basic_operations': self.test_basic_embedding_operations(),
            'model_loading': self.test_embedding_model_loading(), 
            'search_accuracy': self.test_vector_search_accuracy()
        }
        
        # ê²°ê³¼ ìš”ì•½
        logger.info("\n=== í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ===")
        for test_name, result in test_results.items():
            status = "âœ… í†µê³¼" if result else "âŒ ì‹¤íŒ¨"
            logger.info(f"{test_name}: {status}")
        
        all_passed = all(test_results.values())
        
        if all_passed:
            logger.info("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ì„ë² ë”© ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")
        else:
            logger.warning("\nâš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ì‹œìŠ¤í…œ ì ê²€ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        return test_results

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    tester = ImprovedEmbeddingTester()
    tester.run_comprehensive_test()

if __name__ == "__main__":
    main()

