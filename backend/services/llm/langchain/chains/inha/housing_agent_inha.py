"""
ì£¼íƒ ê²€ìƒ‰ Agent
í•˜ì´ë¸Œë¦¬ë“œ LLM ì§€ì› (ì„¤ì •ìœ¼ë¡œ í™œì„±í™”/ë¹„í™œì„±í™”)
"""

import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_core.output_parsers import StrOutputParser

from backend.services.llm.models.inha.llm_inha import agent_llm, response_llm, USE_HYBRID
from backend.services.llm.prompts.inha.prompt_inha import agent_prompt, rag_prompt
from backend.services.llm.utils.inha.housing_tools_inha import search_housing

import logging
logger = logging.getLogger(__name__)


# ============================================================================
# Agent ì„¤ì •
# ============================================================================

# ë„êµ¬ ëª©ë¡ (í–¥í›„ í™•ì¥ ê°€ëŠ¥)
tools = [search_housing]

# Agent ìƒì„± (ë„êµ¬ í˜¸ì¶œìš©)
agent = create_tool_calling_agent(agent_llm, tools, agent_prompt)
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,
    handle_parsing_errors=True,
    max_iterations=5
)


# ============================================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================================

def housing_assistant(query: str, use_hybrid: bool = USE_HYBRID) -> str:
    """
    ì£¼íƒ ê²€ìƒ‰ ì–´ì‹œìŠ¤í„´íŠ¸

    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        use_hybrid: í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€

    Returns:
        ë‹µë³€ í…ìŠ¤íŠ¸
    """
    try:
        if use_hybrid:
            # Phase 1: Agent LLMì´ ë„êµ¬ ì‹¤í–‰
            logger.info(f"[Hybrid Mode] Agent LLM ì‹¤í–‰: {query}")
            search_results = agent_executor.invoke({"input": query})

            # Phase 2: Response LLMì´ ìµœì¢… ë‹µë³€ ìƒì„±
            logger.info("[Hybrid Mode] Response LLM ë‹µë³€ ìƒì„±")
            final_response = (
                rag_prompt
                | response_llm
                | StrOutputParser()
            ).invoke({
                "context": search_results["output"],
                "query": query
            })
            return final_response
        else:
            # ë‹¨ì¼ LLM ëª¨ë“œ (ê¸°ë³¸)
            logger.info(f"[Single LLM Mode] Agent ì‹¤í–‰: {query}")
            result = agent_executor.invoke({"input": query})
            return result["output"]

    except Exception as e:
        logger.error(f"Housing assistant failed: {e}")
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"




# =============================================================================
# 5. í…ŒìŠ¤íŠ¸ ì½”ë“œ
# =============================================================================

if __name__ == "__main__":
    print("=" * 80)
    print("Agent ê¸°ë°˜ ì£¼íƒ ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        # "ê°•ë‚¨êµ¬ ì²­ë…„ì£¼íƒ ì¶”ì²œí•´ì¤˜",
        "ì„œì´ˆêµ¬ì— ìˆëŠ” ì£¼íƒ ëª¨ë‘ ë³´ì—¬ì¤˜",
        "ëŒ€ì¹˜ë™ ê·¼ì²˜ ì¢‹ì€ ì£¼íƒ ì¶”ì²œí•´ì¤˜"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n\nğŸ’¬ í…ŒìŠ¤íŠ¸ {i}: {query}")
        print("-" * 80)
        
        try:
            # Agent ì‹¤í–‰
            response = housing_assistant(query)
            print(response)
            
        except Exception as e:
            print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        
        print("-" * 80)
    
    print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")