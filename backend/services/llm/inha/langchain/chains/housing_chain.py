"""
LCEL Chain ê¸°ë°˜ ì£¼íƒ ì¶”ì²œ RAG ì‹œìŠ¤í…œ
Agent ì—†ì´ ë‹¨ìˆœ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ êµ¬í˜„

êµ¬ì„±:
1. Retriever: ChromaDBì—ì„œ ì£¼íƒ ê²€ìƒ‰
2. Prompt: ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•˜ì—¬ LLMì— ì „ë‹¬
3. LLM: Groq llama-3.3-70b-versatile ëª¨ë¸
4. Output Parser: ë¬¸ìì—´ íŒŒì‹±
"""

import sys
from pathlib import Path
import time

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_core.output_parsers import StrOutputParser

from backend.services.llm.models.llm import llm
from backend.services.llm.prompts.prompt import rag_prompt
from backend.services.llm.langchain.retrievers.retriever import GroqHousingRetriever

import logging
logger = logging.getLogger(__name__)

# =============================================================================
# 1. ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
# =============================================================================

# Retriever ìƒì„± (k=5ê°œ ê²°ê³¼, ìœ ì‚¬ë„ ë†’ì€ ìˆœ)
retriever = GroqHousingRetriever(k=5)

# Output Parser
output_parser = StrOutputParser()


# =============================================================================
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =============================================================================

def format_documents(docs):
    """ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ LLMì´ ì½ê¸° ì¢‹ì€ í˜•íƒœë¡œ í¬ë§·íŒ…"""
    if not docs:
        return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    formatted = []
    for i, doc in enumerate(docs, 1):
        metadata = doc.metadata
        housing_name = metadata.get('ì£¼íƒëª…', 'N/A')
        address = metadata.get('ë„ë¡œëª…ì£¼ì†Œ', metadata.get('ì§€ë²ˆì£¼ì†Œ', 'N/A'))
        district = metadata.get('ì‹œêµ°êµ¬', 'N/A')
        dong = metadata.get('ë™ëª…', 'N/A')
        tags = metadata.get('íƒœê·¸', metadata.get('theme', 'N/A'))
        similarity = metadata.get('similarity', 0)
        
        formatted.append(f"""
{i}. {housing_name}
   - ì£¼ì†Œ: {address}
   - ì§€ì—­: {district} {dong}
   - íŠ¹ì„±: {tags}
   - ìœ ì‚¬ë„: {similarity:.2f}
        """.strip())
    
    return "\n\n".join(formatted)


def retrieve_and_format(query: str) -> str:
    """ì¿¼ë¦¬ë¡œ ê²€ìƒ‰í•˜ê³  ê²°ê³¼ë¥¼ í¬ë§·íŒ…"""
    try:
        # Retriever í˜¸ì¶œ
        docs = retriever.invoke(query)
        
        # ê²€ìƒ‰ëœ ë¬¸ì„œ í¬ë§·íŒ…
        formatted_context = format_documents(docs)
        
        logger.info(f"Retrieved {len(docs)} documents for query: '{query}'")
        return formatted_context
        
    except Exception as e:
        logger.error(f"Retrieval failed: {e}")
        return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"


# =============================================================================
# 3. LCEL Chain ì •ì˜ (íŒŒì´í”„ë¼ì¸)
# =============================================================================

# ë©”ì¸ RAG Chain
rag_chain = (
    {
        "context": RunnableLambda(retrieve_and_format),  # ê²€ìƒ‰ & í¬ë§·íŒ…
        "query": RunnablePassthrough()                   # ì¿¼ë¦¬ ê·¸ëŒ€ë¡œ ì „ë‹¬
    }
    | rag_prompt      # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    | llm             # LLM ëª¨ë¸
    | output_parser   # ì¶œë ¥ íŒŒì‹±
)


# =============================================================================
# 4. í¸ì˜ í•¨ìˆ˜
# =============================================================================

def recommend_housing(query: str, memory=None) -> str:
    """ì£¼íƒ ì¶”ì²œ ì‹¤í–‰
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        memory: ConversationSummaryBufferMemory ê°ì²´ (ëŒ€í™” ë§¥ë½ ê´€ë¦¬)
    """
    try:
        logger.info(f"Housing recommendation for: '{query}'")
        response = rag_chain.invoke(query)
        
        # ë©”ëª¨ë¦¬ì— ëŒ€í™” ì €ì¥
        if memory:
            memory.save_context({"input": query}, {"output": response})
            logger.info("Conversation saved to memory")
        
        return response
    except Exception as e:
        logger.error(f"Recommendation failed: {e}")
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"


def stream_recommendation(query: str, memory=None):
    """ìŠ¤íŠ¸ë¦¬ë° ì£¼íƒ ì¶”ì²œ
    
    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        memory: ConversationSummaryBufferMemory ê°ì²´ (ëŒ€í™” ë§¥ë½ ê´€ë¦¬)
    """
    try:
        logger.info(f"Streaming recommendation for: '{query}'")
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ëª¨ì•„ì„œ ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ê¸° ìœ„í•´
        full_response = ""
        
        for chunk in rag_chain.stream(query):
            full_response += chunk
            yield chunk
        
        # ë©”ëª¨ë¦¬ì— ëŒ€í™” ì €ì¥
        if memory:
            memory.save_context({"input": query}, {"output": full_response})
            logger.info("Conversation saved to memory")
            
    except Exception as e:
        logger.error(f"Streaming failed: {e}")
        yield f"ì˜¤ë¥˜: {e}"


# =============================================================================
# 5. í…ŒìŠ¤íŠ¸ ì½”ë“œ
# =============================================================================

if __name__ == "__main__":
    print("=" * 80)
    print("LCEL Chain ê¸°ë°˜ ì£¼íƒ ì¶”ì²œ RAG ì‹œìŠ¤í…œ - ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤
    test_queries = [
        # "ê°•ë‚¨êµ¬ ì²­ë…„ì£¼íƒ ì¶”ì²œí•´ì¤˜",
        # "ì„œì´ˆêµ¬ì— ìˆëŠ” ì£¼íƒ ë³´ì—¬ì¤˜",
        "ëŒ€ì¹˜ë™ ê·¼ì²˜ ì¢‹ì€ ì£¼íƒ ì°¾ì•„ì¤˜"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n\nğŸ’¬ í…ŒìŠ¤íŠ¸ {i}: {query}")
        print("-" * 80)
        
        try:
            # ìŠ¤íŠ¸ë¦¬ë° ì¶”ì²œ
            for chunk in stream_recommendation(query):
                print(chunk, end="", flush=True)
                time.sleep(0.03)
            
        except Exception as e:
            print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
        
        print("\n" + "-" * 80)
    
    print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

