# ì£¼íƒ ì¶”ì²œ LangChain ì‹œìŠ¤í…œ

## ğŸ“Œ ê°œìš”

ì„œìš¸ì‹œ ì²­ë…„ ì£¼íƒ ê²€ìƒ‰ ë° ì¶”ì²œ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
- **2ê°€ì§€ ì‹¤í–‰ ë°©ì‹**: Chain (ë‹¨ìˆœ) vs Agent (ë˜‘ë˜‘)
- **2ê°€ì§€ LLM ëª¨ë“œ**: ë‹¨ì¼ (ë¹ ë¦„) vs í•˜ì´ë¸Œë¦¬ë“œ (ì •í™•)

---

## ğŸ”€ ì‹¤í–‰ ë°©ì‹

### 1. Chain ëª¨ë“œ (ë‹¨ìˆœ íŒŒì´í”„ë¼ì¸)
**íŒŒì¼**: `langchain/chains/inha/housing_chain_inha.py`

```python
ê²€ìƒ‰(ê³ ì • k=5) â†’ í”„ë¡¬í”„íŠ¸ â†’ LLM â†’ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
```

**íŠ¹ì§•**:
- âœ… ë¹ ë¥´ê³  ê°„ë‹¨
- âœ… ìŠ¤íŠ¸ë¦¬ë° ì§€ì›
- âŒ ê³ ì •ëœ ê²€ìƒ‰ (í•­ìƒ 5ê°œ)

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
from backend.services.llm.langchain.chains.inha.housing_chain_inha import stream_recommendation

for chunk in stream_recommendation("ì„œì´ˆêµ¬ ì²­ë…„ì£¼íƒ"):
    print(chunk, end="", flush=True)
```

---

### 2. Agent ëª¨ë“œ (ë˜‘ë˜‘í•œ ë„êµ¬ ì„ íƒ)
**íŒŒì¼**: `langchain/chains/inha/housing_agent_inha.py`

```python
ì§ˆë¬¸ â†’ Agent (ë„êµ¬ ì„ íƒ) â†’ ê²€ìƒ‰ ì‹¤í–‰ â†’ ë‹µë³€ ìƒì„±
```

**íŠ¹ì§•**:
- âœ… ì‚¬ìš©ì ì˜ë„ íŒŒì•… ("ëª¨ë‘ ë³´ì—¬ì¤˜" vs "ì¶”ì²œí•´ì¤˜")
- âœ… ë™ì  ê²€ìƒ‰ ì¡°ê±´ ë³€ê²½
- âœ… í™•ì¥ ê°€ëŠ¥ (ë„êµ¬ ì¶”ê°€)
- âŒ ì•½ê°„ ëŠë¦¼

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
from backend.services.llm.langchain.chains.inha.housing_agent_inha import housing_assistant

# "ëª¨ë‘" ê°ì§€ â†’ comprehensive ëª¨ë“œ (20ê°œ)
answer = housing_assistant("ì„œì´ˆêµ¬ ì£¼íƒ ëª¨ë‘ ë³´ì—¬ì¤˜")

# "ì¶”ì²œ" ê°ì§€ â†’ diverse ëª¨ë“œ (5ê°œ, MMR)
answer = housing_assistant("ê°•ë‚¨êµ¬ ì¢‹ì€ ì£¼íƒ ì¶”ì²œí•´ì¤˜")
```

---

## ğŸ¤– LLM ëª¨ë“œ

### ëª¨ë“œ 1: ë‹¨ì¼ LLM (ê¸°ë³¸, ì¶”ì²œ)
**ëª¨ë¸**: Groq `llama-3.3-70b-versatile`

```
ëª¨ë“  ì‘ì—…ì„ í•˜ë‚˜ì˜ LLMìœ¼ë¡œ ì²˜ë¦¬
```

**ì¥ì **:
- âš¡ ë¹ ë¦„
- ğŸ’° ë¬´ë£Œ (Groq ë¬´ë£Œ tier)
- ğŸ¯ 70B ëª¨ë¸ì´ë¼ ì„±ëŠ¥ ìš°ìˆ˜

**ë‹¨ì **:
- ì—†ìŒ (llama-3.3-70bëŠ” ì¶©ë¶„íˆ ê°•ë ¥)

---

### ëª¨ë“œ 2: í•˜ì´ë¸Œë¦¬ë“œ LLM (ê³ ê¸‰)
**Agent**: OpenAI `gpt-4o-mini` (ë„êµ¬ í˜¸ì¶œ)  
**Response**: Groq `llama-3.3-70b-versatile` (ë‹µë³€ ìƒì„±)

```
ì§ˆë¬¸ â†’ GPT-4o-mini (ë„êµ¬ ì„ íƒ) â†’ Groq (ë‹µë³€ ìƒì„±)
```

**ì¥ì **:
- ğŸ¯ ì •í™•í•œ ë„êµ¬ í˜¸ì¶œ (GPT-4o-mini)
- âš¡ ë¹ ë¥¸ ë‹µë³€ ìƒì„± (Groq)
- ğŸ’° ë¹„ìš© íš¨ìœ¨ì 

**ë‹¨ì **:
- ğŸ¢ ì•½ê°„ ëŠë¦¼ (2ë‹¨ê³„)
- ğŸ’µ OpenAI API ë¹„ìš© ë°œìƒ

**ì–¸ì œ ì‚¬ìš©?**:
- ë³µì¡í•œ ë©€í‹°ìŠ¤í… ì¶”ë¡  í•„ìš”
- ì—¬ëŸ¬ ë„êµ¬ ì¡°í•© í•„ìš” 
  (í–¥í›„ í™•ì¥ì‹œ ì ìš©í•˜ê¸° ì¢‹ì„ ê²ƒìœ¼ë¡œ ì‚¬ë£Œë¨)
  (ì—¬ëŸ¬ ë„êµ¬ ì¶”ê°€í•˜ì—¬ Groqëª¨ë¸ì´ ì¼ì²˜ë¦¬ ëª»í•˜ë©´ í•˜ì´ë¸Œë¦¬ë“œëª¨ë“œë¡œ ë³€ê²½í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ìª½ìœ¼ë¡œ í™•ì •í•˜ê¸°)
- í”„ë¡œë•ì…˜ í™˜ê²½

---

## âš™ï¸ ì„¤ì • ë°©ë²•

### 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (`.env`)

**ë‹¨ì¼ ëª¨ë“œ (ê¸°ë³¸, ì¶”ì²œ)**:
```bash
# API Key
GROQ_API_KEY=gsk_your_key_here ì…ë ¥

# LLM ëª¨ë“œ ì„¤ì •
.env íŒŒì¼ì—ì„œ USE_HYBRID_LLM=False  # ë‹¨ì¼ ëª¨ë“œ
(RESPONSE_MODEL=llama-3.3-70b-versatile)
```

**í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ**:
```bash
env.example í•˜ë‹¨ì˜ llm ë° apií‚¤ ë¶€ë¶„ ë³µì‚¬í•˜ì—¬ .env íŒŒì¼ì— ë¶™ì—¬ë„£ê¸°
.env íŒŒì¼ì—ì„œ USE_HYBRID_LLM=Trueë¡œ ë³€ê²½ ì‹œ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ í™œì„±í™”
```

### 2. ëª¨ë“œ ì „í™˜

í„°ë¯¸ë„ì—ì„œ í™•ì¸:
```bash
# ë¡œê·¸ ì¶œë ¥ í™•ì¸
âš™ï¸  ë‹¨ì¼ LLM ëª¨ë“œ (llama-3.3-70b-versatile)  # ê¸°ë³¸
# ë˜ëŠ”
ğŸ”€ í•˜ì´ë¸Œë¦¬ë“œ LLM ëª¨ë“œ í™œì„±í™”
  â”œâ”€ Agent LLM: gpt-4o-mini (OpenAI)
  â””â”€ Response LLM: llama-3.3-70b-versatile (Groq)
```

---

## ğŸš€ ì‚¬ìš© ê°€ì´ë“œ

### Chain ëª¨ë“œ ì‹¤í–‰
```bash
# ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸
python -m backend.services.llm.langchain.chains.inha.housing_chain_inha
```


### Agent ëª¨ë“œ ì‹¤í–‰
```bash
# Agent í…ŒìŠ¤íŠ¸
python -m backend.services.llm.langchain.chains.inha.housing_agent_inha
```

**Agentì˜ ë˜‘ë˜‘í•œ íŒë‹¨**:
(prompt_inha.py íŒŒì¼ ì°¸ê³ )
```python
# ì§ˆë¬¸: "ì„œì´ˆêµ¬ ì£¼íƒ ëª¨ë‘ ë³´ì—¬ì¤˜"
â†’ search_housing(query="ì„œì´ˆêµ¬ ì£¼íƒ", search_mode="comprehensive", max_results=20)

# ì§ˆë¬¸: "ê°•ë‚¨êµ¬ ì¢‹ì€ ì£¼íƒ ì¶”ì²œí•´ì¤˜"
â†’ search_housing(query="ê°•ë‚¨êµ¬ ì¢‹ì€ ì£¼íƒ", search_mode="diverse", max_results=5)
```

---

## ğŸ’° ë¹„ìš© ë¹„êµ (ê°„ë‹¨ ë²„ì „)

| ëª¨ë“œ | ëª¨ë¸ | ë¹„ìš© | ì¶”ì²œë„ |
|------|------|------|--------|
| **ë‹¨ì¼ (ì¶”ì²œ)** | llama-3.3-70b | ë¬´ë£Œ* | â­â­â­â­â­ |
| **í•˜ì´ë¸Œë¦¬ë“œ** | gpt-4o-mini + llama-3.3-70b | ~$0.001/íšŒ | â­â­â­â­ |

*Groq ë¬´ë£Œ tier: ì¼ì¼ 14,400 requests

**ì‹¤ì œ ë¹„ìš© ì˜ˆì‹œ (í•˜ì´ë¸Œë¦¬ë“œ)**:
- ì›” 100íšŒ: ~$0.10
- ì›” 1,000íšŒ: ~$1.00
- ì›” 10,000íšŒ: ~$10.00

**ê²°ë¡ **: ë‹¨ì¼ ëª¨ë“œë¡œ ì‹œì‘ â†’ í•„ìš”ì‹œ í•˜ì´ë¸Œë¦¬ë“œ ì „í™˜

---

## ğŸ”§ ì£¼ìš” ì»´í¬ë„ŒíŠ¸

```
backend/services/llm/
â”œâ”€â”€ models/inha/
â”‚   â””â”€â”€ llm_inha.py              # LLM ì„¤ì • (ë‹¨ì¼/í•˜ì´ë¸Œë¦¬ë“œ)
â”œâ”€â”€ prompts/inha/
â”‚   â””â”€â”€ prompt_inha.py           # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
â”œâ”€â”€ langchain/
â”‚   â”œâ”€â”€ chains/inha/
â”‚   â”‚   â”œâ”€â”€ housing_chain_inha.py   # Chain ëª¨ë“œ (ìŠ¤íŠ¸ë¦¬ë°)
â”‚   â”‚   â””â”€â”€ housing_agent_inha.py   # Agent ëª¨ë“œ
â”‚   â””â”€â”€ retrievers/inha/
â”‚       â””â”€â”€ retriever_inha.py       # ë²¡í„° ê²€ìƒ‰ (MMR/ìœ ì‚¬ë„)
â””â”€â”€ utils/inha/
    â”œâ”€â”€ housing_tools_inha.py    # Agent ë„êµ¬ ì •ì˜
    â””â”€â”€ output_parser_inha.py    # ì¶œë ¥ íŒŒì„œ
```

---

## ğŸ“ ì¶”ê°€ ì •ë³´

### ê²€ìƒ‰ ëª¨ë“œ (Agentì—ì„œ ìë™ ì„ íƒ)

**Diverse ëª¨ë“œ** (ê¸°ë³¸):
- ìœ ì‚¬ë„ ë†’ì€ ìˆœ ì •ë ¬
- ê¸°ë³¸ 5ê°œ ê²°ê³¼
- ì‚¬ìš©: "ì¶”ì²œí•´ì¤˜", "ì¢‹ì€ ê³³"

**Comprehensive ëª¨ë“œ** (ì „ì²´):
- ìœ ì‚¬ë„ ë†’ì€ ìˆœ ì •ë ¬
- ê¸°ë³¸ 20ê°œ ê²°ê³¼
- ëª¨ë“  ë§¤ì¹­ ê²°ê³¼
- ì‚¬ìš©: "ëª¨ë‘ ë³´ì—¬ì¤˜", "ì „ë¶€"

**ì°¸ê³ **: ì´ì „ ë²„ì „ì˜ MMR(Maximal Marginal Relevance)ì€ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤. ì£¼íƒ ê²€ìƒ‰ì—ì„œëŠ” "ë‹¤ì–‘ì„±"ë³´ë‹¤ "ê´€ë ¨ì„±"ì´ ë” ì¤‘ìš”í•˜ë©°, ê° ì£¼íƒì´ ì´ë¯¸ ê³ ìœ í•œ ë§¤ë¬¼ì´ê¸° ë•Œë¬¸ì— ìœ ì‚¬ë„ ìˆœ ì •ë ¬ì´ ë” ì‹¤ìš©ì ì…ë‹ˆë‹¤.

### í–¥í›„ í™•ì¥

Agent ëª¨ë“œì— ë„êµ¬ ì¶”ê°€ ê°€ëŠ¥:
```python
# ì˜ˆì •ëœ ë„êµ¬
- calculate_commute_time()  # í†µê·¼ì‹œê°„ ê³„ì‚°
- filter_by_price()         # ê°€ê²© í•„í„°ë§
- get_area_info()           # ì§€ì—­ ì •ë³´
```

---

## â“ FAQ

**Q: Chain vs Agent ì–´ë–¤ ê±¸ ì¨ì•¼ í•˜ë‚˜ìš”?**  
A: ì¼ë°˜ì ì¸ ê²€ìƒ‰ â†’ Chain, ë³µì¡í•œ ì¡°ê±´ â†’ Agent

**Q: í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œê°€ í•„ìš”í•œê°€ìš”?**  
A: llama-3.3-70bë§Œìœ¼ë¡œë„ ì¶©ë¶„í•©ë‹ˆë‹¤. ë‚˜ì¤‘ì— ë³µì¡í•œ ë„êµ¬ê°€ ì¶”ê°€ë˜ë©´ ê³ ë ¤í•˜ì„¸ìš”.

**Q: MMR ì˜¤ë¥˜ê°€ ë‚©ë‹ˆë‹¤**  
A: ìˆ˜ì • ì™„ë£Œ. `.env`ì—ì„œ `RESPONSE_MODEL=llama-3.3-70b-versatile` í™•ì¸

**Q: ë¹„ìš©ì´ ê±±ì •ë©ë‹ˆë‹¤**  
A: ë‹¨ì¼ ëª¨ë“œëŠ” Groq ë¬´ë£Œ tierë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤ (ì¼ 14,400íšŒ)

---

## ğŸ¯ ë¹ ë¥¸ ì‹œì‘

```bash
# 1. .env ì„¤ì •
GROQ_API_KEY=your_key
USE_HYBRID_LLM=False

# 2. Chain ëª¨ë“œ í…ŒìŠ¤íŠ¸ (ìŠ¤íŠ¸ë¦¬ë°)
python -m backend.services.llm.langchain.chains.inha.housing_chain_inha

# 3. Agent ëª¨ë“œ í…ŒìŠ¤íŠ¸ (ë˜‘ë˜‘í•œ ê²€ìƒ‰)
python -m backend.services.llm.langchain.chains.inha.housing_agent_inha
```

ë! ğŸš€
