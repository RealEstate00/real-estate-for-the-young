#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ì •ê·œí™”ëœ ë°ì´í„°ë¥¼ DBì— ì ì¬í•˜ëŠ” CLI ìŠ¤í¬ë¦½íŠ¸
Usage:
  data-load housing --data-dir backend/data/normalized
  data-load all     --data-dir backend/data/normalized
"""
import os
import sys
import logging
from pathlib import Path
from typing import Optional

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).resolve().parents[4]
sys.path.insert(0, str(project_root))

from backend.services.db.common.db_utils import test_connection, get_engine
from backend.services.loading.housing.housing_db_loader import HousingLoader, LoaderConfig, build_db_url
from backend.services.rag.core import MultiModelEmbedder
from sqlalchemy import text

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

def _resolve_db_url(cli_db_url: Optional[str]) -> str:
    if cli_db_url:
        return cli_db_url
    env_url = os.getenv("DATABASE_URL")
    if env_url:
        return env_url
    return build_db_url()

def _load_housing_dir(housing_root: Path, db_url: str) -> bool:
    try:
        if not housing_root.exists():
            logger.error("ì •ê·œí™”ëœ ì£¼íƒ ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: %s", housing_root)
            return False

        logger.info("DB ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
        if not test_connection():
            logger.error("DB ì—°ê²° ì‹¤íŒ¨")
            return False
        logger.info("DB ì—°ê²° ì„±ê³µ")

        cfg = LoaderConfig(root_dir=housing_root, db_url=db_url, only_latest_date=True)
        logger.info("ì£¼íƒ ë°ì´í„° ë¡œë“œ ì‹œì‘: %s", housing_root)

        loader = HousingLoader(cfg)  # âœ… __init__(cfg) ë¡œ í†µì¼
        loader.run()

        logger.info("ì£¼íƒ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        return True
    except Exception as e:
        logger.exception("ì£¼íƒ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: %s", e)
        return False

def load_housing_data(normalized_data_dir: str, db_url: Optional[str] = None) -> bool:
    root = Path(normalized_data_dir).resolve()
    housing_root = root / "housing"
    dbu = _resolve_db_url(db_url)
    masked = dbu
    if "postgresql" in dbu:
        pwd = os.getenv("PG_PASSWORD", "post1234")
        masked = dbu.replace(pwd, "******")
    logger.info("ì£¼íƒ ë°ì´í„° ë””ë ‰í† ë¦¬: %s", housing_root)
    logger.info("DB URL: %s", masked)
    return _load_housing_dir(housing_root, dbu)

def load_rtms_data(normalized_data_dir: str, db_url: Optional[str] = None) -> bool:
    try:
        root = Path(normalized_data_dir).resolve()
        rtms_root = root / "rtms"
        
        if not rtms_root.exists():
            logger.error("ì •ê·œí™”ëœ RTMS ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: %s", rtms_root)
            return False

        logger.info("DB ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
        if not test_connection():
            logger.error("DB ì—°ê²° ì‹¤íŒ¨")
            return False
        logger.info("DB ì—°ê²° ì„±ê³µ")

        # RTMS ë¡œë” import
        from backend.services.loading.rtms.load_rtms_data import RTMSDataLoader
        
        # DB ì„¤ì •
        db_config = {
            'host': os.getenv('PG_HOST', 'localhost'),
            'port': os.getenv('PG_PORT', '55432'),
            'database': os.getenv('PG_DB', 'rey'),
            'user': os.getenv('PG_USER', 'postgres'),
            'password': os.getenv('PG_PASSWORD', 'post1234'),
        }
        
        logger.info("RTMS ë°ì´í„° ë””ë ‰í† ë¦¬: %s", rtms_root)
        logger.info("DB í˜¸ìŠ¤íŠ¸: %s:%s", db_config['host'], db_config['port'])
        
        # RTMS ë°ì´í„° ë¡œë“œ
        loader = RTMSDataLoader(db_config)
        loader.connect()
        loader.clear_and_load(rtms_root, batch_size=10000)
        loader.close()
        
        logger.info("RTMS ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.exception("RTMS ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: %s", e)
        return False

def load_infra_data(normalized_data_dir: str, db_url: Optional[str] = None) -> bool:
    try:
        root = Path(normalized_data_dir).resolve()
        infra_root = root / "infra"
        
        if not infra_root.exists():
            logger.error("ì •ê·œí™”ëœ ì¸í”„ë¼ ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: %s", infra_root)
            return False

        logger.info("DB ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
        if not test_connection():
            logger.error("DB ì—°ê²° ì‹¤íŒ¨")
            return False
        logger.info("DB ì—°ê²° ì„±ê³µ")

        # INFRA ë¡œë” import
        from backend.services.loading.infra.infra_db_loader import JSONLDBLoader
        
        dbu = _resolve_db_url(db_url)
        masked = dbu
        if "postgresql" in dbu:
            pwd = os.getenv("PG_PASSWORD", "post1234")
            masked = dbu.replace(pwd, "******")
        
        logger.info("ì¸í”„ë¼ ë°ì´í„° ë””ë ‰í† ë¦¬: %s", infra_root)
        logger.info("DB URL: %s", masked)
        
        # JSONL íŒŒì¼ë“¤ì„ DBì— ë¡œë“œ
        loader = JSONLDBLoader(db_url=dbu)
        loader.load_all_jsonl_files(infra_root)
        
        logger.info("ì¸í”„ë¼ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.exception("ì¸í”„ë¼ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: %s", e)
        return False

def load_normalized_data(normalized_data_dir: str, db_url: Optional[str] = None) -> bool:
    """ëª¨ë“  ë°ì´í„° ë¡œë“œ (ì£¼íƒ, ê³µê³µì‹œì„¤, ì‹¤ê±°ë˜)"""
    logger.info("=== ì „ì²´ ë°ì´í„° ë¡œë“œ ì‹œì‘ ===")
    
    housing_ok = load_housing_data(normalized_data_dir, db_url)
    infra_ok = load_infra_data(normalized_data_dir, db_url)
    rtms_ok = load_rtms_data(normalized_data_dir, db_url)
    
    logger.info("=== ì „ì²´ ë°ì´í„° ë¡œë“œ ê²°ê³¼ ===")
    logger.info("ì£¼íƒ ë°ì´í„°: %s", "ì„±ê³µ" if housing_ok else "ì‹¤íŒ¨")
    logger.info("ê³µê³µì‹œì„¤ ë°ì´í„°: %s", "ì„±ê³µ" if infra_ok else "ì‹¤íŒ¨")
    logger.info("ì‹¤ê±°ë˜ ë°ì´í„°: %s", "ì„±ê³µ" if rtms_ok else "ì‹¤íŒ¨")
    
    return housing_ok and infra_ok and rtms_ok

def _create_vector_db_schema():
    """vector_db ìŠ¤í‚¤ë§ˆ ë° í…Œì´ë¸” ìƒì„±"""
    logger.info("ğŸ“Š vector_db ìŠ¤í‚¤ë§ˆ ë° í…Œì´ë¸” ìƒì„± ì¤‘...")
    try:
        engine = get_engine()
        with engine.connect() as conn:
            # vector_db ìŠ¤í‚¤ë§ˆ ìƒì„±
            conn.execute(text("CREATE SCHEMA IF NOT EXISTS vector_db;"))
            conn.commit()
            logger.info("âœ… vector_db ìŠ¤í‚¤ë§ˆ ìƒì„± ì™„ë£Œ")

            # í•„ìš”í•œ í…Œì´ë¸”ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            required_tables = [
                'embedding_models', 'document_sources', 'document_chunks', 
                'chunk_embeddings', 'search_logs', 'model_metrics',
                'embeddings_e5_small', 'embeddings_kakaobank', 'embeddings_qwen3',
                'embeddings_gemma'
            ]
            
            missing_tables = []
            for table in required_tables:
                result = conn.execute(text(f"""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables
                        WHERE table_schema = 'vector_db'
                        AND table_name = '{table}'
                    )
                """))
                if not result.scalar():
                    missing_tables.append(table)

            if not missing_tables:
                logger.info("âœ… vector_db í…Œì´ë¸”ë“¤ì´ ëª¨ë‘ ì¡´ì¬í•©ë‹ˆë‹¤. ê±´ë„ˆë›°ê¸°")
                return True

            logger.info(f"ğŸ“‹ ëˆ„ë½ëœ í…Œì´ë¸”ë“¤: {', '.join(missing_tables)}")
            logger.info("ğŸ”§ í…Œì´ë¸” ìƒì„± ì¤‘...")

            # ìŠ¤í‚¤ë§ˆ íŒŒì¼ ì½ê¸° ë° ì‹¤í–‰
            schema_file = Path("backend/services/rag/vectorstore/schema.sql")
            if schema_file.exists():
                with open(schema_file, 'r', encoding='utf-8') as f:
                    schema_sql = f.read()
                conn.execute(text(schema_sql))
                conn.commit()
                logger.info("âœ… vector_db í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
            else:
                logger.error(f"âŒ ìŠ¤í‚¤ë§ˆ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {schema_file}")
                return False

            logger.info("âœ… vector_db ìŠ¤í‚¤ë§ˆ ë° í…Œì´ë¸” ìƒì„± ì™„ë£Œ!")
            return True
    except Exception as e:
        logger.error(f"âŒ vector_db ìŠ¤í‚¤ë§ˆ ìƒì„± ì‹¤íŒ¨: {e}")
        logger.exception(e)
        return False

def _load_vector_db_data(data_dir: Path, models_to_use: list = None) -> bool:
    """vector_db ë°ì´í„° ë¡œë”© (ì„ íƒëœ ëª¨ë¸ë¡œ ì„ë² ë”©)

    Args:
        data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬
        models_to_use: ì‚¬ìš©í•  ëª¨ë¸ ëª©ë¡ (ì˜ˆ: ['kakaobank', 'gemma'])
                      Noneì´ë©´ ëª¨ë“  ëª¨ë¸ ì‚¬ìš©
    """
    try:
        # JSON íŒŒì¼ ê²½ë¡œ í™•ì¸
        json_file = data_dir / "structured" / "ì„œìš¸ì‹œ_ì£¼ê±°ë³µì§€ì‚¬ì—…_pgvector_ready_clecd ..aned.json"

        if not json_file.exists():
            logger.error("âŒ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: %s", json_file)
            return False

        # ëª¨ë¸ ì„ íƒ
        from backend.services.rag.models.config import EmbeddingModelType

        model_mapping = {
            'e5': EmbeddingModelType.MULTILINGUAL_E5_SMALL,
            'kakaobank': EmbeddingModelType.KAKAOBANK_DEBERTA,
            'qwen3': EmbeddingModelType.QWEN_EMBEDDING,
            'gemma': EmbeddingModelType.EMBEDDING_GEMMA
        }

        if models_to_use:
            selected_models = [model_mapping[m] for m in models_to_use if m in model_mapping]
            logger.info("ğŸš€ ì„ íƒëœ %dê°œ ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„± ì‹œì‘: %s", len(selected_models), models_to_use)
        else:
            selected_models = None
            logger.info("ğŸš€ ëª¨ë“  ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„± ì‹œì‘")

        logger.info("ğŸ“ ë°ì´í„° íŒŒì¼: %s", json_file)

        # ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
        db_config = {
            'host': 'localhost',
            'port': '5432',
            'database': 'rey',
            'user': 'postgres',
            'password': 'post1234'
        }

        # MultiModelEmbedder ì‹¤í–‰
        embedder = MultiModelEmbedder(str(json_file), db_config, models_to_use=selected_models)
        results = embedder.embed_all_models()
        
        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        print(embedder.get_summary())
        
        # ì„±ê³µí•œ ëª¨ë¸ ìˆ˜ í™•ì¸
        successful_models = [k for k, v in results.items() if v.get("status") == "success"]
        
        if successful_models:
            logger.info("âœ… %dê°œ ëª¨ë¸ ì„ë² ë”© ì™„ë£Œ", len(successful_models))
            return True
        else:
            logger.error("âŒ ëª¨ë“  ëª¨ë¸ ì„ë² ë”© ì‹¤íŒ¨")
            return False
            
    except Exception as e:
        logger.error(f"âŒ vector_db ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
        return False

def load_vector_db_data(data_dir: Path, db_url: str, models_to_use: list = None) -> bool:
    """vector_db ë°ì´í„° ë¡œë”© ë©”ì¸ í•¨ìˆ˜

    Args:
        data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬
        db_url: ë°ì´í„°ë² ì´ìŠ¤ URL
        models_to_use: ì‚¬ìš©í•  ëª¨ë¸ ëª©ë¡ (ì˜ˆ: ['kakaobank', 'gemma'])
                      Noneì´ë©´ ëª¨ë“  ëª¨ë¸ ì‚¬ìš©
    """
    try:
        logger.info("DB ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
        if not test_connection():
            logger.error("DB ì—°ê²° ì‹¤íŒ¨")
            return False
        logger.info("DB ì—°ê²° ì„±ê³µ")

        # 1. vector_db ìŠ¤í‚¤ë§ˆ ìƒì„±
        if not _create_vector_db_schema():
            return False

        # 2. ì„ íƒëœ ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„± ë° ë¡œë”©
        if not _load_vector_db_data(data_dir, models_to_use=models_to_use):
            return False
        
        logger.info("âœ… vector_db ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
        return True
        
    except Exception as e:
        logger.error(f"âŒ vector_db ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
        return False

def main():
    import argparse
    os.environ.setdefault("PG_USER", "postgres")
    os.environ.setdefault("PG_PASSWORD", "post1234")
    os.environ.setdefault("PG_HOST", "localhost")
    os.environ.setdefault("PG_PORT", "55432")
    os.environ.setdefault("PG_DB", "rey")
    os.environ.setdefault("DATABASE_URL", "")

    parser = argparse.ArgumentParser(description="data-load: ë°ì´í„°ë¥¼ DBì— ì ì¬")
    parser.add_argument("--db-url", type=str, help="ë°ì´í„°ë² ì´ìŠ¤ URL (ë¯¸ì§€ì •ì‹œ PG_*ë¡œ ì¡°ë¦½)")
    parser.add_argument("--verbose", "-v", action="store_true", help="ìƒì„¸ ë¡œê·¸ ì¶œë ¥")

    subparsers = parser.add_subparsers(dest="command", help="ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´")

    p_housing = subparsers.add_parser("housing", help="ì£¼íƒ ë°ì´í„° ë¡œë“œ")
    p_housing.add_argument("--data-dir", type=str, default="backend/data/normalized",
                           help="ì •ê·œí™”ëœ ë°ì´í„° ë£¨íŠ¸ ê²½ë¡œ (ê¸°ë³¸: backend/data/normalized)")

    p_rtms = subparsers.add_parser("rtms", help="RTMS ë°ì´í„° ë¡œë“œ")
    p_rtms.add_argument("--data-dir", type=str, default="backend/data/normalized",
                        help="ì •ê·œí™”ëœ ë°ì´í„° ë£¨íŠ¸ ê²½ë¡œ (ê¸°ë³¸: backend/data/normalized)")

    p_infra = subparsers.add_parser("infra", help="ê³µê³µì‹œì„¤ ë°ì´í„° ë¡œë“œ")
    p_infra.add_argument("--data-dir", type=str, default="backend/data/normalized",
                        help="ì •ê·œí™”ëœ ë°ì´í„° ë£¨íŠ¸ ê²½ë¡œ (ê¸°ë³¸: backend/data/normalized)")

    p_all = subparsers.add_parser("all", help="ëª¨ë“  ë°ì´í„° ë¡œë“œ")
    p_all.add_argument("--data-dir", type=str, default="backend/data/normalized",
                       help="ì •ê·œí™”ëœ ë°ì´í„° ë£¨íŠ¸ ê²½ë¡œ (ê¸°ë³¸: backend/data/normalized)")
    
    p_vector_db = subparsers.add_parser("vector_db", help="vector_db ë°ì´í„° ë¡œë“œ (ì„ íƒëœ ëª¨ë¸ë¡œ ì„ë² ë”©)")
    p_vector_db.add_argument("--data-dir", type=str, default="backend/data/vector_db",
                            help="ë²¡í„° ë°ì´í„° ë£¨íŠ¸ ê²½ë¡œ (ê¸°ë³¸: backend/data/vector_db)")
    p_vector_db.add_argument("--models", type=str, nargs='+',
                            choices=['e5', 'kakaobank', 'qwen3', 'gemma'],
                            help="ì‚¬ìš©í•  ëª¨ë¸ (ì˜ˆ: --models kakaobank gemma). ë¯¸ì§€ì • ì‹œ ëª¨ë“  ëª¨ë¸ ì‚¬ìš©")

    args = parser.parse_args()
    if not args.command:
        parser.print_help()
        sys.exit(1)

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    db_url = _resolve_db_url(args.db_url)

    success = False
    if args.command == "housing":
        success = load_housing_data(args.data_dir, db_url)
    elif args.command == "rtms":
        success = load_rtms_data(args.data_dir, db_url)
    elif args.command == "infra":
        success = load_infra_data(args.data_dir, db_url)
    elif args.command == "all":
        success = load_normalized_data(args.data_dir, db_url)
    elif args.command == "vector_db":
        models = args.models if hasattr(args, 'models') and args.models else None
        success = load_vector_db_data(Path(args.data_dir), db_url, models_to_use=models)

    if success:
        logger.info("%s ë°ì´í„° ì ì¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.", args.command)
        sys.exit(0)
    else:
        logger.error("%s ë°ì´í„° ì ì¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", args.command)
        sys.exit(1)

if __name__ == "__main__":
    main()
