"""
JSONL íŒŒì¼ì„ PostgreSQL DBì— ë¡œë“œí•˜ëŠ” ëª¨ë“ˆ
infra_schema.sqlì˜ í…Œì´ë¸” êµ¬ì¡°ì— ë§ì¶° ë°ì´í„°ë¥¼ ì‚½ì…
"""
import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError
from dotenv import load_dotenv
import os
import pandas as pd
from datetime import datetime

logger = logging.getLogger(__name__)

class JSONLDBLoader:
    """JSONL íŒŒì¼ì„ DBì— ë¡œë“œí•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, db_url: str = None):
        load_dotenv()
        
        if db_url:
            self.db_url = db_url
        else:
            # .env íŒŒì¼ì—ì„œ DB ì—°ê²° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            db_host = os.getenv('PG_HOST', 'localhost')
            db_port = os.getenv('PG_PORT', '55432')
            db_name = os.getenv('PG_DB', 'rey')
            db_user = os.getenv('PG_USER', 'postgres')
            db_password = os.getenv('PG_PASSWORD', 'post1234')
            
            if db_password:
                self.db_url = f"postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}"
            else:
                self.db_url = f"postgresql://{db_user}@{db_host}:{db_port}/{db_name}"
        
        self.engine = create_engine(self.db_url)
        self.connection = self.engine.connect()
        logger.info("JSONL DB Loader ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _safe_int(self, value) -> Optional[int]:
        """ì•ˆì „í•˜ê²Œ ì •ìˆ˜ë¡œ ë³€í™˜"""
        if pd.isna(value) or value == '' or value is None:
            return None
        try:
            return int(float(str(value)))
        except (ValueError, TypeError):
            return None
    
    def _safe_float(self, value) -> Optional[float]:
        """ì•ˆì „í•˜ê²Œ ì‹¤ìˆ˜ë¡œ ë³€í™˜"""
        if pd.isna(value) or value == '' or value is None:
            return None
        try:
            return float(str(value))
        except (ValueError, TypeError):
            return None
    
    def _safe_str(self, value, max_length: int = None) -> Optional[str]:
        """ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ë¡œ ë³€í™˜"""
        if pd.isna(value) or value == '' or value is None:
            return None
        str_value = str(value).strip()
        if max_length and len(str_value) > max_length:
            str_value = str_value[:max_length]
        return str_value
    
    def _clean_json_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """JSON ë°ì´í„°ì—ì„œ NaN ê°’ì„ Noneìœ¼ë¡œ ë³€í™˜"""
        if not isinstance(data, dict):
            return data
        
        cleaned = {}
        for key, value in data.items():
            if pd.isna(value):
                cleaned[key] = None
            elif isinstance(value, dict):
                cleaned[key] = self._clean_json_data(value)
            else:
                cleaned[key] = value
        return cleaned
    
    
    def load_jsonl_file(self, jsonl_file_path: Path, batch_size: int = 1000) -> Dict[str, int]:
        """JSONL íŒŒì¼ì„ ì½ì–´ì„œ ì ì ˆí•œ í…Œì´ë¸”ì— ì‚½ì…"""
        if not jsonl_file_path.exists():
            logger.error(f"JSONL íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {jsonl_file_path}")
            return {"success": 0, "failed": 0}
        
        results = {"success": 0, "failed": 0}
        batch = []
        
        try:
            with open(jsonl_file_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    try:
                        data = json.loads(line.strip())
                        batch.append(data)
                        
                        # ë°°ì¹˜ í¬ê¸° ë„ë‹¬ ì‹œ ì²˜ë¦¬
                        if len(batch) >= batch_size:
                            batch_results = self._process_batch(batch, jsonl_file_path.name)
                            results["success"] += batch_results["success"]
                            results["failed"] += batch_results["failed"]
                            batch = []
                            
                    except json.JSONDecodeError as e:
                        logger.error(f"JSON íŒŒì‹± ì˜¤ë¥˜ (ë¼ì¸ {line_num}): {e}")
                        results["failed"] += 1
                    except Exception as e:
                        logger.error(f"ë¼ì¸ {line_num} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                        results["failed"] += 1
            
            # ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬
            if batch:
                batch_results = self._process_batch(batch, jsonl_file_path.name)
                results["success"] += batch_results["success"]
                results["failed"] += batch_results["failed"]
                
        except Exception as e:
            logger.error(f"JSONL íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            return {"success": 0, "failed": 0}
        
        logger.info(f"JSONL ë¡œë”© ì™„ë£Œ: {jsonl_file_path.name} - ì„±ê³µ: {results['success']}, ì‹¤íŒ¨: {results['failed']}")
        return results
    
    def _process_batch(self, batch: List[Dict], filename: str) -> Dict[str, int]:
        """ë°°ì¹˜ ë°ì´í„°ë¥¼ ì ì ˆí•œ í…Œì´ë¸”ì— ì‚½ì…"""
        results = {"success": 0, "failed": 0}
        
        # ë¡œê·¸ íŒŒì¼ì€ DB ì ì¬í•˜ì§€ ì•ŠìŒ
        if "failed_addresses" in filename or "progress" in filename:
            logger.info(f"ë¡œê·¸ íŒŒì¼ì€ DB ì ì¬í•˜ì§€ ì•ŠìŒ: {filename}")
            return results
        
        # íŒŒì¼ëª…ìœ¼ë¡œ í…Œì´ë¸” íƒ€ì… ê²°ì •
        if "transport_points" in filename or "subway" in filename or "bus" in filename:
            # êµí†µ ì‹œì„¤ í…Œì´ë¸”
            for data in batch:
                try:
                    # íŠ¸ëœì­ì…˜ ë¡¤ë°± í›„ ì¬ì‹œì‘
                    try:
                        self.connection.rollback()
                    except:
                        pass
                    
                    self._insert_transport_point(data)
                    self.connection.commit()
                    results["success"] += 1
                except Exception as e:
                    logger.error(f"êµí†µ ì‹œì„¤ ì‚½ì… ì˜¤ë¥˜: {e}")
                    logger.error(f"ì‹¤íŒ¨í•œ ë°ì´í„°: {data.get('name', 'Unknown')} (ID: {data.get('id', 'Unknown')})")
                    try:
                        self.connection.rollback()
                    except:
                        pass
                    results["failed"] += 1
        else:
            # ì¼ë°˜ ì‹œì„¤ í…Œì´ë¸”
            for data in batch:
                try:
                    # íŠ¸ëœì­ì…˜ ë¡¤ë°± í›„ ì¬ì‹œì‘
                    try:
                        self.connection.rollback()
                    except:
                        pass
                    
                    self._insert_facility_info(data)
                    self.connection.commit()
                    results["success"] += 1
                except Exception as e:
                    logger.error(f"ì‹œì„¤ ì •ë³´ ì‚½ì… ì˜¤ë¥˜: {e}")
                    logger.error(f"ì‹¤íŒ¨í•œ ë°ì´í„°: {data.get('name', 'Unknown')} (ID: {data.get('facility_id', 'Unknown')}, CD: {data.get('cd', 'Unknown')})")
                    try:
                        self.connection.rollback()
                    except:
                        pass
                    results["failed"] += 1
        
        return results
    
    def _insert_facility_info(self, data: Dict[str, Any]):
        """facility_info í…Œì´ë¸”ì— ë°ì´í„° ì‚½ì…"""
        # address_idê°€ ìˆìœ¼ë©´ addresses í…Œì´ë¸”ì— ë¨¼ì € ì‚½ì…
        if data.get('address_id') and data.get('address_nm'):
            self._insert_address(data['address_id'], data['address_nm'])
        
        # facility_info í…Œì´ë¸”ì— ì‚½ì…
        insert_sql = text("""
            INSERT INTO infra.facility_info (
                facility_id, cd, name, address_raw, address_id, lat, lon,
                tel, website, operating_hours, is_24h, is_emergency,
                capacity, grade_level, facility_extra, data_source,
                last_updated, created_at
            ) VALUES (
                :facility_id, :cd, :name, :address_raw, :address_id, :lat, :lon,
                :tel, :website, :operating_hours, :is_24h, :is_emergency,
                :capacity, :grade_level, :facility_extra, :data_source,
                :last_updated, :created_at
            )
            ON CONFLICT (facility_id) DO UPDATE SET
                cd = EXCLUDED.cd,
                name = EXCLUDED.name,
                address_raw = EXCLUDED.address_raw,
                address_id = EXCLUDED.address_id,
                lat = EXCLUDED.lat,
                lon = EXCLUDED.lon,
                tel = EXCLUDED.tel,
                website = EXCLUDED.website,
                operating_hours = EXCLUDED.operating_hours,
                is_24h = EXCLUDED.is_24h,
                is_emergency = EXCLUDED.is_emergency,
                capacity = EXCLUDED.capacity,
                grade_level = EXCLUDED.grade_level,
                facility_extra = EXCLUDED.facility_extra,
                data_source = EXCLUDED.data_source,
                last_updated = EXCLUDED.last_updated
        """)
        
        params = {
            'facility_id': self._safe_str(data.get('facility_id'), 50),
            'cd': self._safe_str(data.get('cd'), 20),
            'name': self._safe_str(data.get('name'), 200),
            'address_raw': self._safe_str(data.get('address_raw')),
            'address_id': self._safe_str(data.get('address_id'), 10),
            'lat': self._safe_float(data.get('lat')),
            'lon': self._safe_float(data.get('lon')),
            'tel': self._safe_str(data.get('phone'), 50),
            'website': self._safe_str(data.get('website')),
            'operating_hours': self._safe_str(data.get('operating_hours')),
            'is_24h': data.get('is_24h', False),
            'is_emergency': data.get('is_emergency', False),
            'capacity': self._safe_int(data.get('capacity')),
            'grade_level': self._safe_str(data.get('grade_level')),
            'facility_extra': json.dumps(self._clean_json_data(data.get('facility_extra', {})), ensure_ascii=False),
            'data_source': self._safe_str(data.get('data_source')),
            'last_updated': datetime.now(),
            'created_at': datetime.now()
        }
        
        self.connection.execute(insert_sql, params)
        self.connection.commit()
    
    def _insert_transport_point(self, data: Dict[str, Any]):
        """transport_points í…Œì´ë¸”ì— ë°ì´í„° ì‚½ì…"""
        # address_idê°€ ìˆìœ¼ë©´ addresses í…Œì´ë¸”ì— ë¨¼ì € ì‚½ì…
        if data.get('address_id') and data.get('address_nm'):
            self._insert_address(data['address_id'], data['address_nm'])
        
        # transport_type ê²°ì • (ìƒˆë¡œìš´ ë°ì´í„° í˜•ì‹ë§Œ ì§€ì›)
        transport_type = data.get('transport_type')
        if not transport_type:
            logger.warning(f"transport_typeì´ ì—†ëŠ” ë°ì´í„° ê±´ë„ˆë›°ê¸°: {data}")
            return
        
        insert_sql = text("""
            INSERT INTO infra.transport_points (
                id, transport_type, name, official_code, line_name, stop_type, is_transfer,
                lat, lon, extra_info, created_at
            ) VALUES (
                :id, :transport_type, :name, :official_code, :line_name, :stop_type, :is_transfer,
                :lat, :lon, :extra_info, :created_at
            )
            ON CONFLICT (id) DO NOTHING
        """)
        
        # ìƒˆë¡œìš´ ë°ì´í„° í˜•ì‹ë§Œ ì²˜ë¦¬
        params = {
            'id': data.get('id'),
            'transport_type': transport_type,
            'name': self._safe_str(data.get('name'), 200),
            'official_code': self._safe_str(data.get('official_code')),
            'line_name': self._safe_str(data.get('line_name')),
            'stop_type': self._safe_str(data.get('stop_type')),
            'is_transfer': data.get('is_transfer', False),
            'lat': self._safe_float(data.get('lat')),
            'lon': self._safe_float(data.get('lon')),
            'extra_info': json.dumps(data.get('extra_info', {}), ensure_ascii=False),
            'created_at': datetime.now()
        }
        
        self.connection.execute(insert_sql, params)
    
    def _insert_address(self, address_id: str, address_nm: str):
        """addresses í…Œì´ë¸”ì— ì£¼ì†Œ ì •ë³´ ì‚½ì…"""
        if not address_id or not address_nm:
            return
        
        # address_nmì„ íŒŒì‹±í•´ì„œ ì‹œë„, ì‹œêµ°êµ¬, ìë©´ë™ ì¶”ì¶œ
        parts = address_nm.split()
        ctpv_nm = parts[0] if len(parts) > 0 else None
        sgg_nm = parts[1] if len(parts) > 1 else None
        emd_nm = parts[2] if len(parts) > 2 else None
        
        insert_sql = text("""
            INSERT INTO infra.addresses (id, name, ctpv_nm, sgg_nm, emd_nm, created_at)
            VALUES (:id, :name, :ctpv_nm, :sgg_nm, :emd_nm, :created_at)
            ON CONFLICT (id) DO NOTHING
        """)
        
        params = {
            'id': self._safe_str(address_id, 10),
            'name': self._safe_str(address_nm, 100),
            'ctpv_nm': self._safe_str(ctpv_nm, 50),
            'sgg_nm': self._safe_str(sgg_nm, 50),
            'emd_nm': self._safe_str(emd_nm, 50),
            'created_at': datetime.now()
        }
        
        self.connection.execute(insert_sql, params)
        self.connection.commit()
    
    def load_all_jsonl_files(self, jsonl_dir: Path) -> Dict[str, Dict[str, int]]:
        """ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  JSONL íŒŒì¼ì„ ë¡œë“œ"""
        results = {}
        
        if not jsonl_dir.exists():
            logger.error(f"JSONL ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {jsonl_dir}")
            return results
        
        jsonl_files = list(jsonl_dir.glob("*.jsonl"))
        logger.info(f"ë°œê²¬ëœ JSONL íŒŒì¼: {len(jsonl_files)}ê°œ")
        
        for jsonl_file in jsonl_files:
            logger.info(f"ë¡œë”© ì‹œì‘: {jsonl_file.name}")
            file_results = self.load_jsonl_file(jsonl_file)
            results[jsonl_file.name] = file_results
        
        return results
    
    def clear_all_data(self):
        """ëª¨ë“  infra ë°ì´í„° ì‚­ì œ"""
        try:
            logger.info("ğŸ—‘ï¸ infra ìŠ¤í‚¤ë§ˆ ë°ì´í„° ì‚­ì œ ì‹œì‘...")
            
            # ì™¸ë˜í‚¤ ì°¸ì¡° ë•Œë¬¸ì— ìˆœì„œëŒ€ë¡œ ì‚­ì œ (infra_codeëŠ” ìœ ì§€)
            delete_queries = [
                "DELETE FROM infra.housing_facility_distances",
                "DELETE FROM infra.transport_points", 
                "DELETE FROM infra.facility_info",
                "DELETE FROM infra.addresses"
            ]
            
            for query in delete_queries:
                result = self.connection.execute(text(query))
                logger.info(f"ì‚­ì œ ì™„ë£Œ: {query} - {result.rowcount}ê°œ í–‰")
                self.connection.commit()
            
            logger.info("âœ… ëª¨ë“  infra ë°ì´í„° ì‚­ì œ ì™„ë£Œ!")
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")
            self.connection.rollback()
            raise
    
    def clear_transport_data(self):
        """êµí†µ ë°ì´í„°ë§Œ ì‚­ì œ"""
        try:
            logger.info("ğŸ—‘ï¸ êµí†µ ë°ì´í„° ì‚­ì œ ì‹œì‘...")
            
            # transport_points í…Œì´ë¸”ë§Œ ì‚­ì œ
            result = self.connection.execute(text("DELETE FROM infra.transport_points"))
            self.connection.commit()
            
            logger.info(f"âœ… êµí†µ ë°ì´í„° ì‚­ì œ ì™„ë£Œ: {result.rowcount}ê°œ í–‰")
            
        except Exception as e:
            logger.error(f"âŒ êµí†µ ë°ì´í„° ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")
            self.connection.rollback()
            raise
    
    def clear_facility_data(self):
        """ì‹œì„¤ ë°ì´í„°ë§Œ ì‚­ì œ"""
        try:
            logger.info("ğŸ—‘ï¸ ì‹œì„¤ ë°ì´í„° ì‚­ì œ ì‹œì‘...")
            
            # ì‹œì„¤ ê´€ë ¨ í…Œì´ë¸” ì‚­ì œ
            delete_queries = [
                "DELETE FROM infra.housing_facility_distances",
                "DELETE FROM infra.facility_info"
            ]
            
            for query in delete_queries:
                result = self.connection.execute(text(query))
                logger.info(f"ì‚­ì œ ì™„ë£Œ: {query} - {result.rowcount}ê°œ í–‰")
                self.connection.commit()
            
            logger.info("âœ… ì‹œì„¤ ë°ì´í„° ì‚­ì œ ì™„ë£Œ!")
            
        except Exception as e:
            logger.error(f"âŒ ì‹œì„¤ ë°ì´í„° ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")
            self.connection.rollback()
            raise
    
    def load_legal_dong_codes(self, file_path: Path = None):
        """ë²•ì •ë™ì½”ë“œ ì „ì²´ìë£Œ.txtë¥¼ addresses í…Œì´ë¸”ì— ë¡œë“œ"""
        try:
            if file_path is None:
                # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
                file_path = Path(__file__).resolve().parents[4] / "backend" / "data" / "rtms" / "ë²•ì •ë™ì½”ë“œ ì „ì²´ìë£Œ.txt"
            
            if not file_path.exists():
                logger.error(f"ë²•ì •ë™ì½”ë“œ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
                return False
            
            logger.info(f"ğŸ“‚ ë²•ì •ë™ì½”ë“œ íŒŒì¼ ë¡œë”© ì‹œì‘: {file_path}")
            
            # ê¸°ì¡´ addresses ë°ì´í„° ì‚­ì œ
            self.connection.execute(text("DELETE FROM infra.addresses"))
            self.connection.commit()
            logger.info("ğŸ—‘ï¸ ê¸°ì¡´ ì£¼ì†Œ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
            
            loaded_count = 0
            
            with open(file_path, 'r', encoding='utf-8') as f:
                # í—¤ë” ìŠ¤í‚µ
                next(f)
                
                for line_num, line in enumerate(f, 2):
                    try:
                        parts = line.strip().split('\t')
                        if len(parts) < 3:
                            continue
                        
                        legal_code = parts[0].strip()
                        legal_name = parts[1].strip()
                        status = parts[2].strip()
                        
                        # íì§€ì—¬ë¶€ê°€ 'ì¡´ì¬'ì¸ ë°ì´í„°ë§Œ ë¡œë“œ
                        if status != 'ì¡´ì¬':
                            continue
                        
                        # ì£¼ì†Œëª…ì„ íŒŒì‹±í•´ì„œ ì‹œë„, ì‹œêµ°êµ¬, ìë©´ë™ ì¶”ì¶œ
                        address_parts = legal_name.split()
                        ctpv_nm = address_parts[0] if len(address_parts) > 0 else None
                        sgg_nm = address_parts[1] if len(address_parts) > 1 else None
                        emd_nm = address_parts[2] if len(address_parts) > 2 else None
                        
                        # addresses í…Œì´ë¸”ì— ì‚½ì…
                        insert_sql = text("""
                            INSERT INTO infra.addresses (id, name, ctpv_nm, sgg_nm, emd_nm, created_at)
                            VALUES (:id, :name, :ctpv_nm, :sgg_nm, :emd_nm, :created_at)
                        """)
                        
                        params = {
                            'id': legal_code,
                            'name': legal_name,
                            'ctpv_nm': ctpv_nm,
                            'sgg_nm': sgg_nm,
                            'emd_nm': emd_nm,
                            'created_at': datetime.now()
                        }
                        
                        self.connection.execute(insert_sql, params)
                        loaded_count += 1
                        
                        # 1000ê°œë§ˆë‹¤ ì»¤ë°‹
                        if loaded_count % 1000 == 0:
                            self.connection.commit()
                            logger.info(f"ğŸ“Š ì§„í–‰ ìƒí™©: {loaded_count}ê°œ ë¡œë“œ ì™„ë£Œ")
                        
                    except Exception as e:
                        logger.warning(f"ë¼ì¸ {line_num} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                        continue
            
            # ë§ˆì§€ë§‰ ì»¤ë°‹
            self.connection.commit()
            logger.info(f"âœ… ë²•ì •ë™ì½”ë“œ ë¡œë”© ì™„ë£Œ: {loaded_count}ê°œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë²•ì •ë™ì½”ë“œ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
            self.connection.rollback()
            return False

    def close(self):
        """ì—°ê²° ì¢…ë£Œ"""
        if self.connection:
            self.connection.close()
        logger.info("JSONL DB Loader ì—°ê²° ì¢…ë£Œ")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="JSONL íŒŒì¼ì„ PostgreSQL DBì— ë¡œë“œí•˜ëŠ” ë„êµ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python ...ê²½ë¡œì„¤ì •.../infra_jsonl_db_loader.py                    # JSONL ë°ì´í„° ë¡œë“œ
  python ...ê²½ë¡œì„¤ì •.../infra_jsonl_db_loader.py --clear-all        # ëª¨ë“  infra ë°ì´í„° ì‚­ì œ
  python ...ê²½ë¡œì„¤ì •.../infra_jsonl_db_loader.py --clear-transport  # êµí†µ ë°ì´í„°ë§Œ ì‚­ì œ
  python ...ê²½ë¡œì„¤ì •.../infra_jsonl_db_loader.py --clear-facility   # ì‹œì„¤ ë°ì´í„°ë§Œ ì‚­ì œ
  python ...ê²½ë¡œì„¤ì •.../infra_jsonl_db_loader.py --help             # ë„ì›€ë§ í‘œì‹œ
        """
    )
    
    parser.add_argument(
        '--clear-all', 
        action='store_true',
        help='ëª¨ë“  infra ë°ì´í„° ì‚­ì œ'
    )
    
    parser.add_argument(
        '--clear-transport', 
        action='store_true',
        help='êµí†µ ë°ì´í„°ë§Œ ì‚­ì œ'
    )
    
    parser.add_argument(
        '--clear-facility',
        action='store_true',
        help='ì‹œì„¤ ë°ì´í„°ë§Œ ì‚­ì œ'
    )
    
    parser.add_argument(
        '--load-addresses',
        action='store_true',
        help='ë²•ì •ë™ì½”ë“œ ì „ì²´ìë£Œ.txtë¥¼ addresses í…Œì´ë¸”ì— ë¡œë“œ'
    )
    
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='ìƒì„¸ ë¡œê·¸ ì¶œë ¥'
    )
    
    args = parser.parse_args()
    
    # ë¡œê¹… ë ˆë²¨ ì„¤ì •
    log_level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    try:
        loader = JSONLDBLoader()
        
        # ëª…ë ¹ ì‹¤í–‰
        if args.clear_all:
            print("ğŸ—‘ï¸ ëª¨ë“  infra ë°ì´í„° ì‚­ì œ ì¤‘...")
            loader.clear_all_data()
            print("âœ… ëª¨ë“  infra ë°ì´í„° ì‚­ì œ ì™„ë£Œ!")
            
        elif args.clear_transport:
            print("ğŸ—‘ï¸ êµí†µ ë°ì´í„° ì‚­ì œ ì¤‘...")
            loader.clear_transport_data()
            print("âœ… êµí†µ ë°ì´í„° ì‚­ì œ ì™„ë£Œ!")
            
        elif args.clear_facility:
            print("ğŸ—‘ï¸ ì‹œì„¤ ë°ì´í„° ì‚­ì œ ì¤‘...")
            loader.clear_facility_data()
            print("âœ… ì‹œì„¤ ë°ì´í„° ì‚­ì œ ì™„ë£Œ!")
            
        elif args.load_addresses:
            print("ğŸ“‚ ë²•ì •ë™ì½”ë“œ ë°ì´í„° ë¡œë”© ì¤‘...")
            success = loader.load_legal_dong_codes()
            if success:
                print("âœ… ë²•ì •ë™ì½”ë“œ ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
            else:
                print("âŒ ë²•ì •ë™ì½”ë“œ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨!")
                return 1
            
        else:
            # ê¸°ë³¸ ë™ì‘: ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ë²•ì •ë™ì½”ë“œ + JSONL ë°ì´í„° ë¡œë“œ
            print("ğŸ—‘ï¸ ê¸°ì¡´ ì¸í”„ë¼ ë°ì´í„° ì‚­ì œ ì¤‘...")
            loader.clear_all_data()
            print("âœ… ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ!")
            
            print("ğŸ“‚ ë²•ì •ë™ì½”ë“œ ë°ì´í„° ë¡œë”© ì¤‘...")
            success = loader.load_legal_dong_codes()
            if success:
                print("âœ… ë²•ì •ë™ì½”ë“œ ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
            else:
                print("âŒ ë²•ì •ë™ì½”ë“œ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨!")
                return 1
            
            print("ğŸ“‚ JSONL ë°ì´í„° ë¡œë”© ì‹œì‘...")
            jsonl_dir = Path(__file__).resolve().parents[4] / "backend" / "data" / "normalized" / "infra"
            results = loader.load_all_jsonl_files(jsonl_dir)
            
            print("\n=== JSONL ë¡œë”© ê²°ê³¼ ===")
            total_success = 0
            total_failed = 0
            
            for filename, result in results.items():
                success = result.get('success', 0)
                failed = result.get('failed', 0)
                total_success += success
                total_failed += failed
                status = "âœ…" if failed == 0 else "âš ï¸" if success > 0 else "âŒ"
                print(f"{status} {filename}: ì„±ê³µ {success}ê°œ, ì‹¤íŒ¨ {failed}ê°œ")
            
            print(f"\nğŸ“Š ì „ì²´ ê²°ê³¼: ì„±ê³µ {total_success}ê°œ, ì‹¤íŒ¨ {total_failed}ê°œ")
            
            if total_failed > 0:
                print(f"\nğŸ’¡ ì‹¤íŒ¨í•œ ë°ì´í„°ë¥¼ í™•ì¸í•˜ë ¤ë©´ --verbose ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        
    except Exception as e:
        logger.error(f"ì‘ì—… ì¤‘ ì˜¤ë¥˜: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
    finally:
        if 'loader' in locals():
            loader.close()


if __name__ == "__main__":
    main()
