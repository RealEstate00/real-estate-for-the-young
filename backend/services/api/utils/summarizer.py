"""
mT5-baseë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ìš”ì•½ ìœ í‹¸ë¦¬í‹°
"""
import logging
import os
from typing import Optional, List, Dict
import torch
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
from dotenv import load_dotenv
import re

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

logger = logging.getLogger(__name__)

# ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ ëª¨ë¸ ë¡œë“œ
_summarizer_model = None
_summarizer_tokenizer = None


def get_mt5_summarizer():
    """mT5-base ìš”ì•½ ëª¨ë¸ì„ ì‹±ê¸€í†¤ìœ¼ë¡œ ë¡œë“œ"""
    global _summarizer_model, _summarizer_tokenizer
    
    if _summarizer_model is None or _summarizer_tokenizer is None:
        try:
            model_name = "google/mt5-base"
            device = "cuda" if torch.cuda.is_available() else "cpu"
            
            logger.info(f"ğŸ”„ mT5-base ìš”ì•½ ëª¨ë¸ ë¡œë”© ì‹œì‘ (ë””ë°”ì´ìŠ¤: {device})...")
            
            # HuggingFace í† í° ê°€ì ¸ì˜¤ê¸° (.envì—ì„œ ë¡œë“œ)
            hf_token = (
                os.getenv('HF_API_TOKEN') or 
                os.getenv('HF_TOKEN') or 
                os.getenv('HUGGING_FACE_HUB_TOKEN')
            )
            
            if hf_token:
                logger.info("âœ… HuggingFace API token ë°œê²¬ë¨")
            else:
                logger.warning("âš ï¸ HuggingFace API token ì—†ìŒ. ì¼ë¶€ ëª¨ë¸ì— ì ‘ê·¼í•˜ì§€ ëª»í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            tokenizer_kwargs = {"token": hf_token} if hf_token else {}
            model_kwargs = {"token": hf_token} if hf_token else {}
            
            logger.info(f"ğŸ“¥ í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ ì¤‘: {model_name}")
            # T5 ê³„ì—´ ëª¨ë¸ì€ SentencePiece í† í¬ë‚˜ì´ì € ì‚¬ìš©, use_fast=Falseë¡œ ì•ˆì •ì ìœ¼ë¡œ ë¡œë“œ
            try:
                _summarizer_tokenizer = AutoTokenizer.from_pretrained(
                    model_name,
                    use_fast=False,  # fast tokenizer ë³€í™˜ ì˜¤ë¥˜ ë°©ì§€
                    **tokenizer_kwargs
                )
            except Exception as e:
                logger.warning(f"Fast tokenizer ë¡œë“œ ì‹¤íŒ¨, slow tokenizer ì‚¬ìš©: {e}")
                # T5Tokenizerë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì ìœ¼ë¡œ ë¡œë“œ
                from transformers import T5Tokenizer
                _summarizer_tokenizer = T5Tokenizer.from_pretrained(
                    model_name,
                    **tokenizer_kwargs
                )
            
            logger.info(f"ğŸ“¥ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘: {model_name}")
            _summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(
                model_name,
                **model_kwargs
            ).to(device)
            
            _summarizer_model.eval()  # í‰ê°€ ëª¨ë“œ
            
            logger.info(f"âœ… mT5-base ìš”ì•½ ëª¨ë¸ ë¡œë”© ì™„ë£Œ (ë””ë°”ì´ìŠ¤: {device})")
            
        except Exception as e:
            logger.error(f"âŒ mT5-base ìš”ì•½ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}", exc_info=True)
            raise
    
    return _summarizer_model, _summarizer_tokenizer


def summarize_title(text: str, max_length: int = 25) -> str:
    """
    mT5-baseë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì œëª© í˜•ì‹ìœ¼ë¡œ ìš”ì•½
    
    Args:
        text: ìš”ì•½í•  í…ìŠ¤íŠ¸
        max_length: ìµœëŒ€ ê¸¸ì´ (ë¬¸ì ìˆ˜, ê¸°ë³¸ê°’ 25ì)
    
    Returns:
        ìš”ì•½ëœ ì œëª© (25ì ë‚´ì™¸)
    """
    logger.info(f"ğŸ“ ì œëª© ìš”ì•½ ì‹œì‘: ì…ë ¥ í…ìŠ¤íŠ¸ ê¸¸ì´ {len(text)}ì")
    try:
        if not text or len(text.strip()) == 0:
            logger.warning("âš ï¸ ìš”ì•½í•  í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return ""
        
        # HTML íƒœê·¸ ì œê±°
        clean_text = re.sub(r'<[^>]*>', '', text).strip()
        if not clean_text:
            return ""
        
        # ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì œê±°
        clean_text = re.sub(r'\*\*', '', clean_text)  # ë³¼ë“œ ì œê±°
        clean_text = re.sub(r'##\s*', '', clean_text)  # í—¤ë” ì œê±°
        clean_text = re.sub(r'#\s*', '', clean_text)  # í—¤ë” ì œê±°
        clean_text = re.sub(r'^\d+\.\s*', '', clean_text, flags=re.MULTILINE)  # ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ ì œê±°
        clean_text = re.sub(r'\n+', ' ', clean_text)  # ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ
        clean_text = re.sub(r'\s+', ' ', clean_text)  # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        clean_text = clean_text.strip()
        
        # ì¸ì‚¬ë§ ë° ë¶ˆí•„ìš”í•œ í‘œí˜„ ì œê±°
        remove_patterns = [
            r'^ì•ˆë…•í•˜ì„¸ìš”[.,]?\s*',
            r'^ì•ˆë…•í•˜ì„¸ìš”[.,]?\s*[ê°€-í£\s]*ë‹˜[.,]?\s*',
            r'^ì§ˆë¬¸[ì—ëŒ€í•œ]?\s*[ë‹µë³€ì•ˆë‚´]+[.:]\s*',
            r'^ë¬¸ì„œì—\s*ë”°ë¥´ë©´[.,]?\s*',
            r'^ì œê³µëœ\s*ë¬¸ì„œ[ì—ì˜í•˜ë©´]*[.,]?\s*',
        ]
        
        for pattern in remove_patterns:
            clean_text = re.sub(pattern, '', clean_text, flags=re.IGNORECASE)
        
        # ê´„í˜¸ ì•ˆ ë‚´ìš© ì œê±° 
        clean_text = re.sub(r'\([^)]*\)', '', clean_text)
        clean_text = clean_text.strip()
        
        if not clean_text:
            return ""
        
        # í…ìŠ¤íŠ¸ê°€ ì´ë¯¸ ì¶©ë¶„íˆ ì§§ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì•½ê°„ì˜ ì—¬ìœ ë¥¼ ë‘ )
        if len(clean_text) <= max_length + 5:
            # ì—¬ì „íˆ 25ì ë‚´ì™¸ë¡œ ì¡°ì •
            if len(clean_text) > max_length:
                clean_text = clean_text[:max_length]
                last_space = clean_text.rfind(" ")
                if last_space > 15:
                    clean_text = clean_text[:last_space]
            return clean_text
        
        logger.info(f"ğŸ¤– mT5-base ëª¨ë¸ í˜¸ì¶œ ì¤€ë¹„ ì¤‘... (ì •ë¦¬ëœ í…ìŠ¤íŠ¸: {len(clean_text)}ì)")
        model, tokenizer = get_mt5_summarizer()
        device = next(model.parameters()).device
        logger.info(f"âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ, ë””ë°”ì´ìŠ¤: {device}")
        
        # mT5ì— ì œëª© í˜•ì‹ ìš”ì•½ ì§€ì‹œ (ëª…í™•í•œ í”„ë¡¬í”„íŠ¸)
        # "25ì ë‚´ì™¸ ì œëª©ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡, ì™„ì „í•œ ì œëª©ìœ¼ë¡œ ìš”ì•½" ì§€ì‹œ
        prompt_text = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ 25ì ë‚´ì™¸ì˜ ì™„ì „í•œ ì œëª© í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”. 
- í•µì‹¬ í‚¤ì›Œë“œë§Œ ì¶”ì¶œí•˜ì—¬ ì œëª©ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ
- ì¤‘ê°„ì— ëŠê¸°ì§€ ì•Šê³  ì™„ì „í•œ ì˜ë¯¸ì˜ ì œëª©ìœ¼ë¡œ
- ì‚¬ìš©ì ì§ˆë¬¸ ë‚´ìš©ì€ ì œì™¸í•˜ê³  ì‘ë‹µ ë‚´ìš©ë§Œ ìš”ì•½:

{clean_text}"""
        
        # mT5ëŠ” text-to-text ëª¨ë¸ì´ë¯€ë¡œ "summarize:" í”„ë¦¬í”½ìŠ¤ ì‚¬ìš©
        input_text = f"summarize: {prompt_text}"
        logger.debug(f"ğŸ“¤ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(input_text)}ì")
        
        # í† í°í™” (ì…ë ¥ì´ ê¸¸ ê²½ìš° ì˜ë¼ëƒ„)
        max_input_length = 512
        inputs = tokenizer(
            input_text,
            max_length=max_input_length,
            truncation=True,
            padding=True,
            return_tensors="pt"
        ).to(device)
        
        # ì œëª© ìƒì„± (25ì ë‚´ì™¸ë¡œ ì œí•œ, ì™„ì „í•œ ì œëª©ìœ¼ë¡œ)
        # max_lengthëŠ” í† í° ìˆ˜ì´ë¯€ë¡œ, í•œê¸€ ê¸°ì¤€ìœ¼ë¡œ ì•½ 25ì = ì•½ 18-22 í† í°
        target_token_length = 22  # í•œê¸€ 1ì = ì•½ 1-1.2 í† í°
        
        with torch.no_grad():
            outputs = model.generate(
                inputs.input_ids,
                max_length=target_token_length,
                min_length=10,  # ìµœì†Œ í† í° ìˆ˜ (ìµœì†Œ 10ì ì´ìƒ ë³´ì¥)
                num_beams=5,  # ë¹” ìˆ˜ ì¦ê°€ (ë” ë‚˜ì€ í›„ë³´ íƒìƒ‰)
                early_stopping=True,
                no_repeat_ngram_size=2,
                do_sample=False,
                length_penalty=1.8,  # ì ì ˆí•œ ê¸¸ì´ (ë„ˆë¬´ ì§§ì§€ ì•Šë„ë¡)
                repetition_penalty=1.5  # ë°˜ë³µ ë°©ì§€
            )
        
        # ë””ì½”ë”©
        logger.info(f"ğŸ”„ ëª¨ë¸ ìƒì„± ì™„ë£Œ, ë””ì½”ë”© ì¤‘...")
        summary = tokenizer.decode(outputs[0], skip_special_tokens=True)
        summary = summary.strip()
        logger.debug(f"ğŸ“¥ ì›ë³¸ ìš”ì•½ ê²°ê³¼: '{summary}' ({len(summary)}ì)")
        
        # ë¶ˆí•„ìš”í•œ ì ‘ë‘ì‚¬ ì œê±° ("ìš”ì•½:", "ì œëª©:", "ë‹µë³€:" ë“±)
        summary = re.sub(r'^(ìš”ì•½|ì œëª©|ë‹µë³€|ì‘ë‹µ)[:ï¼š]\s*', '', summary, flags=re.IGNORECASE)
        summary = summary.strip()
        logger.debug(f"ğŸ“ ì ‘ë‘ì‚¬ ì œê±° í›„: '{summary}' ({len(summary)}ì)")
        
        # ì™„ì „í•œ ì œëª©ìœ¼ë¡œ ì¡°ì • (25ì ë‚´ì™¸, ì¤‘ê°„ì— ëŠê¸°ì§€ ì•Šê²Œ)
        if len(summary) > max_length:
            # 25ì ì´ˆê³¼ ì‹œ ìì—°ìŠ¤ëŸ¬ìš´ ìœ„ì¹˜ì—ì„œ ìë¥´ê¸°
            summary = summary[:max_length]
            
            # ì™„ì „í•œ ë‹¨ì–´/êµ¬ë¡œ ìë¥´ê¸° ìœ„í•´ ìì—°ìŠ¤ëŸ¬ìš´ ëŠê¹€ ì§€ì  ì°¾ê¸°
            # ê³µë°±, êµ¬ë‘ì , ì¡°ì‚¬ ë“±ì—ì„œ ëŠê¸°
            cut_points = [
                summary.rfind(" "),  # ê³µë°±
                summary.rfind("."),   # ë§ˆì¹¨í‘œ
                summary.rfind(","),  # ì‰¼í‘œ
                summary.rfind(":"),  # ì½œë¡ 
                summary.rfind("ì—"), # ì¡°ì‚¬
                summary.rfind("ì˜"), # ì¡°ì‚¬
                summary.rfind("ë¥¼"), # ì¡°ì‚¬
                summary.rfind("ì„"), # ì¡°ì‚¬
                summary.rfind("ì™€"), # ì¡°ì‚¬
                summary.rfind("ê³¼"), # ì¡°ì‚¬
            ]
            
            # ìœ íš¨í•œ ëŠê¹€ ì§€ì  ì¤‘ ê°€ì¥ í° ê°’ ì°¾ê¸° (ìµœì†Œ 12ì ì´ìƒ ìœ ì§€)
            valid_cut_points = [cp for cp in cut_points if cp >= 12]
            
            if valid_cut_points:
                cut_index = max(valid_cut_points)
                summary = summary[:cut_index].strip()
            else:
                # ëŠê¹€ ì§€ì ì´ ì—†ìœ¼ë©´ ê³µë°± ê¸°ì¤€ìœ¼ë¡œ ìµœëŒ€í•œ ê¸¸ê²Œ ìœ ì§€
                last_space = summary.rfind(" ")
                if last_space >= 10:
                    summary = summary[:last_space].strip()
                else:
                    # ë§ˆì§€ë§‰ ë‹¨ì–´ë¥¼ í¬í•¨í•´ì„œ 25ìë¡œ
                    summary = summary[:max_length].strip()
        
        # ìµœì†Œ ê¸¸ì´ í™•ì¸ (ë„ˆë¬´ ì§§ìœ¼ë©´ ì²« ë¶€ë¶„ ì‚¬ìš©)
        if len(summary) < 8:
            # fallback: ì²« 25ì ì‚¬ìš©í•˜ë˜ ìì—°ìŠ¤ëŸ½ê²Œ
            summary = clean_text[:max_length]
            last_space = summary.rfind(" ")
            if last_space > 10:
                summary = summary[:last_space].strip()
        
        logger.info(f"âœ… ì œëª© ìš”ì•½ ì™„ë£Œ: {len(clean_text)}ì -> {len(summary)}ì - '{summary}'")
        return summary
        
    except Exception as e:
        logger.error(f"Error summarizing text with mT5: {e}", exc_info=True)
        # ì‹¤íŒ¨ ì‹œ fallback: ì²« 25ì ë°˜í™˜ (í•µì‹¬ë§Œ ì¶”ì¶œ)
        try:
            clean_text = re.sub(r'<[^>]*>', '', text).strip()
            clean_text = re.sub(r'\n+', ' ', clean_text)
            clean_text = re.sub(r'\s+', ' ', clean_text).strip()
            
            # ì²« ë²ˆì§¸ ì˜ë¯¸ìˆëŠ” ë¬¸ì¥ì´ë‚˜ 25ì ì¶”ì¶œ
            first_sentence = clean_text.split('.')[0].split('!')[0].split('?')[0]
            if len(first_sentence) <= max_length:
                return first_sentence[:max_length]
            else:
                # í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (25ì ë‚´ì™¸)
                words = first_sentence.split()
                result = ""
                for word in words:
                    if len(result + word) <= max_length - 1:
                        result += word + " "
                    else:
                        break
                return result.strip()[:max_length]
        except:
            fallback = text[:max_length] if text else ""
            return fallback


def summarize_conversation_batch(messages: List[Dict[str, str]]) -> str:
    """
    mT5-baseë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” í•¨ìˆ˜ (10ê°œ ë©”ì‹œì§€ë§ˆë‹¤ í˜¸ì¶œ)
    
    Args:
        messages: ìš”ì•½í•  ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ (role, content í¬í•¨)
    
    Returns:
        ìš”ì•½ëœ ëŒ€í™” ë‚´ìš© (3-5ë¬¸ì¥)
    """
    logger.info(f"ğŸ“ ëŒ€í™” ë°°ì¹˜ ìš”ì•½ ì‹œì‘: {len(messages)}ê°œ ë©”ì‹œì§€")
    try:
        if not messages or len(messages) == 0:
            logger.warning("âš ï¸ ìš”ì•½í•  ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return ""
        
        # ëŒ€í™” ë‚´ìš© í¬ë§·íŒ…
        conversation_text = ""
        for msg in messages:
            role = msg.get("role", "")
            content = msg.get("content", "")
            if role == "user":
                conversation_text += f"ì‚¬ìš©ì: {content}\n"
            elif role == "assistant":
                conversation_text += f"ì–´ì‹œìŠ¤í„´íŠ¸: {content}\n"
        
        conversation_text = conversation_text.strip()
        if not conversation_text:
            logger.warning("âš ï¸ í¬ë§·íŒ…ëœ ëŒ€í™” ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return ""
        
        logger.info(f"ğŸ“‹ ëŒ€í™” ë‚´ìš© ê¸¸ì´: {len(conversation_text)}ì")
        
        # í…ìŠ¤íŠ¸ ì •ë¦¬ (HTML íƒœê·¸, ë§ˆí¬ë‹¤ìš´ ì œê±°)
        clean_text = re.sub(r'<[^>]*>', '', conversation_text).strip()
        clean_text = re.sub(r'\*\*', '', clean_text)  # ë³¼ë“œ ì œê±°
        clean_text = re.sub(r'##\s*', '', clean_text)  # í—¤ë” ì œê±°
        clean_text = re.sub(r'#\s*', '', clean_text)  # í—¤ë” ì œê±°
        clean_text = re.sub(r'\n+', ' ', clean_text)  # ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ
        clean_text = re.sub(r'\s+', ' ', clean_text)  # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        clean_text = clean_text.strip()
        
        if not clean_text:
            logger.warning("âš ï¸ ì •ë¦¬ëœ ëŒ€í™” ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return ""
        
        logger.info(f"ğŸ¤– mT5-base ëª¨ë¸ í˜¸ì¶œ ì¤€ë¹„ ì¤‘... (ì •ë¦¬ëœ í…ìŠ¤íŠ¸: {len(clean_text)}ì)")
        model, tokenizer = get_mt5_summarizer()
        device = next(model.parameters()).device
        logger.info(f"âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ, ë””ë°”ì´ìŠ¤: {device}")
        
        # mT5ì— ëŒ€í™” ìš”ì•½ ì§€ì‹œ (3-5ë¬¸ì¥, í•µì‹¬ ì •ë³´ í¬í•¨)
        prompt_text = f"""ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”. ì¤‘ìš”í•œ ì •ë³´(ì´ë¦„, ìœ„ì¹˜, ì§ˆë¬¸ ë‚´ìš©, ë‹µë³€ì˜ í•µì‹¬ ë‚´ìš© ë“±)ëŠ” ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.
- ëŒ€í™”ì˜ í•µì‹¬ ë‚´ìš©ë§Œ ìš”ì•½
- ì‚¬ìš©ìì˜ ì´ë¦„ì´ë‚˜ ì¤‘ìš”í•œ ì •ë³´ëŠ” ë°˜ë“œì‹œ í¬í•¨
- ì§ˆë¬¸ê³¼ ë‹µë³€ì˜ ì£¼ìš” ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ì •ë¦¬
- ë¶ˆí•„ìš”í•œ ì¸ì‚¬ë§ì´ë‚˜ ë°˜ë³µ ë‚´ìš©ì€ ì œì™¸
- 3-5ë¬¸ì¥ ì •ë„ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±

ëŒ€í™” ë‚´ìš©:
{clean_text}"""
        
        # mT5ëŠ” text-to-text ëª¨ë¸ì´ë¯€ë¡œ "summarize:" í”„ë¦¬í”½ìŠ¤ ì‚¬ìš©
        input_text = f"summarize: {prompt_text}"
        logger.debug(f"ğŸ“¤ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(input_text)}ì")
        
        # í† í°í™” (ì…ë ¥ì´ ê¸¸ ê²½ìš° ì˜ë¼ëƒ„)
        max_input_length = 512
        inputs = tokenizer(
            input_text,
            max_length=max_input_length,
            truncation=True,
            padding=True,
            return_tensors="pt"
        ).to(device)
        
        # ëŒ€í™” ìš”ì•½ ìƒì„± (3-5ë¬¸ì¥, ì•½ 100-150 í† í°)
        # í•œê¸€ ê¸°ì¤€ìœ¼ë¡œ ì•½ 100-150ì = ì•½ 80-120 í† í°
        target_token_length = 100  # ëŒ€í™” ìš”ì•½ìš©
        
        with torch.no_grad():
            outputs = model.generate(
                inputs.input_ids,
                max_length=target_token_length,
                min_length=40,  # ìµœì†Œ í† í° ìˆ˜ (ìµœì†Œ 3ë¬¸ì¥ ë³´ì¥)
                num_beams=5,  # ë¹” ìˆ˜ ì¦ê°€ (ë” ë‚˜ì€ í›„ë³´ íƒìƒ‰)
                early_stopping=True,
                no_repeat_ngram_size=2,
                do_sample=False,
                length_penalty=1.2,  # ì ì ˆí•œ ê¸¸ì´ (ë„ˆë¬´ ì§§ì§€ ì•Šë„ë¡)
                repetition_penalty=1.3  # ë°˜ë³µ ë°©ì§€
            )
        
        # ë””ì½”ë”©
        logger.info(f"ğŸ”„ ëª¨ë¸ ìƒì„± ì™„ë£Œ, ë””ì½”ë”© ì¤‘...")
        summary = tokenizer.decode(outputs[0], skip_special_tokens=True)
        summary = summary.strip()
        logger.debug(f"ğŸ“¥ ì›ë³¸ ìš”ì•½ ê²°ê³¼: '{summary}' ({len(summary)}ì)")
        
        # ë¶ˆí•„ìš”í•œ ì ‘ë‘ì‚¬ ì œê±° ("ìš”ì•½:", "ì œëª©:", "ë‹µë³€:" ë“±)
        summary = re.sub(r'^(ìš”ì•½|ì œëª©|ë‹µë³€|ì‘ë‹µ|ëŒ€í™”)[:ï¼š]\s*', '', summary, flags=re.IGNORECASE)
        summary = summary.strip()
        logger.debug(f"ğŸ“ ì ‘ë‘ì‚¬ ì œê±° í›„: '{summary}' ({len(summary)}ì)")
        
        # ìš”ì•½ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ê²½ê³ 
        if len(summary) < 20:
            logger.warning(f"âš ï¸ ìš”ì•½ ê²°ê³¼ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ ({len(summary)}ì). ì›ë³¸ ì¼ë¶€ ë°˜í™˜.")
            # Fallback: ì²« 100ì ë°˜í™˜
            summary = clean_text[:100]
            last_space = summary.rfind(" ")
            if last_space > 50:
                summary = summary[:last_space].strip() + "..."
        
        logger.info(f"âœ… ëŒ€í™” ìš”ì•½ ì™„ë£Œ: {len(clean_text)}ì -> {len(summary)}ì")
        return summary
        
    except Exception as e:
        logger.error(f"âŒ ëŒ€í™” ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        # ì‹¤íŒ¨ ì‹œ fallback: ê¸°ë³¸ í¬ë§·ìœ¼ë¡œ ë°˜í™˜
        try:
            fallback_summary = f"[ëŒ€í™” ìš”ì•½ ì‹¤íŒ¨] ì´ {len(messages)}ê°œì˜ ë©”ì‹œì§€"
            logger.warning(f"Fallback ìš”ì•½ ì‚¬ìš©: {fallback_summary}")
            return fallback_summary
        except:
            return "ëŒ€í™” ìš”ì•½ ì‹¤íŒ¨"
