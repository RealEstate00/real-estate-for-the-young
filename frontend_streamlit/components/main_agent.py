import streamlit as st
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from utils.session_manager import SessionManager

def response_from_agent(messages, memory=None):
    """
    Agent ëª¨ë“œì—ì„œ LLM ì‘ë‹µ ìƒì„±
    ê¸°ì¡´ housing_agent_inha.pyì˜ housing_assistant í•¨ìˆ˜ í™œìš©
    
    Args:
        messages: ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ (UI í‘œì‹œìš©)
        memory: ConversationSummaryBufferMemory ê°ì²´ (LLMì´ ëŒ€í™” ë§¥ë½ ì´í•´ìš©)
    """
    try:
        # ê¸°ì¡´ LangChain Agent ëª¨ë“ˆ import
        from backend.services.llm.langchain.chains.inha.housing_agent_inha import housing_assistant
        
        # ìµœì‹  ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ
        latest_query = messages[-1]["content"] if messages else ""
        
        # Agent ì‘ë‹µ ìƒì„± (ë©”ëª¨ë¦¬ ì „ë‹¬)
        response = housing_assistant(latest_query, memory=memory)
        
        # ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼ë¥¼ ìœ„í•´ ë¬¸ì ë‹¨ìœ„ë¡œ yield
        for char in response:
            yield char
            
    except ImportError as e:
        yield f"Agent ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}"
    except Exception as e:
        yield f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

def render_main_agent():
    """MAIN(Agent) í˜ì´ì§€ ë Œë”ë§"""
    # í˜ì´ì§€ í´ë¦¬ì–´ (ìºì‹œ ë¬¸ì œ í•´ê²°)
    st.empty()
    
    st.title("ğŸ¤– MAIN (Agent)")
    st.caption("LangChain Agent ê¸°ë°˜ ì§€ëŠ¥í˜• ì£¼íƒ ì¶”ì²œ ì‹œìŠ¤í…œ")
    
    # ë””ë²„ê¹… ì •ë³´
    st.caption("âœ… Agent í˜ì´ì§€ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼
    col1, col2 = st.columns([1, 4])
    with col1:
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True):
            SessionManager.clear_messages("agent")
            st.rerun()
    
    with col2:
        st.info("Agent ëª¨ë“œ: ë˜‘ë˜‘í•œ ë„êµ¬ ì„ íƒìœ¼ë¡œ ë§ì¶¤í˜• ê²€ìƒ‰ (ë™ì  ê²°ê³¼)")
    
    ####################################
    # ê¸°ì¡´ì— ì €ì¥ëœ ë©”ì‹œì§€ ì¶œë ¥
    ####################################
    messages = SessionManager.get_messages("agent")
    
    for message in messages:
        with st.chat_message(message['role']):
            st.markdown(message['content'])
    
    ####################################
    # ì‚¬ìš©ìì˜ ë©”ì‹œì§€(prompt) ì…ë ¥
    ####################################
    prompt = st.chat_input("ì£¼íƒì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš” (ì˜ˆ: í™ëŒ€ì—­ ê·¼ì²˜ ì£¼íƒ ëª¨ë‘ ë³´ì—¬ì¤˜)")
    
    if isinstance(prompt, str) and prompt.strip():
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        user_message = {
            "role": "user",
            "content": prompt.strip()
        }
        
        with st.chat_message(user_message["role"]):
            st.markdown(user_message["content"])
        
        # ì„¸ì…˜ì— ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
        SessionManager.add_message("agent", "user", prompt.strip())
        
        ####################################
        # LLMì˜ ë‹µë³€ (Agent ëª¨ë“œ)
        ####################################
        with st.chat_message("assistant"):
            # í˜„ì¬ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ë° ë©”ëª¨ë¦¬ ê°€ì ¸ì˜¤ê¸°
            current_messages = SessionManager.get_messages("agent")
            current_memory = SessionManager.get_memory("agent")
            
            # ë¡œë”© í‘œì‹œ
            with st.spinner("Agentê°€ ìµœì ì˜ ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                assistant_response = st.write_stream(
                    response_from_agent(current_messages, memory=current_memory)
                )
        
        # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µì„ ì„¸ì…˜ì— ì €ì¥
        SessionManager.add_message("agent", "assistant", assistant_response)
    
    # ì‚¬ìš© ì•ˆë‚´
    with st.expander("ğŸ’¡ ì‚¬ìš© íŒ"):
        st.markdown("""
        **Agent ëª¨ë“œ íŠ¹ì§•:**
        - ğŸ§  ì‚¬ìš©ì ì˜ë„ íŒŒì•… ("ëª¨ë‘" vs "ì¶”ì²œ")
        - ğŸ”§ ë™ì  ë„êµ¬ ì„ íƒ ë° ê²€ìƒ‰ ì¡°ê±´ ë³€ê²½
        - ğŸ“Š ë‹¤ì–‘í•œ ê²€ìƒ‰ ëª¨ë“œ (comprehensive/diverse)
        - ğŸ¯ ë§ì¶¤í˜• ê²°ê³¼ ì œê³µ
        
        **ì§ˆë¬¸ ì˜ˆì‹œ:**
        - "ì„œì´ˆêµ¬ ì£¼íƒ **ëª¨ë‘** ë³´ì—¬ì¤˜" â†’ 20ê°œ ê²°ê³¼
        - "ê°•ë‚¨êµ¬ ì¢‹ì€ ì£¼íƒ **ì¶”ì²œ**í•´ì¤˜" â†’ 5ê°œ ì¶”ì²œ
        - "ì§€í•˜ì²  2í˜¸ì„  ê·¼ì²˜ ì›ë£¸ ì°¾ì•„ì¤˜"
        - "ì˜ˆì‚° 50ë§Œì› ì´í•˜ ì£¼íƒ ìˆì–´?"
        """)
    
    # Agent ìƒíƒœ ì •ë³´
    with st.expander("ğŸ”§ Agent ì •ë³´"):
        try:
            from backend.services.llm.models.inha.llm_inha import USE_HYBRID
            
            if USE_HYBRID:
                st.markdown("""
                **í˜„ì¬ ì„¤ì • (í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ):**
                - ğŸ¤– Agent LLM: OpenAI gpt-4o-mini (ë„êµ¬ í˜¸ì¶œ)
                - ğŸ’¬ Response LLM: Groq llama-3.3-70b-versatile (ë‹µë³€ ìƒì„±)
                - ğŸ› ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: ì£¼íƒ ê²€ìƒ‰
                - ğŸ”„ ìµœëŒ€ ë°˜ë³µ: 5íšŒ
                - âš™ï¸ ëª¨ë“œ: í•˜ì´ë¸Œë¦¬ë“œ (2ë‹¨ê³„ ì²˜ë¦¬)
                """)
            else:
                st.markdown("""
                **í˜„ì¬ ì„¤ì • (ë‹¨ì¼ ëª¨ë“œ):**
                - ğŸ¤– LLM: Groq llama-3.3-70b-versatile
                - ğŸ› ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: ì£¼íƒ ê²€ìƒ‰
                - ğŸ”„ ìµœëŒ€ ë°˜ë³µ: 5íšŒ
                - âš™ï¸ ëª¨ë“œ: ë‹¨ì¼ LLM (ë¹ ë¥¸ ì²˜ë¦¬)
                """)
        except ImportError:
            st.markdown("""
            **ì„¤ì • ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.**
            - ğŸ› ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: ì£¼íƒ ê²€ìƒ‰
            - ğŸ”„ ìµœëŒ€ ë°˜ë³µ: 5íšŒ
            """)
    
    # í˜„ì¬ ëŒ€í™” ìˆ˜ í‘œì‹œ
    if messages:
        st.sidebar.metric("í˜„ì¬ ëŒ€í™” ìˆ˜", len([m for m in messages if m["role"] == "user"]))